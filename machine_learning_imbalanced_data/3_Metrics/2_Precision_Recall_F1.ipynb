{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ClassificationReport, DiscriminationThreshold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.0</td>\n",
       "      <td>32.69</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1256.8</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.33</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1595.1</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>2.83</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>445.2</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.0</td>\n",
       "      <td>33.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>608.1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.07</td>\n",
       "      <td>20.5</td>\n",
       "      <td>-52.5</td>\n",
       "      <td>...</td>\n",
       "      <td>762.9</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.3</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>27.27</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>6.0</td>\n",
       "      <td>58.5</td>\n",
       "      <td>1623.6</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1491.8</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>658.2</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.24</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.0</td>\n",
       "      <td>27.91</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1921.6</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-51.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2047.7</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>554.2</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.0</td>\n",
       "      <td>28.00</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>464.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.19</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-51.5</td>\n",
       "      <td>...</td>\n",
       "      <td>479.5</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1     2     3     4       5     6     7     8     9  ...      65  \\\n",
       "0  52.0  32.69  0.30   2.5  20.0  1256.8 -0.89  0.33  11.0 -55.0  ...  1595.1   \n",
       "1  58.0  33.33  0.00  16.5   9.5   608.1  0.50  0.07  20.5 -52.5  ...   762.9   \n",
       "2  77.0  27.27 -0.91   6.0  58.5  1623.6 -1.40  0.02  -6.5 -48.0  ...  1491.8   \n",
       "3  41.0  27.91 -0.35   3.0  46.0  1921.6 -1.36 -0.47 -32.0 -51.5  ...  2047.7   \n",
       "4  50.0  28.00 -1.32  -9.0  12.0   464.8  0.88  0.19   8.0 -51.5  ...   479.5   \n",
       "\n",
       "     66    67   68    69     70    71    72    73  target  \n",
       "0 -1.64  2.83 -2.0 -50.0  445.2 -0.35  0.26  0.76      -1  \n",
       "1  0.29  0.82 -3.0 -35.0  140.3  1.16  0.39  0.73      -1  \n",
       "2  0.32 -1.29  0.0 -34.0  658.2 -0.76  0.26  0.24      -1  \n",
       "3 -0.98  1.53  0.0 -49.0  554.2 -0.83  0.39  0.73      -1  \n",
       "4  0.68 -0.59  2.0 -36.0   -6.9  2.02  0.14 -0.23      -1  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../kdd2004.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
       "       '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24',\n",
       "       '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36',\n",
       "       '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48',\n",
       "       '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60',\n",
       "       '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72',\n",
       "       '73', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        -1\n",
       "1        -1\n",
       "2        -1\n",
       "3        -1\n",
       "4        -1\n",
       "         ..\n",
       "145746   -1\n",
       "145747   -1\n",
       "145748    1\n",
       "145749   -1\n",
       "145750    1\n",
       "Name: target, Length: 145751, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target =df.target.map({-1:0, 1:1})\n",
    "df.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145751, 75)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12',\n",
       "       '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24',\n",
       "       '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36',\n",
       "       '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48',\n",
       "       '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60',\n",
       "       '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72',\n",
       "       '73', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52.0</td>\n",
       "      <td>32.69</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1256.8</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0.33</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1595.1</td>\n",
       "      <td>-1.64</td>\n",
       "      <td>2.83</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>445.2</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.0</td>\n",
       "      <td>33.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>608.1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.07</td>\n",
       "      <td>20.5</td>\n",
       "      <td>-52.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>762.9</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.82</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>140.3</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>27.27</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>6.0</td>\n",
       "      <td>58.5</td>\n",
       "      <td>1623.6</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1491.8</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>658.2</td>\n",
       "      <td>-0.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41.0</td>\n",
       "      <td>27.91</td>\n",
       "      <td>-0.35</td>\n",
       "      <td>3.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1921.6</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>-0.47</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-51.5</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2047.7</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>1.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>554.2</td>\n",
       "      <td>-0.83</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.0</td>\n",
       "      <td>28.00</td>\n",
       "      <td>-1.32</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>464.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.19</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-51.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>479.5</td>\n",
       "      <td>0.68</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-36.0</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1     2     3     4       5     6     7     8     9  ...    64  \\\n",
       "0  52.0  32.69  0.30   2.5  20.0  1256.8 -0.89  0.33  11.0 -55.0  ...  -8.0   \n",
       "1  58.0  33.33  0.00  16.5   9.5   608.1  0.50  0.07  20.5 -52.5  ...  -6.0   \n",
       "2  77.0  27.27 -0.91   6.0  58.5  1623.6 -1.40  0.02  -6.5 -48.0  ...   7.0   \n",
       "3  41.0  27.91 -0.35   3.0  46.0  1921.6 -1.36 -0.47 -32.0 -51.5  ...   6.0   \n",
       "4  50.0  28.00 -1.32  -9.0  12.0   464.8  0.88  0.19   8.0 -51.5  ... -14.0   \n",
       "\n",
       "       65    66    67   68    69     70    71    72    73  \n",
       "0  1595.1 -1.64  2.83 -2.0 -50.0  445.2 -0.35  0.26  0.76  \n",
       "1   762.9  0.29  0.82 -3.0 -35.0  140.3  1.16  0.39  0.73  \n",
       "2  1491.8  0.32 -1.29  0.0 -34.0  658.2 -0.76  0.26  0.24  \n",
       "3  2047.7 -0.98  1.53  0.0 -49.0  554.2 -0.83  0.39  0.73  \n",
       "4   479.5  0.68 -0.59  2.0 -36.0   -6.9  2.02  0.14 -0.23  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=df.drop(columns='target', axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '_AXIS_LEN',\n",
       " '_AXIS_ORDERS',\n",
       " '_AXIS_TO_AXIS_NUMBER',\n",
       " '_HANDLED_TYPES',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__annotations__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_ufunc__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__column_consortium_standard__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__finalize__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pandas_priority__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__round__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_accessors',\n",
       " '_accum_func',\n",
       " '_agg_examples_doc',\n",
       " '_agg_see_also_doc',\n",
       " '_align_for_op',\n",
       " '_align_frame',\n",
       " '_align_series',\n",
       " '_append',\n",
       " '_arith_method',\n",
       " '_as_manager',\n",
       " '_attrs',\n",
       " '_binop',\n",
       " '_cacher',\n",
       " '_can_hold_na',\n",
       " '_check_inplace_and_allows_duplicate_labels',\n",
       " '_check_is_chained_assignment_possible',\n",
       " '_check_label_or_level_ambiguity',\n",
       " '_check_setitem_copy',\n",
       " '_clear_item_cache',\n",
       " '_clip_with_one_bound',\n",
       " '_clip_with_scalar',\n",
       " '_cmp_method',\n",
       " '_consolidate',\n",
       " '_consolidate_inplace',\n",
       " '_construct_axes_dict',\n",
       " '_construct_result',\n",
       " '_constructor',\n",
       " '_constructor_expanddim',\n",
       " '_constructor_expanddim_from_mgr',\n",
       " '_constructor_from_mgr',\n",
       " '_data',\n",
       " '_deprecate_downcast',\n",
       " '_dir_additions',\n",
       " '_dir_deletions',\n",
       " '_drop_axis',\n",
       " '_drop_labels_or_levels',\n",
       " '_duplicated',\n",
       " '_find_valid_index',\n",
       " '_flags',\n",
       " '_flex_method',\n",
       " '_from_mgr',\n",
       " '_get_axis',\n",
       " '_get_axis_name',\n",
       " '_get_axis_number',\n",
       " '_get_axis_resolvers',\n",
       " '_get_block_manager_axis',\n",
       " '_get_bool_data',\n",
       " '_get_cacher',\n",
       " '_get_cleaned_column_resolvers',\n",
       " '_get_index_resolvers',\n",
       " '_get_label_or_level_values',\n",
       " '_get_numeric_data',\n",
       " '_get_rows_with_mask',\n",
       " '_get_value',\n",
       " '_get_values_tuple',\n",
       " '_get_with',\n",
       " '_getitem_slice',\n",
       " '_gotitem',\n",
       " '_hidden_attrs',\n",
       " '_indexed_same',\n",
       " '_info_axis',\n",
       " '_info_axis_name',\n",
       " '_info_axis_number',\n",
       " '_init_dict',\n",
       " '_init_mgr',\n",
       " '_inplace_method',\n",
       " '_internal_names',\n",
       " '_internal_names_set',\n",
       " '_is_cached',\n",
       " '_is_copy',\n",
       " '_is_label_or_level_reference',\n",
       " '_is_label_reference',\n",
       " '_is_level_reference',\n",
       " '_is_mixed_type',\n",
       " '_is_view',\n",
       " '_is_view_after_cow_rules',\n",
       " '_item_cache',\n",
       " '_ixs',\n",
       " '_logical_func',\n",
       " '_logical_method',\n",
       " '_map_values',\n",
       " '_maybe_update_cacher',\n",
       " '_memory_usage',\n",
       " '_metadata',\n",
       " '_mgr',\n",
       " '_min_count_stat_function',\n",
       " '_name',\n",
       " '_needs_reindex_multi',\n",
       " '_pad_or_backfill',\n",
       " '_protect_consolidate',\n",
       " '_reduce',\n",
       " '_references',\n",
       " '_reindex_axes',\n",
       " '_reindex_indexer',\n",
       " '_reindex_multi',\n",
       " '_reindex_with_indexers',\n",
       " '_rename',\n",
       " '_replace_single',\n",
       " '_repr_data_resource_',\n",
       " '_repr_latex_',\n",
       " '_reset_cache',\n",
       " '_reset_cacher',\n",
       " '_set_as_cached',\n",
       " '_set_axis',\n",
       " '_set_axis_name',\n",
       " '_set_axis_nocheck',\n",
       " '_set_is_copy',\n",
       " '_set_labels',\n",
       " '_set_name',\n",
       " '_set_value',\n",
       " '_set_values',\n",
       " '_set_with',\n",
       " '_set_with_engine',\n",
       " '_shift_with_freq',\n",
       " '_slice',\n",
       " '_stat_function',\n",
       " '_stat_function_ddof',\n",
       " '_take_with_is_copy',\n",
       " '_to_latex_via_styler',\n",
       " '_typ',\n",
       " '_update_inplace',\n",
       " '_validate_dtype',\n",
       " '_values',\n",
       " '_where',\n",
       " 'abs',\n",
       " 'add',\n",
       " 'add_prefix',\n",
       " 'add_suffix',\n",
       " 'agg',\n",
       " 'aggregate',\n",
       " 'align',\n",
       " 'all',\n",
       " 'any',\n",
       " 'apply',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'array',\n",
       " 'asfreq',\n",
       " 'asof',\n",
       " 'astype',\n",
       " 'at',\n",
       " 'at_time',\n",
       " 'attrs',\n",
       " 'autocorr',\n",
       " 'axes',\n",
       " 'backfill',\n",
       " 'between',\n",
       " 'between_time',\n",
       " 'bfill',\n",
       " 'bool',\n",
       " 'case_when',\n",
       " 'clip',\n",
       " 'combine',\n",
       " 'combine_first',\n",
       " 'compare',\n",
       " 'convert_dtypes',\n",
       " 'copy',\n",
       " 'corr',\n",
       " 'count',\n",
       " 'cov',\n",
       " 'cummax',\n",
       " 'cummin',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'describe',\n",
       " 'diff',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'divmod',\n",
       " 'dot',\n",
       " 'drop',\n",
       " 'drop_duplicates',\n",
       " 'droplevel',\n",
       " 'dropna',\n",
       " 'dtype',\n",
       " 'dtypes',\n",
       " 'duplicated',\n",
       " 'empty',\n",
       " 'eq',\n",
       " 'equals',\n",
       " 'ewm',\n",
       " 'expanding',\n",
       " 'explode',\n",
       " 'factorize',\n",
       " 'ffill',\n",
       " 'fillna',\n",
       " 'filter',\n",
       " 'first',\n",
       " 'first_valid_index',\n",
       " 'flags',\n",
       " 'floordiv',\n",
       " 'ge',\n",
       " 'get',\n",
       " 'groupby',\n",
       " 'gt',\n",
       " 'hasnans',\n",
       " 'head',\n",
       " 'hist',\n",
       " 'iat',\n",
       " 'idxmax',\n",
       " 'idxmin',\n",
       " 'iloc',\n",
       " 'index',\n",
       " 'infer_objects',\n",
       " 'info',\n",
       " 'interpolate',\n",
       " 'is_monotonic_decreasing',\n",
       " 'is_monotonic_increasing',\n",
       " 'is_unique',\n",
       " 'isin',\n",
       " 'isna',\n",
       " 'isnull',\n",
       " 'item',\n",
       " 'items',\n",
       " 'keys',\n",
       " 'kurt',\n",
       " 'kurtosis',\n",
       " 'last',\n",
       " 'last_valid_index',\n",
       " 'le',\n",
       " 'list',\n",
       " 'loc',\n",
       " 'lt',\n",
       " 'map',\n",
       " 'mask',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'memory_usage',\n",
       " 'min',\n",
       " 'mod',\n",
       " 'mode',\n",
       " 'mul',\n",
       " 'multiply',\n",
       " 'name',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'ne',\n",
       " 'nlargest',\n",
       " 'notna',\n",
       " 'notnull',\n",
       " 'nsmallest',\n",
       " 'nunique',\n",
       " 'pad',\n",
       " 'pct_change',\n",
       " 'pipe',\n",
       " 'plot',\n",
       " 'pop',\n",
       " 'pow',\n",
       " 'prod',\n",
       " 'product',\n",
       " 'quantile',\n",
       " 'radd',\n",
       " 'rank',\n",
       " 'ravel',\n",
       " 'rdiv',\n",
       " 'rdivmod',\n",
       " 'reindex',\n",
       " 'reindex_like',\n",
       " 'rename',\n",
       " 'rename_axis',\n",
       " 'reorder_levels',\n",
       " 'repeat',\n",
       " 'replace',\n",
       " 'resample',\n",
       " 'reset_index',\n",
       " 'rfloordiv',\n",
       " 'rmod',\n",
       " 'rmul',\n",
       " 'rolling',\n",
       " 'round',\n",
       " 'rpow',\n",
       " 'rsub',\n",
       " 'rtruediv',\n",
       " 'sample',\n",
       " 'searchsorted',\n",
       " 'sem',\n",
       " 'set_axis',\n",
       " 'set_flags',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'size',\n",
       " 'skew',\n",
       " 'sort_index',\n",
       " 'sort_values',\n",
       " 'squeeze',\n",
       " 'std',\n",
       " 'struct',\n",
       " 'sub',\n",
       " 'subtract',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'swaplevel',\n",
       " 'tail',\n",
       " 'take',\n",
       " 'to_clipboard',\n",
       " 'to_csv',\n",
       " 'to_dict',\n",
       " 'to_excel',\n",
       " 'to_frame',\n",
       " 'to_hdf',\n",
       " 'to_json',\n",
       " 'to_latex',\n",
       " 'to_list',\n",
       " 'to_markdown',\n",
       " 'to_numpy',\n",
       " 'to_period',\n",
       " 'to_pickle',\n",
       " 'to_sql',\n",
       " 'to_string',\n",
       " 'to_timestamp',\n",
       " 'to_xarray',\n",
       " 'transform',\n",
       " 'transpose',\n",
       " 'truediv',\n",
       " 'truncate',\n",
       " 'tz_convert',\n",
       " 'tz_localize',\n",
       " 'unique',\n",
       " 'unstack',\n",
       " 'update',\n",
       " 'value_counts',\n",
       " 'values',\n",
       " 'var',\n",
       " 'view',\n",
       " 'where',\n",
       " 'xs']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    144455\n",
       "1      1296\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mnormalize\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msort\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mascending\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdropna\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'bool'\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m'Series'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Return a Series containing counts of unique values.\n",
      "\n",
      "The resulting object will be in descending order so that the\n",
      "first element is the most frequently-occurring element.\n",
      "Excludes NA values by default.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "normalize : bool, default False\n",
      "    If True then the object returned will contain the relative\n",
      "    frequencies of the unique values.\n",
      "sort : bool, default True\n",
      "    Sort by frequencies when True. Preserve the order of the data when False.\n",
      "ascending : bool, default False\n",
      "    Sort in ascending order.\n",
      "bins : int, optional\n",
      "    Rather than count values, group them into half-open bins,\n",
      "    a convenience for ``pd.cut``, only works with numeric data.\n",
      "dropna : bool, default True\n",
      "    Don't include counts of NaN.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "Series\n",
      "\n",
      "See Also\n",
      "--------\n",
      "Series.count: Number of non-NA elements in a Series.\n",
      "DataFrame.count: Number of non-NA elements in a DataFrame.\n",
      "DataFrame.value_counts: Equivalent method on DataFrames.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> index = pd.Index([3, 1, 2, 3, 4, np.nan])\n",
      ">>> index.value_counts()\n",
      "3.0    2\n",
      "1.0    1\n",
      "2.0    1\n",
      "4.0    1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "With `normalize` set to `True`, returns the relative frequency by\n",
      "dividing all values by the sum of values.\n",
      "\n",
      ">>> s = pd.Series([3, 1, 2, 3, 4, np.nan])\n",
      ">>> s.value_counts(normalize=True)\n",
      "3.0    0.4\n",
      "1.0    0.2\n",
      "2.0    0.2\n",
      "4.0    0.2\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "**bins**\n",
      "\n",
      "Bins can be useful for going from a continuous variable to a\n",
      "categorical variable; instead of counting unique\n",
      "apparitions of values, divide the index in the specified\n",
      "number of half-open bins.\n",
      "\n",
      ">>> s.value_counts(bins=3)\n",
      "(0.996, 2.0]    2\n",
      "(2.0, 3.0]      2\n",
      "(3.0, 4.0]      1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "**dropna**\n",
      "\n",
      "With `dropna` set to `False` we can also see NaN index values.\n",
      "\n",
      ">>> s.value_counts(dropna=False)\n",
      "3.0    2\n",
      "1.0    1\n",
      "2.0    1\n",
      "4.0    1\n",
      "NaN    1\n",
      "Name: count, dtype: int64\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/pandas/core/base.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "?df.target.value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    0.991108\n",
       "1    0.008892\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= df.target\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((102025, 74), (102025,), (43726, 74), (43726,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Predict the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_base = pd.Series(np.zeros(len(y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_base = pd.Series(np.zeros(len(y_test)))\n",
    "y_test_base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gini'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmin_samples_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sqrt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_leaf_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmin_impurity_decrease\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moob_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mccp_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmonotonic_cst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "A random forest classifier.\n",
      "\n",
      "A random forest is a meta estimator that fits a number of decision tree\n",
      "classifiers on various sub-samples of the dataset and uses averaging to\n",
      "improve the predictive accuracy and control over-fitting.\n",
      "Trees in the forest use the best split strategy, i.e. equivalent to passing\n",
      "`splitter=\"best\"` to the underlying :class:`~sklearn.tree.DecisionTreeClassifier`.\n",
      "The sub-sample size is controlled with the `max_samples` parameter if\n",
      "`bootstrap=True` (default), otherwise the whole dataset is used to build\n",
      "each tree.\n",
      "\n",
      "For a comparison between tree-based ensemble models see the example\n",
      ":ref:`sphx_glr_auto_examples_ensemble_plot_forest_hist_grad_boosting_comparison.py`.\n",
      "\n",
      "Read more in the :ref:`User Guide <forest>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "n_estimators : int, default=100\n",
      "    The number of trees in the forest.\n",
      "\n",
      "    .. versionchanged:: 0.22\n",
      "       The default value of ``n_estimators`` changed from 10 to 100\n",
      "       in 0.22.\n",
      "\n",
      "criterion : {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"\n",
      "    The function to measure the quality of a split. Supported criteria are\n",
      "    \"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the\n",
      "    Shannon information gain, see :ref:`tree_mathematical_formulation`.\n",
      "    Note: This parameter is tree-specific.\n",
      "\n",
      "max_depth : int, default=None\n",
      "    The maximum depth of the tree. If None, then nodes are expanded until\n",
      "    all leaves are pure or until all leaves contain less than\n",
      "    min_samples_split samples.\n",
      "\n",
      "min_samples_split : int or float, default=2\n",
      "    The minimum number of samples required to split an internal node:\n",
      "\n",
      "    - If int, then consider `min_samples_split` as the minimum number.\n",
      "    - If float, then `min_samples_split` is a fraction and\n",
      "      `ceil(min_samples_split * n_samples)` are the minimum\n",
      "      number of samples for each split.\n",
      "\n",
      "    .. versionchanged:: 0.18\n",
      "       Added float values for fractions.\n",
      "\n",
      "min_samples_leaf : int or float, default=1\n",
      "    The minimum number of samples required to be at a leaf node.\n",
      "    A split point at any depth will only be considered if it leaves at\n",
      "    least ``min_samples_leaf`` training samples in each of the left and\n",
      "    right branches.  This may have the effect of smoothing the model,\n",
      "    especially in regression.\n",
      "\n",
      "    - If int, then consider `min_samples_leaf` as the minimum number.\n",
      "    - If float, then `min_samples_leaf` is a fraction and\n",
      "      `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      "      number of samples for each node.\n",
      "\n",
      "    .. versionchanged:: 0.18\n",
      "       Added float values for fractions.\n",
      "\n",
      "min_weight_fraction_leaf : float, default=0.0\n",
      "    The minimum weighted fraction of the sum total of weights (of all\n",
      "    the input samples) required to be at a leaf node. Samples have\n",
      "    equal weight when sample_weight is not provided.\n",
      "\n",
      "max_features : {\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\"\n",
      "    The number of features to consider when looking for the best split:\n",
      "\n",
      "    - If int, then consider `max_features` features at each split.\n",
      "    - If float, then `max_features` is a fraction and\n",
      "      `max(1, int(max_features * n_features_in_))` features are considered at each\n",
      "      split.\n",
      "    - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      "    - If \"log2\", then `max_features=log2(n_features)`.\n",
      "    - If None, then `max_features=n_features`.\n",
      "\n",
      "    .. versionchanged:: 1.1\n",
      "        The default of `max_features` changed from `\"auto\"` to `\"sqrt\"`.\n",
      "\n",
      "    Note: the search for a split does not stop until at least one\n",
      "    valid partition of the node samples is found, even if it requires to\n",
      "    effectively inspect more than ``max_features`` features.\n",
      "\n",
      "max_leaf_nodes : int, default=None\n",
      "    Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      "    Best nodes are defined as relative reduction in impurity.\n",
      "    If None then unlimited number of leaf nodes.\n",
      "\n",
      "min_impurity_decrease : float, default=0.0\n",
      "    A node will be split if this split induces a decrease of the impurity\n",
      "    greater than or equal to this value.\n",
      "\n",
      "    The weighted impurity decrease equation is the following::\n",
      "\n",
      "        N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      "                            - N_t_L / N_t * left_impurity)\n",
      "\n",
      "    where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      "    samples at the current node, ``N_t_L`` is the number of samples in the\n",
      "    left child, and ``N_t_R`` is the number of samples in the right child.\n",
      "\n",
      "    ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      "    if ``sample_weight`` is passed.\n",
      "\n",
      "    .. versionadded:: 0.19\n",
      "\n",
      "bootstrap : bool, default=True\n",
      "    Whether bootstrap samples are used when building trees. If False, the\n",
      "    whole dataset is used to build each tree.\n",
      "\n",
      "oob_score : bool or callable, default=False\n",
      "    Whether to use out-of-bag samples to estimate the generalization score.\n",
      "    By default, :func:`~sklearn.metrics.accuracy_score` is used.\n",
      "    Provide a callable with signature `metric(y_true, y_pred)` to use a\n",
      "    custom metric. Only available if `bootstrap=True`.\n",
      "\n",
      "n_jobs : int, default=None\n",
      "    The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
      "    :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
      "    trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      "    context. ``-1`` means using all processors. See :term:`Glossary\n",
      "    <n_jobs>` for more details.\n",
      "\n",
      "random_state : int, RandomState instance or None, default=None\n",
      "    Controls both the randomness of the bootstrapping of the samples used\n",
      "    when building trees (if ``bootstrap=True``) and the sampling of the\n",
      "    features to consider when looking for the best split at each node\n",
      "    (if ``max_features < n_features``).\n",
      "    See :term:`Glossary <random_state>` for details.\n",
      "\n",
      "verbose : int, default=0\n",
      "    Controls the verbosity when fitting and predicting.\n",
      "\n",
      "warm_start : bool, default=False\n",
      "    When set to ``True``, reuse the solution of the previous call to fit\n",
      "    and add more estimators to the ensemble, otherwise, just fit a whole\n",
      "    new forest. See :term:`Glossary <warm_start>` and\n",
      "    :ref:`tree_ensemble_warm_start` for details.\n",
      "\n",
      "class_weight : {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None\n",
      "    Weights associated with classes in the form ``{class_label: weight}``.\n",
      "    If not given, all classes are supposed to have weight one. For\n",
      "    multi-output problems, a list of dicts can be provided in the same\n",
      "    order as the columns of y.\n",
      "\n",
      "    Note that for multioutput (including multilabel) weights should be\n",
      "    defined for each class of every column in its own dict. For example,\n",
      "    for four-class multilabel classification weights should be\n",
      "    [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      "    [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      "\n",
      "    The \"balanced\" mode uses the values of y to automatically adjust\n",
      "    weights inversely proportional to class frequencies in the input data\n",
      "    as ``n_samples / (n_classes * np.bincount(y))``\n",
      "\n",
      "    The \"balanced_subsample\" mode is the same as \"balanced\" except that\n",
      "    weights are computed based on the bootstrap sample for every tree\n",
      "    grown.\n",
      "\n",
      "    For multi-output, the weights of each column of y will be multiplied.\n",
      "\n",
      "    Note that these weights will be multiplied with sample_weight (passed\n",
      "    through the fit method) if sample_weight is specified.\n",
      "\n",
      "ccp_alpha : non-negative float, default=0.0\n",
      "    Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      "    subtree with the largest cost complexity that is smaller than\n",
      "    ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      "    :ref:`minimal_cost_complexity_pruning` for details. See\n",
      "    :ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`\n",
      "    for an example of such pruning.\n",
      "\n",
      "    .. versionadded:: 0.22\n",
      "\n",
      "max_samples : int or float, default=None\n",
      "    If bootstrap is True, the number of samples to draw from X\n",
      "    to train each base estimator.\n",
      "\n",
      "    - If None (default), then draw `X.shape[0]` samples.\n",
      "    - If int, then draw `max_samples` samples.\n",
      "    - If float, then draw `max(round(n_samples * max_samples), 1)` samples. Thus,\n",
      "      `max_samples` should be in the interval `(0.0, 1.0]`.\n",
      "\n",
      "    .. versionadded:: 0.22\n",
      "\n",
      "monotonic_cst : array-like of int of shape (n_features), default=None\n",
      "    Indicates the monotonicity constraint to enforce on each feature.\n",
      "      - 1: monotonic increase\n",
      "      - 0: no constraint\n",
      "      - -1: monotonic decrease\n",
      "\n",
      "    If monotonic_cst is None, no constraints are applied.\n",
      "\n",
      "    Monotonicity constraints are not supported for:\n",
      "      - multiclass classifications (i.e. when `n_classes > 2`),\n",
      "      - multioutput classifications (i.e. when `n_outputs_ > 1`),\n",
      "      - classifications trained on data with missing values.\n",
      "\n",
      "    The constraints hold over the probability of the positive class.\n",
      "\n",
      "    Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.\n",
      "\n",
      "    .. versionadded:: 1.4\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "estimator_ : :class:`~sklearn.tree.DecisionTreeClassifier`\n",
      "    The child estimator template used to create the collection of fitted\n",
      "    sub-estimators.\n",
      "\n",
      "    .. versionadded:: 1.2\n",
      "       `base_estimator_` was renamed to `estimator_`.\n",
      "\n",
      "estimators_ : list of DecisionTreeClassifier\n",
      "    The collection of fitted sub-estimators.\n",
      "\n",
      "classes_ : ndarray of shape (n_classes,) or a list of such arrays\n",
      "    The classes labels (single output problem), or a list of arrays of\n",
      "    class labels (multi-output problem).\n",
      "\n",
      "n_classes_ : int or list\n",
      "    The number of classes (single output problem), or a list containing the\n",
      "    number of classes for each output (multi-output problem).\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "n_outputs_ : int\n",
      "    The number of outputs when ``fit`` is performed.\n",
      "\n",
      "feature_importances_ : ndarray of shape (n_features,)\n",
      "    The impurity-based feature importances.\n",
      "    The higher, the more important the feature.\n",
      "    The importance of a feature is computed as the (normalized)\n",
      "    total reduction of the criterion brought by that feature.  It is also\n",
      "    known as the Gini importance.\n",
      "\n",
      "    Warning: impurity-based feature importances can be misleading for\n",
      "    high cardinality features (many unique values). See\n",
      "    :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      "\n",
      "oob_score_ : float\n",
      "    Score of the training dataset obtained using an out-of-bag estimate.\n",
      "    This attribute exists only when ``oob_score`` is True.\n",
      "\n",
      "oob_decision_function_ : ndarray of shape (n_samples, n_classes) or             (n_samples, n_classes, n_outputs)\n",
      "    Decision function computed with out-of-bag estimate on the training\n",
      "    set. If n_estimators is small it might be possible that a data point\n",
      "    was never left out during the bootstrap. In this case,\n",
      "    `oob_decision_function_` might contain NaN. This attribute exists\n",
      "    only when ``oob_score`` is True.\n",
      "\n",
      "estimators_samples_ : list of arrays\n",
      "    The subset of drawn samples (i.e., the in-bag samples) for each base\n",
      "    estimator. Each subset is defined by an array of the indices selected.\n",
      "\n",
      "    .. versionadded:: 1.4\n",
      "\n",
      "See Also\n",
      "--------\n",
      "sklearn.tree.DecisionTreeClassifier : A decision tree classifier.\n",
      "sklearn.ensemble.ExtraTreesClassifier : Ensemble of extremely randomized\n",
      "    tree classifiers.\n",
      "sklearn.ensemble.HistGradientBoostingClassifier : A Histogram-based Gradient\n",
      "    Boosting Classification Tree, very fast for big datasets (n_samples >=\n",
      "    10_000).\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The default values for the parameters controlling the size of the trees\n",
      "(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      "unpruned trees which can potentially be very large on some data sets. To\n",
      "reduce memory consumption, the complexity and size of the trees should be\n",
      "controlled by setting those parameter values.\n",
      "\n",
      "The features are always randomly permuted at each split. Therefore,\n",
      "the best found split may vary, even with the same training data,\n",
      "``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      "of the criterion is identical for several splits enumerated during the\n",
      "search of the best split. To obtain a deterministic behaviour during\n",
      "fitting, ``random_state`` has to be fixed.\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.ensemble import RandomForestClassifier\n",
      ">>> from sklearn.datasets import make_classification\n",
      ">>> X, y = make_classification(n_samples=1000, n_features=4,\n",
      "...                            n_informative=2, n_redundant=0,\n",
      "...                            random_state=0, shuffle=False)\n",
      ">>> clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
      ">>> clf.fit(X, y)\n",
      "RandomForestClassifier(...)\n",
      ">>> print(clf.predict([[0, 0, 0, 0]]))\n",
      "[1]\n",
      "\u001b[0;31mFile:\u001b[0m           ~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\n",
      "\u001b[0;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=2, n_jobs=4, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=2, n_jobs=4, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=2, n_jobs=4, random_state=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=0, max_depth=2, n_jobs=4)\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__abstractmethods__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__sklearn_clone__',\n",
       " '__sklearn_tags__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_build_request_for_signature',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_compute_oob_predictions',\n",
       " '_doc_link_module',\n",
       " '_doc_link_template',\n",
       " '_doc_link_url_param_generator',\n",
       " '_estimator_type',\n",
       " '_get_default_requests',\n",
       " '_get_doc_link',\n",
       " '_get_estimators_indices',\n",
       " '_get_metadata_request',\n",
       " '_get_oob_predictions',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_make_estimator',\n",
       " '_more_tags',\n",
       " '_n_samples',\n",
       " '_n_samples_bootstrap',\n",
       " '_parameter_constraints',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_set_oob_score_and_attributes',\n",
       " '_validate_X_predict',\n",
       " '_validate_data',\n",
       " '_validate_estimator',\n",
       " '_validate_params',\n",
       " '_validate_y_class_weight',\n",
       " 'apply',\n",
       " 'bootstrap',\n",
       " 'ccp_alpha',\n",
       " 'class_weight',\n",
       " 'classes_',\n",
       " 'criterion',\n",
       " 'decision_path',\n",
       " 'estimator',\n",
       " 'estimator_',\n",
       " 'estimator_params',\n",
       " 'estimators_',\n",
       " 'estimators_samples_',\n",
       " 'feature_importances_',\n",
       " 'feature_names_in_',\n",
       " 'fit',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'max_depth',\n",
       " 'max_features',\n",
       " 'max_leaf_nodes',\n",
       " 'max_samples',\n",
       " 'min_impurity_decrease',\n",
       " 'min_samples_leaf',\n",
       " 'min_samples_split',\n",
       " 'min_weight_fraction_leaf',\n",
       " 'monotonic_cst',\n",
       " 'n_classes_',\n",
       " 'n_estimators',\n",
       " 'n_features_in_',\n",
       " 'n_jobs',\n",
       " 'n_outputs_',\n",
       " 'oob_score',\n",
       " 'predict',\n",
       " 'predict_log_proba',\n",
       " 'predict_proba',\n",
       " 'random_state',\n",
       " 'score',\n",
       " 'set_fit_request',\n",
       " 'set_params',\n",
       " 'set_score_request',\n",
       " 'verbose',\n",
       " 'warm_start']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99575697, 0.00424303],\n",
       "       [0.99644666, 0.00355334],\n",
       "       [0.99644666, 0.00355334],\n",
       "       ...,\n",
       "       [0.99644666, 0.00355334],\n",
       "       [0.99644666, 0.00355334],\n",
       "       [0.99644666, 0.00355334]], shape=(102025, 2))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_rf = rf.predict_proba(X_train)[:,1]\n",
    "y_test_rf = rf.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdual\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfit_intercept\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mintercept_scaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Logistic Regression (aka logit, MaxEnt) classifier.\n",
      "\n",
      "This class implements regularized logistic regression using the\n",
      "'liblinear' library, 'newton-cg', 'sag', 'saga' and 'lbfgs' solvers. **Note\n",
      "that regularization is applied by default**. It can handle both dense\n",
      "and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit\n",
      "floats for optimal performance; any other input format will be converted\n",
      "(and copied).\n",
      "\n",
      "The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\n",
      "with primal formulation, or no regularization. The 'liblinear' solver\n",
      "supports both L1 and L2 regularization, with a dual formulation only for\n",
      "the L2 penalty. The Elastic-Net regularization is only supported by the\n",
      "'saga' solver.\n",
      "\n",
      "For :term:`multiclass` problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'\n",
      "handle multinomial loss. 'liblinear' and 'newton-cholesky' only handle binary\n",
      "classification but can be extended to handle multiclass by using\n",
      ":class:`~sklearn.multiclass.OneVsRestClassifier`.\n",
      "\n",
      "Read more in the :ref:`User Guide <logistic_regression>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "penalty : {'l1', 'l2', 'elasticnet', None}, default='l2'\n",
      "    Specify the norm of the penalty:\n",
      "\n",
      "    - `None`: no penalty is added;\n",
      "    - `'l2'`: add a L2 penalty term and it is the default choice;\n",
      "    - `'l1'`: add a L1 penalty term;\n",
      "    - `'elasticnet'`: both L1 and L2 penalty terms are added.\n",
      "\n",
      "    .. warning::\n",
      "       Some penalties may not work with some solvers. See the parameter\n",
      "       `solver` below, to know the compatibility between the penalty and\n",
      "       solver.\n",
      "\n",
      "    .. versionadded:: 0.19\n",
      "       l1 penalty with SAGA solver (allowing 'multinomial' + L1)\n",
      "\n",
      "dual : bool, default=False\n",
      "    Dual (constrained) or primal (regularized, see also\n",
      "    :ref:`this equation <regularized-logistic-loss>`) formulation. Dual formulation\n",
      "    is only implemented for l2 penalty with liblinear solver. Prefer dual=False when\n",
      "    n_samples > n_features.\n",
      "\n",
      "tol : float, default=1e-4\n",
      "    Tolerance for stopping criteria.\n",
      "\n",
      "C : float, default=1.0\n",
      "    Inverse of regularization strength; must be a positive float.\n",
      "    Like in support vector machines, smaller values specify stronger\n",
      "    regularization.\n",
      "\n",
      "fit_intercept : bool, default=True\n",
      "    Specifies if a constant (a.k.a. bias or intercept) should be\n",
      "    added to the decision function.\n",
      "\n",
      "intercept_scaling : float, default=1\n",
      "    Useful only when the solver 'liblinear' is used\n",
      "    and self.fit_intercept is set to True. In this case, x becomes\n",
      "    [x, self.intercept_scaling],\n",
      "    i.e. a \"synthetic\" feature with constant value equal to\n",
      "    intercept_scaling is appended to the instance vector.\n",
      "    The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
      "\n",
      "    Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      "    as all other features.\n",
      "    To lessen the effect of regularization on synthetic feature weight\n",
      "    (and therefore on the intercept) intercept_scaling has to be increased.\n",
      "\n",
      "class_weight : dict or 'balanced', default=None\n",
      "    Weights associated with classes in the form ``{class_label: weight}``.\n",
      "    If not given, all classes are supposed to have weight one.\n",
      "\n",
      "    The \"balanced\" mode uses the values of y to automatically adjust\n",
      "    weights inversely proportional to class frequencies in the input data\n",
      "    as ``n_samples / (n_classes * np.bincount(y))``.\n",
      "\n",
      "    Note that these weights will be multiplied with sample_weight (passed\n",
      "    through the fit method) if sample_weight is specified.\n",
      "\n",
      "    .. versionadded:: 0.17\n",
      "       *class_weight='balanced'*\n",
      "\n",
      "random_state : int, RandomState instance, default=None\n",
      "    Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the\n",
      "    data. See :term:`Glossary <random_state>` for details.\n",
      "\n",
      "solver : {'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'},             default='lbfgs'\n",
      "\n",
      "    Algorithm to use in the optimization problem. Default is 'lbfgs'.\n",
      "    To choose a solver, you might want to consider the following aspects:\n",
      "\n",
      "    - For small datasets, 'liblinear' is a good choice, whereas 'sag'\n",
      "      and 'saga' are faster for large ones;\n",
      "    - For :term:`multiclass` problems, all solvers except 'liblinear' minimize the\n",
      "      full multinomial loss;\n",
      "    - 'liblinear' can only handle binary classification by default. To apply a\n",
      "      one-versus-rest scheme for the multiclass setting one can wrap it with the\n",
      "      :class:`~sklearn.multiclass.OneVsRestClassifier`.\n",
      "    - 'newton-cholesky' is a good choice for\n",
      "      `n_samples` >> `n_features * n_classes`, especially with one-hot encoded\n",
      "      categorical features with rare categories. Be aware that the memory usage\n",
      "      of this solver has a quadratic dependency on `n_features * n_classes`\n",
      "      because it explicitly computes the full Hessian matrix.\n",
      "\n",
      "    .. warning::\n",
      "       The choice of the algorithm depends on the penalty chosen and on\n",
      "       (multinomial) multiclass support:\n",
      "\n",
      "       ================= ============================== ======================\n",
      "       solver            penalty                        multinomial multiclass\n",
      "       ================= ============================== ======================\n",
      "       'lbfgs'           'l2', None                     yes\n",
      "       'liblinear'       'l1', 'l2'                     no\n",
      "       'newton-cg'       'l2', None                     yes\n",
      "       'newton-cholesky' 'l2', None                     no\n",
      "       'sag'             'l2', None                     yes\n",
      "       'saga'            'elasticnet', 'l1', 'l2', None yes\n",
      "       ================= ============================== ======================\n",
      "\n",
      "    .. note::\n",
      "       'sag' and 'saga' fast convergence is only guaranteed on features\n",
      "       with approximately the same scale. You can preprocess the data with\n",
      "       a scaler from :mod:`sklearn.preprocessing`.\n",
      "\n",
      "    .. seealso::\n",
      "       Refer to the :ref:`User Guide <Logistic_regression>` for more\n",
      "       information regarding :class:`LogisticRegression` and more specifically the\n",
      "       :ref:`Table <logistic_regression_solvers>`\n",
      "       summarizing solver/penalty supports.\n",
      "\n",
      "    .. versionadded:: 0.17\n",
      "       Stochastic Average Gradient descent solver.\n",
      "    .. versionadded:: 0.19\n",
      "       SAGA solver.\n",
      "    .. versionchanged:: 0.22\n",
      "        The default solver changed from 'liblinear' to 'lbfgs' in 0.22.\n",
      "    .. versionadded:: 1.2\n",
      "       newton-cholesky solver.\n",
      "\n",
      "max_iter : int, default=100\n",
      "    Maximum number of iterations taken for the solvers to converge.\n",
      "\n",
      "multi_class : {'auto', 'ovr', 'multinomial'}, default='auto'\n",
      "    If the option chosen is 'ovr', then a binary problem is fit for each\n",
      "    label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
      "    across the entire probability distribution, *even when the data is\n",
      "    binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
      "    'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
      "    and otherwise selects 'multinomial'.\n",
      "\n",
      "    .. versionadded:: 0.18\n",
      "       Stochastic Average Gradient descent solver for 'multinomial' case.\n",
      "    .. versionchanged:: 0.22\n",
      "        Default changed from 'ovr' to 'auto' in 0.22.\n",
      "    .. deprecated:: 1.5\n",
      "       ``multi_class`` was deprecated in version 1.5 and will be removed in 1.7.\n",
      "       From then on, the recommended 'multinomial' will always be used for\n",
      "       `n_classes >= 3`.\n",
      "       Solvers that do not support 'multinomial' will raise an error.\n",
      "       Use `sklearn.multiclass.OneVsRestClassifier(LogisticRegression())` if you\n",
      "       still want to use OvR.\n",
      "\n",
      "verbose : int, default=0\n",
      "    For the liblinear and lbfgs solvers set verbose to any positive\n",
      "    number for verbosity.\n",
      "\n",
      "warm_start : bool, default=False\n",
      "    When set to True, reuse the solution of the previous call to fit as\n",
      "    initialization, otherwise, just erase the previous solution.\n",
      "    Useless for liblinear solver. See :term:`the Glossary <warm_start>`.\n",
      "\n",
      "    .. versionadded:: 0.17\n",
      "       *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\n",
      "\n",
      "n_jobs : int, default=None\n",
      "    Number of CPU cores used when parallelizing over classes if\n",
      "    multi_class='ovr'\". This parameter is ignored when the ``solver`` is\n",
      "    set to 'liblinear' regardless of whether 'multi_class' is specified or\n",
      "    not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      "    context. ``-1`` means using all processors.\n",
      "    See :term:`Glossary <n_jobs>` for more details.\n",
      "\n",
      "l1_ratio : float, default=None\n",
      "    The Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``. Only\n",
      "    used if ``penalty='elasticnet'``. Setting ``l1_ratio=0`` is equivalent\n",
      "    to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent\n",
      "    to using ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a\n",
      "    combination of L1 and L2.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "\n",
      "classes_ : ndarray of shape (n_classes, )\n",
      "    A list of class labels known to the classifier.\n",
      "\n",
      "coef_ : ndarray of shape (1, n_features) or (n_classes, n_features)\n",
      "    Coefficient of the features in the decision function.\n",
      "\n",
      "    `coef_` is of shape (1, n_features) when the given problem is binary.\n",
      "    In particular, when `multi_class='multinomial'`, `coef_` corresponds\n",
      "    to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\n",
      "\n",
      "intercept_ : ndarray of shape (1,) or (n_classes,)\n",
      "    Intercept (a.k.a. bias) added to the decision function.\n",
      "\n",
      "    If `fit_intercept` is set to False, the intercept is set to zero.\n",
      "    `intercept_` is of shape (1,) when the given problem is binary.\n",
      "    In particular, when `multi_class='multinomial'`, `intercept_`\n",
      "    corresponds to outcome 1 (True) and `-intercept_` corresponds to\n",
      "    outcome 0 (False).\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "n_iter_ : ndarray of shape (n_classes,) or (1, )\n",
      "    Actual number of iterations for all classes. If binary or multinomial,\n",
      "    it returns only 1 element. For liblinear solver, only the maximum\n",
      "    number of iteration across all classes is given.\n",
      "\n",
      "    .. versionchanged:: 0.20\n",
      "\n",
      "        In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\n",
      "        ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "SGDClassifier : Incrementally trained logistic regression (when given\n",
      "    the parameter ``loss=\"log_loss\"``).\n",
      "LogisticRegressionCV : Logistic regression with built-in cross validation.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The underlying C implementation uses a random number generator to\n",
      "select features when fitting the model. It is thus not uncommon,\n",
      "to have slightly different results for the same input data. If\n",
      "that happens, try with a smaller tol parameter.\n",
      "\n",
      "Predict output may not match that of standalone liblinear in certain\n",
      "cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
      "in the narrative documentation.\n",
      "\n",
      "References\n",
      "----------\n",
      "\n",
      "L-BFGS-B -- Software for Large-scale Bound-constrained Optimization\n",
      "    Ciyou Zhu, Richard Byrd, Jorge Nocedal and Jose Luis Morales.\n",
      "    http://users.iems.northwestern.edu/~nocedal/lbfgsb.html\n",
      "\n",
      "LIBLINEAR -- A Library for Large Linear Classification\n",
      "    https://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
      "\n",
      "SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach\n",
      "    Minimizing Finite Sums with the Stochastic Average Gradient\n",
      "    https://hal.inria.fr/hal-00860051/document\n",
      "\n",
      "SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014).\n",
      "        :arxiv:`\"SAGA: A Fast Incremental Gradient Method With Support\n",
      "        for Non-Strongly Convex Composite Objectives\" <1407.0202>`\n",
      "\n",
      "Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\n",
      "    methods for logistic regression and maximum entropy models.\n",
      "    Machine Learning 85(1-2):41-75.\n",
      "    https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.datasets import load_iris\n",
      ">>> from sklearn.linear_model import LogisticRegression\n",
      ">>> X, y = load_iris(return_X_y=True)\n",
      ">>> clf = LogisticRegression(random_state=0).fit(X, y)\n",
      ">>> clf.predict(X[:2, :])\n",
      "array([0, 0])\n",
      ">>> clf.predict_proba(X[:2, :])\n",
      "array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
      "       [9.7...e-01, 2.8...e-02, ...e-08]])\n",
      ">>> clf.score(X, y)\n",
      "0.97...\n",
      "\n",
      "For a comaprison of the LogisticRegression with other classifiers see:\n",
      ":ref:`sphx_glr_auto_examples_classification_plot_classification_probability.py`.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     LogisticRegressionCV"
     ]
    }
   ],
   "source": [
    "?LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000, random_state=0)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(random_state=0, max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.88506747e-03, 2.38945568e-03, 1.79349443e-07, 1.53497324e-04,\n",
       "       3.40394634e-05])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_lr = lr.predict_proba(X_train)[:,1]\n",
    "y_train_lr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.66891213e-04, 3.96809830e-05, 9.91983520e-01, 7.33617668e-04,\n",
       "       8.60238431e-05])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_lr = lr.predict_proba(X_test)[:,1]\n",
    "y_train_lr[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision, Recall, F1, Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, f1_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ConfusionMatrixDisplay',\n",
       " 'DetCurveDisplay',\n",
       " 'DistanceMetric',\n",
       " 'PrecisionRecallDisplay',\n",
       " 'PredictionErrorDisplay',\n",
       " 'RocCurveDisplay',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_base',\n",
       " '_classification',\n",
       " '_dist_metrics',\n",
       " '_pairwise_distances_reduction',\n",
       " '_pairwise_fast',\n",
       " '_plot',\n",
       " '_ranking',\n",
       " '_regression',\n",
       " '_scorer',\n",
       " 'accuracy_score',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'auc',\n",
       " 'average_precision_score',\n",
       " 'balanced_accuracy_score',\n",
       " 'brier_score_loss',\n",
       " 'calinski_harabasz_score',\n",
       " 'check_scoring',\n",
       " 'class_likelihood_ratios',\n",
       " 'classification_report',\n",
       " 'cluster',\n",
       " 'cohen_kappa_score',\n",
       " 'completeness_score',\n",
       " 'confusion_matrix',\n",
       " 'consensus_score',\n",
       " 'coverage_error',\n",
       " 'd2_absolute_error_score',\n",
       " 'd2_log_loss_score',\n",
       " 'd2_pinball_score',\n",
       " 'd2_tweedie_score',\n",
       " 'davies_bouldin_score',\n",
       " 'dcg_score',\n",
       " 'det_curve',\n",
       " 'euclidean_distances',\n",
       " 'explained_variance_score',\n",
       " 'f1_score',\n",
       " 'fbeta_score',\n",
       " 'fowlkes_mallows_score',\n",
       " 'get_scorer',\n",
       " 'get_scorer_names',\n",
       " 'hamming_loss',\n",
       " 'hinge_loss',\n",
       " 'homogeneity_completeness_v_measure',\n",
       " 'homogeneity_score',\n",
       " 'jaccard_score',\n",
       " 'label_ranking_average_precision_score',\n",
       " 'label_ranking_loss',\n",
       " 'log_loss',\n",
       " 'make_scorer',\n",
       " 'matthews_corrcoef',\n",
       " 'max_error',\n",
       " 'mean_absolute_error',\n",
       " 'mean_absolute_percentage_error',\n",
       " 'mean_gamma_deviance',\n",
       " 'mean_pinball_loss',\n",
       " 'mean_poisson_deviance',\n",
       " 'mean_squared_error',\n",
       " 'mean_squared_log_error',\n",
       " 'mean_tweedie_deviance',\n",
       " 'median_absolute_error',\n",
       " 'multilabel_confusion_matrix',\n",
       " 'mutual_info_score',\n",
       " 'nan_euclidean_distances',\n",
       " 'ndcg_score',\n",
       " 'normalized_mutual_info_score',\n",
       " 'pair_confusion_matrix',\n",
       " 'pairwise',\n",
       " 'pairwise_distances',\n",
       " 'pairwise_distances_argmin',\n",
       " 'pairwise_distances_argmin_min',\n",
       " 'pairwise_distances_chunked',\n",
       " 'pairwise_kernels',\n",
       " 'precision_recall_curve',\n",
       " 'precision_recall_fscore_support',\n",
       " 'precision_score',\n",
       " 'r2_score',\n",
       " 'rand_score',\n",
       " 'recall_score',\n",
       " 'roc_auc_score',\n",
       " 'roc_curve',\n",
       " 'root_mean_squared_error',\n",
       " 'root_mean_squared_log_error',\n",
       " 'silhouette_samples',\n",
       " 'silhouette_score',\n",
       " 'top_k_accuracy_score',\n",
       " 'v_measure_score',\n",
       " 'zero_one_loss']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package sklearn.metrics in sklearn:\n",
      "\n",
      "NAME\n",
      "    sklearn.metrics - Score functions, performance metrics, pairwise metrics and distance computations.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _base\n",
      "    _classification\n",
      "    _dist_metrics\n",
      "    _pairwise_distances_reduction (package)\n",
      "    _pairwise_fast\n",
      "    _plot (package)\n",
      "    _ranking\n",
      "    _regression\n",
      "    _scorer\n",
      "    cluster (package)\n",
      "    pairwise\n",
      "    tests (package)\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        sklearn.metrics._dist_metrics.DistanceMetric\n",
      "        sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay\n",
      "        sklearn.metrics._plot.regression.PredictionErrorDisplay\n",
      "    sklearn.utils._plotting._BinaryClassifierCurveDisplayMixin(builtins.object)\n",
      "        sklearn.metrics._plot.det_curve.DetCurveDisplay\n",
      "        sklearn.metrics._plot.precision_recall_curve.PrecisionRecallDisplay\n",
      "        sklearn.metrics._plot.roc_curve.RocCurveDisplay\n",
      "    \n",
      "    class ConfusionMatrixDisplay(builtins.object)\n",
      "     |  ConfusionMatrixDisplay(confusion_matrix, *, display_labels=None)\n",
      "     |  \n",
      "     |  Confusion Matrix visualization.\n",
      "     |  \n",
      "     |  It is recommend to use\n",
      "     |  :func:`~sklearn.metrics.ConfusionMatrixDisplay.from_estimator` or\n",
      "     |  :func:`~sklearn.metrics.ConfusionMatrixDisplay.from_predictions` to\n",
      "     |  create a :class:`ConfusionMatrixDisplay`. All parameters are stored as\n",
      "     |  attributes.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <visualizations>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  confusion_matrix : ndarray of shape (n_classes, n_classes)\n",
      "     |      Confusion matrix.\n",
      "     |  \n",
      "     |  display_labels : ndarray of shape (n_classes,), default=None\n",
      "     |      Display labels for plot. If None, display labels are set from 0 to\n",
      "     |      `n_classes - 1`.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  im_ : matplotlib AxesImage\n",
      "     |      Image representing the confusion matrix.\n",
      "     |  \n",
      "     |  text_ : ndarray of shape (n_classes, n_classes), dtype=matplotlib Text,             or None\n",
      "     |      Array of matplotlib axes. `None` if `include_values` is false.\n",
      "     |  \n",
      "     |  ax_ : matplotlib Axes\n",
      "     |      Axes with confusion matrix.\n",
      "     |  \n",
      "     |  figure_ : matplotlib Figure\n",
      "     |      Figure containing the confusion matrix.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  confusion_matrix : Compute Confusion Matrix to evaluate the accuracy of a\n",
      "     |      classification.\n",
      "     |  ConfusionMatrixDisplay.from_estimator : Plot the confusion matrix\n",
      "     |      given an estimator, the data, and the label.\n",
      "     |  ConfusionMatrixDisplay.from_predictions : Plot the confusion matrix\n",
      "     |      given the true and predicted labels.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import matplotlib.pyplot as plt\n",
      "     |  >>> from sklearn.datasets import make_classification\n",
      "     |  >>> from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
      "     |  >>> from sklearn.model_selection import train_test_split\n",
      "     |  >>> from sklearn.svm import SVC\n",
      "     |  >>> X, y = make_classification(random_state=0)\n",
      "     |  >>> X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
      "     |  ...                                                     random_state=0)\n",
      "     |  >>> clf = SVC(random_state=0)\n",
      "     |  >>> clf.fit(X_train, y_train)\n",
      "     |  SVC(random_state=0)\n",
      "     |  >>> predictions = clf.predict(X_test)\n",
      "     |  >>> cm = confusion_matrix(y_test, predictions, labels=clf.classes_)\n",
      "     |  >>> disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
      "     |  ...                               display_labels=clf.classes_)\n",
      "     |  >>> disp.plot()\n",
      "     |  <...>\n",
      "     |  >>> plt.show()\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, confusion_matrix, *, display_labels=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  plot(self, *, include_values=True, cmap='viridis', xticks_rotation='horizontal', values_format=None, ax=None, colorbar=True, im_kw=None, text_kw=None)\n",
      "     |      Plot visualization.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      include_values : bool, default=True\n",
      "     |          Includes values in confusion matrix.\n",
      "     |      \n",
      "     |      cmap : str or matplotlib Colormap, default='viridis'\n",
      "     |          Colormap recognized by matplotlib.\n",
      "     |      \n",
      "     |      xticks_rotation : {'vertical', 'horizontal'} or float,                          default='horizontal'\n",
      "     |          Rotation of xtick labels.\n",
      "     |      \n",
      "     |      values_format : str, default=None\n",
      "     |          Format specification for values in confusion matrix. If `None`,\n",
      "     |          the format specification is 'd' or '.2g' whichever is shorter.\n",
      "     |      \n",
      "     |      ax : matplotlib axes, default=None\n",
      "     |          Axes object to plot on. If `None`, a new figure and axes is\n",
      "     |          created.\n",
      "     |      \n",
      "     |      colorbar : bool, default=True\n",
      "     |          Whether or not to add a colorbar to the plot.\n",
      "     |      \n",
      "     |      im_kw : dict, default=None\n",
      "     |          Dict with keywords passed to `matplotlib.pyplot.imshow` call.\n",
      "     |      \n",
      "     |      text_kw : dict, default=None\n",
      "     |          Dict with keywords passed to `matplotlib.pyplot.text` call.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.2\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      display : :class:`~sklearn.metrics.ConfusionMatrixDisplay`\n",
      "     |          Returns a :class:`~sklearn.metrics.ConfusionMatrixDisplay` instance\n",
      "     |          that contains all the information to plot the confusion matrix.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_estimator(estimator, X, y, *, labels=None, sample_weight=None, normalize=None, display_labels=None, include_values=True, xticks_rotation='horizontal', values_format=None, cmap='viridis', ax=None, colorbar=True, im_kw=None, text_kw=None) from builtins.type\n",
      "     |      Plot Confusion Matrix given an estimator and some data.\n",
      "     |      \n",
      "     |      Read more in the :ref:`User Guide <confusion_matrix>`.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      estimator : estimator instance\n",
      "     |          Fitted classifier or a fitted :class:`~sklearn.pipeline.Pipeline`\n",
      "     |          in which the last estimator is a classifier.\n",
      "     |      \n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Input values.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |      \n",
      "     |      labels : array-like of shape (n_classes,), default=None\n",
      "     |          List of labels to index the confusion matrix. This may be used to\n",
      "     |          reorder or select a subset of labels. If `None` is given, those\n",
      "     |          that appear at least once in `y_true` or `y_pred` are used in\n",
      "     |          sorted order.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      normalize : {'true', 'pred', 'all'}, default=None\n",
      "     |          Either to normalize the counts display in the matrix:\n",
      "     |      \n",
      "     |          - if `'true'`, the confusion matrix is normalized over the true\n",
      "     |            conditions (e.g. rows);\n",
      "     |          - if `'pred'`, the confusion matrix is normalized over the\n",
      "     |            predicted conditions (e.g. columns);\n",
      "     |          - if `'all'`, the confusion matrix is normalized by the total\n",
      "     |            number of samples;\n",
      "     |          - if `None` (default), the confusion matrix will not be normalized.\n",
      "     |      \n",
      "     |      display_labels : array-like of shape (n_classes,), default=None\n",
      "     |          Target names used for plotting. By default, `labels` will be used\n",
      "     |          if it is defined, otherwise the unique labels of `y_true` and\n",
      "     |          `y_pred` will be used.\n",
      "     |      \n",
      "     |      include_values : bool, default=True\n",
      "     |          Includes values in confusion matrix.\n",
      "     |      \n",
      "     |      xticks_rotation : {'vertical', 'horizontal'} or float,                 default='horizontal'\n",
      "     |          Rotation of xtick labels.\n",
      "     |      \n",
      "     |      values_format : str, default=None\n",
      "     |          Format specification for values in confusion matrix. If `None`, the\n",
      "     |          format specification is 'd' or '.2g' whichever is shorter.\n",
      "     |      \n",
      "     |      cmap : str or matplotlib Colormap, default='viridis'\n",
      "     |          Colormap recognized by matplotlib.\n",
      "     |      \n",
      "     |      ax : matplotlib Axes, default=None\n",
      "     |          Axes object to plot on. If `None`, a new figure and axes is\n",
      "     |          created.\n",
      "     |      \n",
      "     |      colorbar : bool, default=True\n",
      "     |          Whether or not to add a colorbar to the plot.\n",
      "     |      \n",
      "     |      im_kw : dict, default=None\n",
      "     |          Dict with keywords passed to `matplotlib.pyplot.imshow` call.\n",
      "     |      \n",
      "     |      text_kw : dict, default=None\n",
      "     |          Dict with keywords passed to `matplotlib.pyplot.text` call.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.2\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      display : :class:`~sklearn.metrics.ConfusionMatrixDisplay`\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      ConfusionMatrixDisplay.from_predictions : Plot the confusion matrix\n",
      "     |          given the true and predicted labels.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> from sklearn.datasets import make_classification\n",
      "     |      >>> from sklearn.metrics import ConfusionMatrixDisplay\n",
      "     |      >>> from sklearn.model_selection import train_test_split\n",
      "     |      >>> from sklearn.svm import SVC\n",
      "     |      >>> X, y = make_classification(random_state=0)\n",
      "     |      >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "     |      ...         X, y, random_state=0)\n",
      "     |      >>> clf = SVC(random_state=0)\n",
      "     |      >>> clf.fit(X_train, y_train)\n",
      "     |      SVC(random_state=0)\n",
      "     |      >>> ConfusionMatrixDisplay.from_estimator(\n",
      "     |      ...     clf, X_test, y_test)\n",
      "     |      <...>\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  from_predictions(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None, display_labels=None, include_values=True, xticks_rotation='horizontal', values_format=None, cmap='viridis', ax=None, colorbar=True, im_kw=None, text_kw=None) from builtins.type\n",
      "     |      Plot Confusion Matrix given true and predicted labels.\n",
      "     |      \n",
      "     |      Read more in the :ref:`User Guide <confusion_matrix>`.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      y_true : array-like of shape (n_samples,)\n",
      "     |          True labels.\n",
      "     |      \n",
      "     |      y_pred : array-like of shape (n_samples,)\n",
      "     |          The predicted labels given by the method `predict` of an\n",
      "     |          classifier.\n",
      "     |      \n",
      "     |      labels : array-like of shape (n_classes,), default=None\n",
      "     |          List of labels to index the confusion matrix. This may be used to\n",
      "     |          reorder or select a subset of labels. If `None` is given, those\n",
      "     |          that appear at least once in `y_true` or `y_pred` are used in\n",
      "     |          sorted order.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      normalize : {'true', 'pred', 'all'}, default=None\n",
      "     |          Either to normalize the counts display in the matrix:\n",
      "     |      \n",
      "     |          - if `'true'`, the confusion matrix is normalized over the true\n",
      "     |            conditions (e.g. rows);\n",
      "     |          - if `'pred'`, the confusion matrix is normalized over the\n",
      "     |            predicted conditions (e.g. columns);\n",
      "     |          - if `'all'`, the confusion matrix is normalized by the total\n",
      "     |            number of samples;\n",
      "     |          - if `None` (default), the confusion matrix will not be normalized.\n",
      "     |      \n",
      "     |      display_labels : array-like of shape (n_classes,), default=None\n",
      "     |          Target names used for plotting. By default, `labels` will be used\n",
      "     |          if it is defined, otherwise the unique labels of `y_true` and\n",
      "     |          `y_pred` will be used.\n",
      "     |      \n",
      "     |      include_values : bool, default=True\n",
      "     |          Includes values in confusion matrix.\n",
      "     |      \n",
      "     |      xticks_rotation : {'vertical', 'horizontal'} or float,                 default='horizontal'\n",
      "     |          Rotation of xtick labels.\n",
      "     |      \n",
      "     |      values_format : str, default=None\n",
      "     |          Format specification for values in confusion matrix. If `None`, the\n",
      "     |          format specification is 'd' or '.2g' whichever is shorter.\n",
      "     |      \n",
      "     |      cmap : str or matplotlib Colormap, default='viridis'\n",
      "     |          Colormap recognized by matplotlib.\n",
      "     |      \n",
      "     |      ax : matplotlib Axes, default=None\n",
      "     |          Axes object to plot on. If `None`, a new figure and axes is\n",
      "     |          created.\n",
      "     |      \n",
      "     |      colorbar : bool, default=True\n",
      "     |          Whether or not to add a colorbar to the plot.\n",
      "     |      \n",
      "     |      im_kw : dict, default=None\n",
      "     |          Dict with keywords passed to `matplotlib.pyplot.imshow` call.\n",
      "     |      \n",
      "     |      text_kw : dict, default=None\n",
      "     |          Dict with keywords passed to `matplotlib.pyplot.text` call.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.2\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      display : :class:`~sklearn.metrics.ConfusionMatrixDisplay`\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      ConfusionMatrixDisplay.from_estimator : Plot the confusion matrix\n",
      "     |          given an estimator, the data, and the label.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> from sklearn.datasets import make_classification\n",
      "     |      >>> from sklearn.metrics import ConfusionMatrixDisplay\n",
      "     |      >>> from sklearn.model_selection import train_test_split\n",
      "     |      >>> from sklearn.svm import SVC\n",
      "     |      >>> X, y = make_classification(random_state=0)\n",
      "     |      >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "     |      ...         X, y, random_state=0)\n",
      "     |      >>> clf = SVC(random_state=0)\n",
      "     |      >>> clf.fit(X_train, y_train)\n",
      "     |      SVC(random_state=0)\n",
      "     |      >>> y_pred = clf.predict(X_test)\n",
      "     |      >>> ConfusionMatrixDisplay.from_predictions(\n",
      "     |      ...    y_test, y_pred)\n",
      "     |      <...>\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class DetCurveDisplay(sklearn.utils._plotting._BinaryClassifierCurveDisplayMixin)\n",
      "     |  DetCurveDisplay(*, fpr, fnr, estimator_name=None, pos_label=None)\n",
      "     |  \n",
      "     |  DET curve visualization.\n",
      "     |  \n",
      "     |  It is recommend to use :func:`~sklearn.metrics.DetCurveDisplay.from_estimator`\n",
      "     |  or :func:`~sklearn.metrics.DetCurveDisplay.from_predictions` to create a\n",
      "     |  visualizer. All parameters are stored as attributes.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <visualizations>`.\n",
      "     |  \n",
      "     |  .. versionadded:: 0.24\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  fpr : ndarray\n",
      "     |      False positive rate.\n",
      "     |  \n",
      "     |  fnr : ndarray\n",
      "     |      False negative rate.\n",
      "     |  \n",
      "     |  estimator_name : str, default=None\n",
      "     |      Name of estimator. If None, the estimator name is not shown.\n",
      "     |  \n",
      "     |  pos_label : int, float, bool or str, default=None\n",
      "     |      The label of the positive class.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  line_ : matplotlib Artist\n",
      "     |      DET Curve.\n",
      "     |  \n",
      "     |  ax_ : matplotlib Axes\n",
      "     |      Axes with DET Curve.\n",
      "     |  \n",
      "     |  figure_ : matplotlib Figure\n",
      "     |      Figure containing the curve.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  det_curve : Compute error rates for different probability thresholds.\n",
      "     |  DetCurveDisplay.from_estimator : Plot DET curve given an estimator and\n",
      "     |      some data.\n",
      "     |  DetCurveDisplay.from_predictions : Plot DET curve given the true and\n",
      "     |      predicted labels.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import matplotlib.pyplot as plt\n",
      "     |  >>> from sklearn.datasets import make_classification\n",
      "     |  >>> from sklearn.metrics import det_curve, DetCurveDisplay\n",
      "     |  >>> from sklearn.model_selection import train_test_split\n",
      "     |  >>> from sklearn.svm import SVC\n",
      "     |  >>> X, y = make_classification(n_samples=1000, random_state=0)\n",
      "     |  >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "     |  ...     X, y, test_size=0.4, random_state=0)\n",
      "     |  >>> clf = SVC(random_state=0).fit(X_train, y_train)\n",
      "     |  >>> y_pred = clf.decision_function(X_test)\n",
      "     |  >>> fpr, fnr, _ = det_curve(y_test, y_pred)\n",
      "     |  >>> display = DetCurveDisplay(\n",
      "     |  ...     fpr=fpr, fnr=fnr, estimator_name=\"SVC\"\n",
      "     |  ... )\n",
      "     |  >>> display.plot()\n",
      "     |  <...>\n",
      "     |  >>> plt.show()\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      DetCurveDisplay\n",
      "     |      sklearn.utils._plotting._BinaryClassifierCurveDisplayMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, fpr, fnr, estimator_name=None, pos_label=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  plot(self, ax=None, *, name=None, **kwargs)\n",
      "     |      Plot visualization.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ax : matplotlib axes, default=None\n",
      "     |          Axes object to plot on. If `None`, a new figure and axes is\n",
      "     |          created.\n",
      "     |      \n",
      "     |      name : str, default=None\n",
      "     |          Name of DET curve for labeling. If `None`, use `estimator_name` if\n",
      "     |          it is not `None`, otherwise no labeling is shown.\n",
      "     |      \n",
      "     |      **kwargs : dict\n",
      "     |          Additional keywords arguments passed to matplotlib `plot` function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      display : :class:`~sklearn.metrics.DetCurveDisplay`\n",
      "     |          Object that stores computed values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_estimator(estimator, X, y, *, sample_weight=None, response_method='auto', pos_label=None, name=None, ax=None, **kwargs) from builtins.type\n",
      "     |      Plot DET curve given an estimator and data.\n",
      "     |      \n",
      "     |      Read more in the :ref:`User Guide <visualizations>`.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      estimator : estimator instance\n",
      "     |          Fitted classifier or a fitted :class:`~sklearn.pipeline.Pipeline`\n",
      "     |          in which the last estimator is a classifier.\n",
      "     |      \n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Input values.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      response_method : {'predict_proba', 'decision_function', 'auto'}                 default='auto'\n",
      "     |          Specifies whether to use :term:`predict_proba` or\n",
      "     |          :term:`decision_function` as the predicted target response. If set\n",
      "     |          to 'auto', :term:`predict_proba` is tried first and if it does not\n",
      "     |          exist :term:`decision_function` is tried next.\n",
      "     |      \n",
      "     |      pos_label : int, float, bool or str, default=None\n",
      "     |          The label of the positive class. When `pos_label=None`, if `y_true`\n",
      "     |          is in {-1, 1} or {0, 1}, `pos_label` is set to 1, otherwise an\n",
      "     |          error will be raised.\n",
      "     |      \n",
      "     |      name : str, default=None\n",
      "     |          Name of DET curve for labeling. If `None`, use the name of the\n",
      "     |          estimator.\n",
      "     |      \n",
      "     |      ax : matplotlib axes, default=None\n",
      "     |          Axes object to plot on. If `None`, a new figure and axes is\n",
      "     |          created.\n",
      "     |      \n",
      "     |      **kwargs : dict\n",
      "     |          Additional keywords arguments passed to matplotlib `plot` function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      display : :class:`~sklearn.metrics.DetCurveDisplay`\n",
      "     |          Object that stores computed values.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      det_curve : Compute error rates for different probability thresholds.\n",
      "     |      DetCurveDisplay.from_predictions : Plot DET curve given the true and\n",
      "     |          predicted labels.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> from sklearn.datasets import make_classification\n",
      "     |      >>> from sklearn.metrics import DetCurveDisplay\n",
      "     |      >>> from sklearn.model_selection import train_test_split\n",
      "     |      >>> from sklearn.svm import SVC\n",
      "     |      >>> X, y = make_classification(n_samples=1000, random_state=0)\n",
      "     |      >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "     |      ...     X, y, test_size=0.4, random_state=0)\n",
      "     |      >>> clf = SVC(random_state=0).fit(X_train, y_train)\n",
      "     |      >>> DetCurveDisplay.from_estimator(\n",
      "     |      ...    clf, X_test, y_test)\n",
      "     |      <...>\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  from_predictions(y_true, y_pred, *, sample_weight=None, pos_label=None, name=None, ax=None, **kwargs) from builtins.type\n",
      "     |      Plot the DET curve given the true and predicted labels.\n",
      "     |      \n",
      "     |      Read more in the :ref:`User Guide <visualizations>`.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      y_true : array-like of shape (n_samples,)\n",
      "     |          True labels.\n",
      "     |      \n",
      "     |      y_pred : array-like of shape (n_samples,)\n",
      "     |          Target scores, can either be probability estimates of the positive\n",
      "     |          class, confidence values, or non-thresholded measure of decisions\n",
      "     |          (as returned by `decision_function` on some classifiers).\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      pos_label : int, float, bool or str, default=None\n",
      "     |          The label of the positive class. When `pos_label=None`, if `y_true`\n",
      "     |          is in {-1, 1} or {0, 1}, `pos_label` is set to 1, otherwise an\n",
      "     |          error will be raised.\n",
      "     |      \n",
      "     |      name : str, default=None\n",
      "     |          Name of DET curve for labeling. If `None`, name will be set to\n",
      "     |          `\"Classifier\"`.\n",
      "     |      \n",
      "     |      ax : matplotlib axes, default=None\n",
      "     |          Axes object to plot on. If `None`, a new figure and axes is\n",
      "     |          created.\n",
      "     |      \n",
      "     |      **kwargs : dict\n",
      "     |          Additional keywords arguments passed to matplotlib `plot` function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      display : :class:`~sklearn.metrics.DetCurveDisplay`\n",
      "     |          Object that stores computed values.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      det_curve : Compute error rates for different probability thresholds.\n",
      "     |      DetCurveDisplay.from_estimator : Plot DET curve given an estimator and\n",
      "     |          some data.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> from sklearn.datasets import make_classification\n",
      "     |      >>> from sklearn.metrics import DetCurveDisplay\n",
      "     |      >>> from sklearn.model_selection import train_test_split\n",
      "     |      >>> from sklearn.svm import SVC\n",
      "     |      >>> X, y = make_classification(n_samples=1000, random_state=0)\n",
      "     |      >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "     |      ...     X, y, test_size=0.4, random_state=0)\n",
      "     |      >>> clf = SVC(random_state=0).fit(X_train, y_train)\n",
      "     |      >>> y_pred = clf.decision_function(X_test)\n",
      "     |      >>> DetCurveDisplay.from_predictions(\n",
      "     |      ...    y_test, y_pred)\n",
      "     |      <...>\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.utils._plotting._BinaryClassifierCurveDisplayMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class DistanceMetric(builtins.object)\n",
      "     |  Uniform interface for fast distance metric functions.\n",
      "     |  \n",
      "     |  The `DistanceMetric` class provides a convenient way to compute pairwise distances\n",
      "     |  between samples. It supports various distance metrics, such as Euclidean distance,\n",
      "     |  Manhattan distance, and more.\n",
      "     |  \n",
      "     |  The `pairwise` method can be used to compute pairwise distances between samples in\n",
      "     |  the input arrays. It returns a distance matrix representing the distances between\n",
      "     |  all pairs of samples.\n",
      "     |  \n",
      "     |  The :meth:`get_metric` method allows you to retrieve a specific metric using its\n",
      "     |  string identifier.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.metrics import DistanceMetric\n",
      "     |  >>> dist = DistanceMetric.get_metric('euclidean')\n",
      "     |  >>> X = [[1, 2], [3, 4], [5, 6]]\n",
      "     |  >>> Y = [[7, 8], [9, 10]]\n",
      "     |  >>> dist.pairwise(X,Y)\n",
      "     |  array([[7.81..., 10.63...]\n",
      "     |         [5.65...,  8.48...]\n",
      "     |         [1.41...,  4.24...]])\n",
      "     |  \n",
      "     |  .. rubric:: Available Metrics\n",
      "     |  \n",
      "     |  The following lists the string metric identifiers and the associated\n",
      "     |  distance metric classes:\n",
      "     |  \n",
      "     |  **Metrics intended for real-valued vector spaces:**\n",
      "     |  \n",
      "     |  ==============  ====================  ========  ===============================\n",
      "     |  identifier      class name            args      distance function\n",
      "     |  --------------  --------------------  --------  -------------------------------\n",
      "     |  \"euclidean\"     EuclideanDistance     -         ``sqrt(sum((x - y)^2))``\n",
      "     |  \"manhattan\"     ManhattanDistance     -         ``sum(|x - y|)``\n",
      "     |  \"chebyshev\"     ChebyshevDistance     -         ``max(|x - y|)``\n",
      "     |  \"minkowski\"     MinkowskiDistance     p, w      ``sum(w * |x - y|^p)^(1/p)``\n",
      "     |  \"seuclidean\"    SEuclideanDistance    V         ``sqrt(sum((x - y)^2 / V))``\n",
      "     |  \"mahalanobis\"   MahalanobisDistance   V or VI   ``sqrt((x - y)' V^-1 (x - y))``\n",
      "     |  ==============  ====================  ========  ===============================\n",
      "     |  \n",
      "     |  **Metrics intended for two-dimensional vector spaces:**  Note that the haversine\n",
      "     |  distance metric requires data in the form of [latitude, longitude] and both\n",
      "     |  inputs and outputs are in units of radians.\n",
      "     |  \n",
      "     |  ============  ==================  ===============================================================\n",
      "     |  identifier    class name          distance function\n",
      "     |  ------------  ------------------  ---------------------------------------------------------------\n",
      "     |  \"haversine\"   HaversineDistance   ``2 arcsin(sqrt(sin^2(0.5*dx) + cos(x1)cos(x2)sin^2(0.5*dy)))``\n",
      "     |  ============  ==================  ===============================================================\n",
      "     |  \n",
      "     |  \n",
      "     |  **Metrics intended for integer-valued vector spaces:**  Though intended\n",
      "     |  for integer-valued vectors, these are also valid metrics in the case of\n",
      "     |  real-valued vectors.\n",
      "     |  \n",
      "     |  =============  ====================  ========================================\n",
      "     |  identifier     class name            distance function\n",
      "     |  -------------  --------------------  ----------------------------------------\n",
      "     |  \"hamming\"      HammingDistance       ``N_unequal(x, y) / N_tot``\n",
      "     |  \"canberra\"     CanberraDistance      ``sum(|x - y| / (|x| + |y|))``\n",
      "     |  \"braycurtis\"   BrayCurtisDistance    ``sum(|x - y|) / (sum(|x|) + sum(|y|))``\n",
      "     |  =============  ====================  ========================================\n",
      "     |  \n",
      "     |  **Metrics intended for boolean-valued vector spaces:**  Any nonzero entry\n",
      "     |  is evaluated to \"True\".  In the listings below, the following\n",
      "     |  abbreviations are used:\n",
      "     |  \n",
      "     |  - N: number of dimensions\n",
      "     |  - NTT: number of dims in which both values are True\n",
      "     |  - NTF: number of dims in which the first value is True, second is False\n",
      "     |  - NFT: number of dims in which the first value is False, second is True\n",
      "     |  - NFF: number of dims in which both values are False\n",
      "     |  - NNEQ: number of non-equal dimensions, NNEQ = NTF + NFT\n",
      "     |  - NNZ: number of nonzero dimensions, NNZ = NTF + NFT + NTT\n",
      "     |  \n",
      "     |  =================  =======================  ===============================\n",
      "     |  identifier         class name               distance function\n",
      "     |  -----------------  -----------------------  -------------------------------\n",
      "     |  \"jaccard\"          JaccardDistance          NNEQ / NNZ\n",
      "     |  \"matching\"         MatchingDistance         NNEQ / N\n",
      "     |  \"dice\"             DiceDistance             NNEQ / (NTT + NNZ)\n",
      "     |  \"kulsinski\"        KulsinskiDistance        (NNEQ + N - NTT) / (NNEQ + N)\n",
      "     |  \"rogerstanimoto\"   RogersTanimotoDistance   2 * NNEQ / (N + NNEQ)\n",
      "     |  \"russellrao\"       RussellRaoDistance       (N - NTT) / N\n",
      "     |  \"sokalmichener\"    SokalMichenerDistance    2 * NNEQ / (N + NNEQ)\n",
      "     |  \"sokalsneath\"      SokalSneathDistance      NNEQ / (NNEQ + 0.5 * NTT)\n",
      "     |  =================  =======================  ===============================\n",
      "     |  \n",
      "     |  **User-defined distance:**\n",
      "     |  \n",
      "     |  ===========    ===============    =======\n",
      "     |  identifier     class name         args\n",
      "     |  -----------    ---------------    -------\n",
      "     |  \"pyfunc\"       PyFuncDistance     func\n",
      "     |  ===========    ===============    =======\n",
      "     |  \n",
      "     |  Here ``func`` is a function which takes two one-dimensional numpy\n",
      "     |  arrays, and returns a distance.  Note that in order to be used within\n",
      "     |  the BallTree, the distance must be a true metric:\n",
      "     |  i.e. it must satisfy the following properties\n",
      "     |  \n",
      "     |  1) Non-negativity: d(x, y) >= 0\n",
      "     |  2) Identity: d(x, y) = 0 if and only if x == y\n",
      "     |  3) Symmetry: d(x, y) = d(y, x)\n",
      "     |  4) Triangle Inequality: d(x, y) + d(y, z) >= d(x, z)\n",
      "     |  \n",
      "     |  Because of the Python object overhead involved in calling the python\n",
      "     |  function, this will be fairly slow, but it will have the same\n",
      "     |  scaling as other distances.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |  \n",
      "     |  __reduce_cython__(self)\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |  \n",
      "     |  __setstate_cython__(self, __pyx_state)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  get_metric(metric, dtype=<class 'numpy.float64'>, **kwargs) from builtins.type\n",
      "     |      Get the given distance metric from the string identifier.\n",
      "     |      \n",
      "     |      See the docstring of DistanceMetric for a list of available metrics.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      metric : str or class name\n",
      "     |          The string identifier or class name of the desired distance metric.\n",
      "     |          See the documentation of the `DistanceMetric` class for a list of\n",
      "     |          available metrics.\n",
      "     |      \n",
      "     |      dtype : {np.float32, np.float64}, default=np.float64\n",
      "     |          The data type of the input on which the metric will be applied.\n",
      "     |          This affects the precision of the computed distances.\n",
      "     |          By default, it is set to `np.float64`.\n",
      "     |      \n",
      "     |      **kwargs\n",
      "     |          Additional keyword arguments that will be passed to the requested metric.\n",
      "     |          These arguments can be used to customize the behavior of the specific\n",
      "     |          metric.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      metric_obj : instance of the requested metric\n",
      "     |          An instance of the requested distance metric class.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "    \n",
      "    class PrecisionRecallDisplay(sklearn.utils._plotting._BinaryClassifierCurveDisplayMixin)\n",
      "     |  PrecisionRecallDisplay(precision, recall, *, average_precision=None, estimator_name=None, pos_label=None, prevalence_pos_label=None)\n",
      "     |  \n",
      "     |  Precision Recall visualization.\n",
      "     |  \n",
      "     |  It is recommend to use\n",
      "     |  :func:`~sklearn.metrics.PrecisionRecallDisplay.from_estimator` or\n",
      "     |  :func:`~sklearn.metrics.PrecisionRecallDisplay.from_predictions` to create\n",
      "     |  a :class:`~sklearn.metrics.PrecisionRecallDisplay`. All parameters are\n",
      "     |  stored as attributes.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <visualizations>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  precision : ndarray\n",
      "     |      Precision values.\n",
      "     |  \n",
      "     |  recall : ndarray\n",
      "     |      Recall values.\n",
      "     |  \n",
      "     |  average_precision : float, default=None\n",
      "     |      Average precision. If None, the average precision is not shown.\n",
      "     |  \n",
      "     |  estimator_name : str, default=None\n",
      "     |      Name of estimator. If None, then the estimator name is not shown.\n",
      "     |  \n",
      "     |  pos_label : int, float, bool or str, default=None\n",
      "     |      The class considered as the positive class. If None, the class will not\n",
      "     |      be shown in the legend.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.24\n",
      "     |  \n",
      "     |  prevalence_pos_label : float, default=None\n",
      "     |      The prevalence of the positive label. It is used for plotting the\n",
      "     |      chance level line. If None, the chance level line will not be plotted\n",
      "     |      even if `plot_chance_level` is set to True when plotting.\n",
      "     |  \n",
      "     |      .. versionadded:: 1.3\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  line_ : matplotlib Artist\n",
      "     |      Precision recall curve.\n",
      "     |  \n",
      "     |  chance_level_ : matplotlib Artist or None\n",
      "     |      The chance level line. It is `None` if the chance level is not plotted.\n",
      "     |  \n",
      "     |      .. versionadded:: 1.3\n",
      "     |  \n",
      "     |  ax_ : matplotlib Axes\n",
      "     |      Axes with precision recall curve.\n",
      "     |  \n",
      "     |  figure_ : matplotlib Figure\n",
      "     |      Figure containing the curve.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  precision_recall_curve : Compute precision-recall pairs for different\n",
      "     |      probability thresholds.\n",
      "     |  PrecisionRecallDisplay.from_estimator : Plot Precision Recall Curve given\n",
      "     |      a binary classifier.\n",
      "     |  PrecisionRecallDisplay.from_predictions : Plot Precision Recall Curve\n",
      "     |      using predictions from a binary classifier.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The average precision (cf. :func:`~sklearn.metrics.average_precision_score`) in\n",
      "     |  scikit-learn is computed without any interpolation. To be consistent with\n",
      "     |  this metric, the precision-recall curve is plotted without any\n",
      "     |  interpolation as well (step-wise style).\n",
      "     |  \n",
      "     |  You can change this style by passing the keyword argument\n",
      "     |  `drawstyle=\"default\"` in :meth:`plot`, :meth:`from_estimator`, or\n",
      "     |  :meth:`from_predictions`. However, the curve will not be strictly\n",
      "     |  consistent with the reported average precision.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import matplotlib.pyplot as plt\n",
      "     |  >>> from sklearn.datasets import make_classification\n",
      "     |  >>> from sklearn.metrics import (precision_recall_curve,\n",
      "     |  ...                              PrecisionRecallDisplay)\n",
      "     |  >>> from sklearn.model_selection import train_test_split\n",
      "     |  >>> from sklearn.svm import SVC\n",
      "     |  >>> X, y = make_classification(random_state=0)\n",
      "     |  >>> X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
      "     |  ...                                                     random_state=0)\n",
      "     |  >>> clf = SVC(random_state=0)\n",
      "     |  >>> clf.fit(X_train, y_train)\n",
      "     |  SVC(random_state=0)\n",
      "     |  >>> predictions = clf.predict(X_test)\n",
      "     |  >>> precision, recall, _ = precision_recall_curve(y_test, predictions)\n",
      "     |  >>> disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
      "     |  >>> disp.plot()\n",
      "     |  <...>\n",
      "     |  >>> plt.show()\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PrecisionRecallDisplay\n",
      "     |      sklearn.utils._plotting._BinaryClassifierCurveDisplayMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, precision, recall, *, average_precision=None, estimator_name=None, pos_label=None, prevalence_pos_label=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  plot(self, ax=None, *, name=None, plot_chance_level=False, chance_level_kw=None, despine=False, **kwargs)\n",
      "     |      Plot visualization.\n",
      "     |      \n",
      "     |      Extra keyword arguments will be passed to matplotlib's `plot`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ax : Matplotlib Axes, default=None\n",
      "     |          Axes object to plot on. If `None`, a new figure and axes is\n",
      "     |          created.\n",
      "     |      \n",
      "     |      name : str, default=None\n",
      "     |          Name of precision recall curve for labeling. If `None`, use\n",
      "     |          `estimator_name` if not `None`, otherwise no labeling is shown.\n",
      "     |      \n",
      "     |      plot_chance_level : bool, default=False\n",
      "     |          Whether to plot the chance level. The chance level is the prevalence\n",
      "     |          of the positive label computed from the data passed during\n",
      "     |          :meth:`from_estimator` or :meth:`from_predictions` call.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      chance_level_kw : dict, default=None\n",
      "     |          Keyword arguments to be passed to matplotlib's `plot` for rendering\n",
      "     |          the chance level line.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      despine : bool, default=False\n",
      "     |          Whether to remove the top and right spines from the plot.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.6\n",
      "     |      \n",
      "     |      **kwargs : dict\n",
      "     |          Keyword arguments to be passed to matplotlib's `plot`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      display : :class:`~sklearn.metrics.PrecisionRecallDisplay`\n",
      "     |          Object that stores computed values.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The average precision (cf. :func:`~sklearn.metrics.average_precision_score`)\n",
      "     |      in scikit-learn is computed without any interpolation. To be consistent\n",
      "     |      with this metric, the precision-recall curve is plotted without any\n",
      "     |      interpolation as well (step-wise style).\n",
      "     |      \n",
      "     |      You can change this style by passing the keyword argument\n",
      "     |      `drawstyle=\"default\"`. However, the curve will not be strictly\n",
      "     |      consistent with the reported average precision.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_estimator(estimator, X, y, *, sample_weight=None, pos_label=None, drop_intermediate=False, response_method='auto', name=None, ax=None, plot_chance_level=False, chance_level_kw=None, despine=False, **kwargs) from builtins.type\n",
      "     |      Plot precision-recall curve given an estimator and some data.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      estimator : estimator instance\n",
      "     |          Fitted classifier or a fitted :class:`~sklearn.pipeline.Pipeline`\n",
      "     |          in which the last estimator is a classifier.\n",
      "     |      \n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Input values.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      pos_label : int, float, bool or str, default=None\n",
      "     |          The class considered as the positive class when computing the\n",
      "     |          precision and recall metrics. By default, `estimators.classes_[1]`\n",
      "     |          is considered as the positive class.\n",
      "     |      \n",
      "     |      drop_intermediate : bool, default=False\n",
      "     |          Whether to drop some suboptimal thresholds which would not appear\n",
      "     |          on a plotted precision-recall curve. This is useful in order to\n",
      "     |          create lighter precision-recall curves.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      response_method : {'predict_proba', 'decision_function', 'auto'},             default='auto'\n",
      "     |          Specifies whether to use :term:`predict_proba` or\n",
      "     |          :term:`decision_function` as the target response. If set to 'auto',\n",
      "     |          :term:`predict_proba` is tried first and if it does not exist\n",
      "     |          :term:`decision_function` is tried next.\n",
      "     |      \n",
      "     |      name : str, default=None\n",
      "     |          Name for labeling curve. If `None`, no name is used.\n",
      "     |      \n",
      "     |      ax : matplotlib axes, default=None\n",
      "     |          Axes object to plot on. If `None`, a new figure and axes is created.\n",
      "     |      \n",
      "     |      plot_chance_level : bool, default=False\n",
      "     |          Whether to plot the chance level. The chance level is the prevalence\n",
      "     |          of the positive label computed from the data passed during\n",
      "     |          :meth:`from_estimator` or :meth:`from_predictions` call.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      chance_level_kw : dict, default=None\n",
      "     |          Keyword arguments to be passed to matplotlib's `plot` for rendering\n",
      "     |          the chance level line.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      despine : bool, default=False\n",
      "     |          Whether to remove the top and right spines from the plot.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.6\n",
      "     |      \n",
      "     |      **kwargs : dict\n",
      "     |          Keyword arguments to be passed to matplotlib's `plot`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      display : :class:`~sklearn.metrics.PrecisionRecallDisplay`\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      PrecisionRecallDisplay.from_predictions : Plot precision-recall curve\n",
      "     |          using estimated probabilities or output of decision function.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The average precision (cf. :func:`~sklearn.metrics.average_precision_score`)\n",
      "     |      in scikit-learn is computed without any interpolation. To be consistent\n",
      "     |      with this metric, the precision-recall curve is plotted without any\n",
      "     |      interpolation as well (step-wise style).\n",
      "     |      \n",
      "     |      You can change this style by passing the keyword argument\n",
      "     |      `drawstyle=\"default\"`. However, the curve will not be strictly\n",
      "     |      consistent with the reported average precision.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> from sklearn.datasets import make_classification\n",
      "     |      >>> from sklearn.metrics import PrecisionRecallDisplay\n",
      "     |      >>> from sklearn.model_selection import train_test_split\n",
      "     |      >>> from sklearn.linear_model import LogisticRegression\n",
      "     |      >>> X, y = make_classification(random_state=0)\n",
      "     |      >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "     |      ...         X, y, random_state=0)\n",
      "     |      >>> clf = LogisticRegression()\n",
      "     |      >>> clf.fit(X_train, y_train)\n",
      "     |      LogisticRegression()\n",
      "     |      >>> PrecisionRecallDisplay.from_estimator(\n",
      "     |      ...    clf, X_test, y_test)\n",
      "     |      <...>\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  from_predictions(y_true, y_pred, *, sample_weight=None, pos_label=None, drop_intermediate=False, name=None, ax=None, plot_chance_level=False, chance_level_kw=None, despine=False, **kwargs) from builtins.type\n",
      "     |      Plot precision-recall curve given binary class predictions.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      y_true : array-like of shape (n_samples,)\n",
      "     |          True binary labels.\n",
      "     |      \n",
      "     |      y_pred : array-like of shape (n_samples,)\n",
      "     |          Estimated probabilities or output of decision function.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      pos_label : int, float, bool or str, default=None\n",
      "     |          The class considered as the positive class when computing the\n",
      "     |          precision and recall metrics.\n",
      "     |      \n",
      "     |      drop_intermediate : bool, default=False\n",
      "     |          Whether to drop some suboptimal thresholds which would not appear\n",
      "     |          on a plotted precision-recall curve. This is useful in order to\n",
      "     |          create lighter precision-recall curves.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      name : str, default=None\n",
      "     |          Name for labeling curve. If `None`, name will be set to\n",
      "     |          `\"Classifier\"`.\n",
      "     |      \n",
      "     |      ax : matplotlib axes, default=None\n",
      "     |          Axes object to plot on. If `None`, a new figure and axes is created.\n",
      "     |      \n",
      "     |      plot_chance_level : bool, default=False\n",
      "     |          Whether to plot the chance level. The chance level is the prevalence\n",
      "     |          of the positive label computed from the data passed during\n",
      "     |          :meth:`from_estimator` or :meth:`from_predictions` call.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      chance_level_kw : dict, default=None\n",
      "     |          Keyword arguments to be passed to matplotlib's `plot` for rendering\n",
      "     |          the chance level line.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      despine : bool, default=False\n",
      "     |          Whether to remove the top and right spines from the plot.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.6\n",
      "     |      \n",
      "     |      **kwargs : dict\n",
      "     |          Keyword arguments to be passed to matplotlib's `plot`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      display : :class:`~sklearn.metrics.PrecisionRecallDisplay`\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      PrecisionRecallDisplay.from_estimator : Plot precision-recall curve\n",
      "     |          using an estimator.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The average precision (cf. :func:`~sklearn.metrics.average_precision_score`)\n",
      "     |      in scikit-learn is computed without any interpolation. To be consistent\n",
      "     |      with this metric, the precision-recall curve is plotted without any\n",
      "     |      interpolation as well (step-wise style).\n",
      "     |      \n",
      "     |      You can change this style by passing the keyword argument\n",
      "     |      `drawstyle=\"default\"`. However, the curve will not be strictly\n",
      "     |      consistent with the reported average precision.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> from sklearn.datasets import make_classification\n",
      "     |      >>> from sklearn.metrics import PrecisionRecallDisplay\n",
      "     |      >>> from sklearn.model_selection import train_test_split\n",
      "     |      >>> from sklearn.linear_model import LogisticRegression\n",
      "     |      >>> X, y = make_classification(random_state=0)\n",
      "     |      >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "     |      ...         X, y, random_state=0)\n",
      "     |      >>> clf = LogisticRegression()\n",
      "     |      >>> clf.fit(X_train, y_train)\n",
      "     |      LogisticRegression()\n",
      "     |      >>> y_pred = clf.predict_proba(X_test)[:, 1]\n",
      "     |      >>> PrecisionRecallDisplay.from_predictions(\n",
      "     |      ...    y_test, y_pred)\n",
      "     |      <...>\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.utils._plotting._BinaryClassifierCurveDisplayMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class PredictionErrorDisplay(builtins.object)\n",
      "     |  PredictionErrorDisplay(*, y_true, y_pred)\n",
      "     |  \n",
      "     |  Visualization of the prediction error of a regression model.\n",
      "     |  \n",
      "     |  This tool can display \"residuals vs predicted\" or \"actual vs predicted\"\n",
      "     |  using scatter plots to qualitatively assess the behavior of a regressor,\n",
      "     |  preferably on held-out data points.\n",
      "     |  \n",
      "     |  See the details in the docstrings of\n",
      "     |  :func:`~sklearn.metrics.PredictionErrorDisplay.from_estimator` or\n",
      "     |  :func:`~sklearn.metrics.PredictionErrorDisplay.from_predictions` to\n",
      "     |  create a visualizer. All parameters are stored as attributes.\n",
      "     |  \n",
      "     |  For general information regarding `scikit-learn` visualization tools, read\n",
      "     |  more in the :ref:`Visualization Guide <visualizations>`.\n",
      "     |  For details regarding interpreting these plots, refer to the\n",
      "     |  :ref:`Model Evaluation Guide <visualization_regression_evaluation>`.\n",
      "     |  \n",
      "     |  .. versionadded:: 1.2\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  y_true : ndarray of shape (n_samples,)\n",
      "     |      True values.\n",
      "     |  \n",
      "     |  y_pred : ndarray of shape (n_samples,)\n",
      "     |      Prediction values.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  line_ : matplotlib Artist\n",
      "     |      Optimal line representing `y_true == y_pred`. Therefore, it is a\n",
      "     |      diagonal line for `kind=\"predictions\"` and a horizontal line for\n",
      "     |      `kind=\"residuals\"`.\n",
      "     |  \n",
      "     |  errors_lines_ : matplotlib Artist or None\n",
      "     |      Residual lines. If `with_errors=False`, then it is set to `None`.\n",
      "     |  \n",
      "     |  scatter_ : matplotlib Artist\n",
      "     |      Scatter data points.\n",
      "     |  \n",
      "     |  ax_ : matplotlib Axes\n",
      "     |      Axes with the different matplotlib axis.\n",
      "     |  \n",
      "     |  figure_ : matplotlib Figure\n",
      "     |      Figure containing the scatter and lines.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  PredictionErrorDisplay.from_estimator : Prediction error visualization\n",
      "     |      given an estimator and some data.\n",
      "     |  PredictionErrorDisplay.from_predictions : Prediction error visualization\n",
      "     |      given the true and predicted targets.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import matplotlib.pyplot as plt\n",
      "     |  >>> from sklearn.datasets import load_diabetes\n",
      "     |  >>> from sklearn.linear_model import Ridge\n",
      "     |  >>> from sklearn.metrics import PredictionErrorDisplay\n",
      "     |  >>> X, y = load_diabetes(return_X_y=True)\n",
      "     |  >>> ridge = Ridge().fit(X, y)\n",
      "     |  >>> y_pred = ridge.predict(X)\n",
      "     |  >>> display = PredictionErrorDisplay(y_true=y, y_pred=y_pred)\n",
      "     |  >>> display.plot()\n",
      "     |  <...>\n",
      "     |  >>> plt.show()\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, y_true, y_pred)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  plot(self, ax=None, *, kind='residual_vs_predicted', scatter_kwargs=None, line_kwargs=None)\n",
      "     |      Plot visualization.\n",
      "     |      \n",
      "     |      Extra keyword arguments will be passed to matplotlib's ``plot``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ax : matplotlib axes, default=None\n",
      "     |          Axes object to plot on. If `None`, a new figure and axes is\n",
      "     |          created.\n",
      "     |      \n",
      "     |      kind : {\"actual_vs_predicted\", \"residual_vs_predicted\"},                 default=\"residual_vs_predicted\"\n",
      "     |          The type of plot to draw:\n",
      "     |      \n",
      "     |          - \"actual_vs_predicted\" draws the observed values (y-axis) vs.\n",
      "     |            the predicted values (x-axis).\n",
      "     |          - \"residual_vs_predicted\" draws the residuals, i.e. difference\n",
      "     |            between observed and predicted values, (y-axis) vs. the predicted\n",
      "     |            values (x-axis).\n",
      "     |      \n",
      "     |      scatter_kwargs : dict, default=None\n",
      "     |          Dictionary with keywords passed to the `matplotlib.pyplot.scatter`\n",
      "     |          call.\n",
      "     |      \n",
      "     |      line_kwargs : dict, default=None\n",
      "     |          Dictionary with keyword passed to the `matplotlib.pyplot.plot`\n",
      "     |          call to draw the optimal line.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      display : :class:`~sklearn.metrics.PredictionErrorDisplay`\n",
      "     |      \n",
      "     |          Object that stores computed values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_estimator(estimator, X, y, *, kind='residual_vs_predicted', subsample=1000, random_state=None, ax=None, scatter_kwargs=None, line_kwargs=None) from builtins.type\n",
      "     |      Plot the prediction error given a regressor and some data.\n",
      "     |      \n",
      "     |      For general information regarding `scikit-learn` visualization tools,\n",
      "     |      read more in the :ref:`Visualization Guide <visualizations>`.\n",
      "     |      For details regarding interpreting these plots, refer to the\n",
      "     |      :ref:`Model Evaluation Guide <visualization_regression_evaluation>`.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.2\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      estimator : estimator instance\n",
      "     |          Fitted regressor or a fitted :class:`~sklearn.pipeline.Pipeline`\n",
      "     |          in which the last estimator is a regressor.\n",
      "     |      \n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Input values.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |      \n",
      "     |      kind : {\"actual_vs_predicted\", \"residual_vs_predicted\"},                 default=\"residual_vs_predicted\"\n",
      "     |          The type of plot to draw:\n",
      "     |      \n",
      "     |          - \"actual_vs_predicted\" draws the observed values (y-axis) vs.\n",
      "     |            the predicted values (x-axis).\n",
      "     |          - \"residual_vs_predicted\" draws the residuals, i.e. difference\n",
      "     |            between observed and predicted values, (y-axis) vs. the predicted\n",
      "     |            values (x-axis).\n",
      "     |      \n",
      "     |      subsample : float, int or None, default=1_000\n",
      "     |          Sampling the samples to be shown on the scatter plot. If `float`,\n",
      "     |          it should be between 0 and 1 and represents the proportion of the\n",
      "     |          original dataset. If `int`, it represents the number of samples\n",
      "     |          display on the scatter plot. If `None`, no subsampling will be\n",
      "     |          applied. by default, 1000 samples or less will be displayed.\n",
      "     |      \n",
      "     |      random_state : int or RandomState, default=None\n",
      "     |          Controls the randomness when `subsample` is not `None`.\n",
      "     |          See :term:`Glossary <random_state>` for details.\n",
      "     |      \n",
      "     |      ax : matplotlib axes, default=None\n",
      "     |          Axes object to plot on. If `None`, a new figure and axes is\n",
      "     |          created.\n",
      "     |      \n",
      "     |      scatter_kwargs : dict, default=None\n",
      "     |          Dictionary with keywords passed to the `matplotlib.pyplot.scatter`\n",
      "     |          call.\n",
      "     |      \n",
      "     |      line_kwargs : dict, default=None\n",
      "     |          Dictionary with keyword passed to the `matplotlib.pyplot.plot`\n",
      "     |          call to draw the optimal line.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      display : :class:`~sklearn.metrics.PredictionErrorDisplay`\n",
      "     |          Object that stores the computed values.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      PredictionErrorDisplay : Prediction error visualization for regression.\n",
      "     |      PredictionErrorDisplay.from_predictions : Prediction error visualization\n",
      "     |          given the true and predicted targets.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> from sklearn.datasets import load_diabetes\n",
      "     |      >>> from sklearn.linear_model import Ridge\n",
      "     |      >>> from sklearn.metrics import PredictionErrorDisplay\n",
      "     |      >>> X, y = load_diabetes(return_X_y=True)\n",
      "     |      >>> ridge = Ridge().fit(X, y)\n",
      "     |      >>> disp = PredictionErrorDisplay.from_estimator(ridge, X, y)\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  from_predictions(y_true, y_pred, *, kind='residual_vs_predicted', subsample=1000, random_state=None, ax=None, scatter_kwargs=None, line_kwargs=None) from builtins.type\n",
      "     |      Plot the prediction error given the true and predicted targets.\n",
      "     |      \n",
      "     |      For general information regarding `scikit-learn` visualization tools,\n",
      "     |      read more in the :ref:`Visualization Guide <visualizations>`.\n",
      "     |      For details regarding interpreting these plots, refer to the\n",
      "     |      :ref:`Model Evaluation Guide <visualization_regression_evaluation>`.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.2\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      y_true : array-like of shape (n_samples,)\n",
      "     |          True target values.\n",
      "     |      \n",
      "     |      y_pred : array-like of shape (n_samples,)\n",
      "     |          Predicted target values.\n",
      "     |      \n",
      "     |      kind : {\"actual_vs_predicted\", \"residual_vs_predicted\"},                 default=\"residual_vs_predicted\"\n",
      "     |          The type of plot to draw:\n",
      "     |      \n",
      "     |          - \"actual_vs_predicted\" draws the observed values (y-axis) vs.\n",
      "     |            the predicted values (x-axis).\n",
      "     |          - \"residual_vs_predicted\" draws the residuals, i.e. difference\n",
      "     |            between observed and predicted values, (y-axis) vs. the predicted\n",
      "     |            values (x-axis).\n",
      "     |      \n",
      "     |      subsample : float, int or None, default=1_000\n",
      "     |          Sampling the samples to be shown on the scatter plot. If `float`,\n",
      "     |          it should be between 0 and 1 and represents the proportion of the\n",
      "     |          original dataset. If `int`, it represents the number of samples\n",
      "     |          display on the scatter plot. If `None`, no subsampling will be\n",
      "     |          applied. by default, 1000 samples or less will be displayed.\n",
      "     |      \n",
      "     |      random_state : int or RandomState, default=None\n",
      "     |          Controls the randomness when `subsample` is not `None`.\n",
      "     |          See :term:`Glossary <random_state>` for details.\n",
      "     |      \n",
      "     |      ax : matplotlib axes, default=None\n",
      "     |          Axes object to plot on. If `None`, a new figure and axes is\n",
      "     |          created.\n",
      "     |      \n",
      "     |      scatter_kwargs : dict, default=None\n",
      "     |          Dictionary with keywords passed to the `matplotlib.pyplot.scatter`\n",
      "     |          call.\n",
      "     |      \n",
      "     |      line_kwargs : dict, default=None\n",
      "     |          Dictionary with keyword passed to the `matplotlib.pyplot.plot`\n",
      "     |          call to draw the optimal line.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      display : :class:`~sklearn.metrics.PredictionErrorDisplay`\n",
      "     |          Object that stores the computed values.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      PredictionErrorDisplay : Prediction error visualization for regression.\n",
      "     |      PredictionErrorDisplay.from_estimator : Prediction error visualization\n",
      "     |          given an estimator and some data.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> from sklearn.datasets import load_diabetes\n",
      "     |      >>> from sklearn.linear_model import Ridge\n",
      "     |      >>> from sklearn.metrics import PredictionErrorDisplay\n",
      "     |      >>> X, y = load_diabetes(return_X_y=True)\n",
      "     |      >>> ridge = Ridge().fit(X, y)\n",
      "     |      >>> y_pred = ridge.predict(X)\n",
      "     |      >>> disp = PredictionErrorDisplay.from_predictions(y_true=y, y_pred=y_pred)\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class RocCurveDisplay(sklearn.utils._plotting._BinaryClassifierCurveDisplayMixin)\n",
      "     |  RocCurveDisplay(*, fpr, tpr, roc_auc=None, estimator_name=None, pos_label=None)\n",
      "     |  \n",
      "     |  ROC Curve visualization.\n",
      "     |  \n",
      "     |  It is recommend to use\n",
      "     |  :func:`~sklearn.metrics.RocCurveDisplay.from_estimator` or\n",
      "     |  :func:`~sklearn.metrics.RocCurveDisplay.from_predictions` to create\n",
      "     |  a :class:`~sklearn.metrics.RocCurveDisplay`. All parameters are\n",
      "     |  stored as attributes.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <visualizations>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  fpr : ndarray\n",
      "     |      False positive rate.\n",
      "     |  \n",
      "     |  tpr : ndarray\n",
      "     |      True positive rate.\n",
      "     |  \n",
      "     |  roc_auc : float, default=None\n",
      "     |      Area under ROC curve. If None, the roc_auc score is not shown.\n",
      "     |  \n",
      "     |  estimator_name : str, default=None\n",
      "     |      Name of estimator. If None, the estimator name is not shown.\n",
      "     |  \n",
      "     |  pos_label : int, float, bool or str, default=None\n",
      "     |      The class considered as the positive class when computing the roc auc\n",
      "     |      metrics. By default, `estimators.classes_[1]` is considered\n",
      "     |      as the positive class.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.24\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  line_ : matplotlib Artist\n",
      "     |      ROC Curve.\n",
      "     |  \n",
      "     |  chance_level_ : matplotlib Artist or None\n",
      "     |      The chance level line. It is `None` if the chance level is not plotted.\n",
      "     |  \n",
      "     |      .. versionadded:: 1.3\n",
      "     |  \n",
      "     |  ax_ : matplotlib Axes\n",
      "     |      Axes with ROC Curve.\n",
      "     |  \n",
      "     |  figure_ : matplotlib Figure\n",
      "     |      Figure containing the curve.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  roc_curve : Compute Receiver operating characteristic (ROC) curve.\n",
      "     |  RocCurveDisplay.from_estimator : Plot Receiver Operating Characteristic\n",
      "     |      (ROC) curve given an estimator and some data.\n",
      "     |  RocCurveDisplay.from_predictions : Plot Receiver Operating Characteristic\n",
      "     |      (ROC) curve given the true and predicted values.\n",
      "     |  roc_auc_score : Compute the area under the ROC curve.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import matplotlib.pyplot as plt\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn import metrics\n",
      "     |  >>> y = np.array([0, 0, 1, 1])\n",
      "     |  >>> pred = np.array([0.1, 0.4, 0.35, 0.8])\n",
      "     |  >>> fpr, tpr, thresholds = metrics.roc_curve(y, pred)\n",
      "     |  >>> roc_auc = metrics.auc(fpr, tpr)\n",
      "     |  >>> display = metrics.RocCurveDisplay(fpr=fpr, tpr=tpr, roc_auc=roc_auc,\n",
      "     |  ...                                   estimator_name='example estimator')\n",
      "     |  >>> display.plot()\n",
      "     |  <...>\n",
      "     |  >>> plt.show()\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RocCurveDisplay\n",
      "     |      sklearn.utils._plotting._BinaryClassifierCurveDisplayMixin\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, fpr, tpr, roc_auc=None, estimator_name=None, pos_label=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  plot(self, ax=None, *, name=None, plot_chance_level=False, chance_level_kw=None, despine=False, **kwargs)\n",
      "     |      Plot visualization.\n",
      "     |      \n",
      "     |      Extra keyword arguments will be passed to matplotlib's ``plot``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ax : matplotlib axes, default=None\n",
      "     |          Axes object to plot on. If `None`, a new figure and axes is\n",
      "     |          created.\n",
      "     |      \n",
      "     |      name : str, default=None\n",
      "     |          Name of ROC Curve for labeling. If `None`, use `estimator_name` if\n",
      "     |          not `None`, otherwise no labeling is shown.\n",
      "     |      \n",
      "     |      plot_chance_level : bool, default=False\n",
      "     |          Whether to plot the chance level.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      chance_level_kw : dict, default=None\n",
      "     |          Keyword arguments to be passed to matplotlib's `plot` for rendering\n",
      "     |          the chance level line.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      despine : bool, default=False\n",
      "     |          Whether to remove the top and right spines from the plot.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.6\n",
      "     |      \n",
      "     |      **kwargs : dict\n",
      "     |          Keyword arguments to be passed to matplotlib's `plot`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      display : :class:`~sklearn.metrics.RocCurveDisplay`\n",
      "     |          Object that stores computed values.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_estimator(estimator, X, y, *, sample_weight=None, drop_intermediate=True, response_method='auto', pos_label=None, name=None, ax=None, plot_chance_level=False, chance_level_kw=None, despine=False, **kwargs) from builtins.type\n",
      "     |      Create a ROC Curve display from an estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      estimator : estimator instance\n",
      "     |          Fitted classifier or a fitted :class:`~sklearn.pipeline.Pipeline`\n",
      "     |          in which the last estimator is a classifier.\n",
      "     |      \n",
      "     |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "     |          Input values.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Target values.\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      drop_intermediate : bool, default=True\n",
      "     |          Whether to drop some suboptimal thresholds which would not appear\n",
      "     |          on a plotted ROC curve. This is useful in order to create lighter\n",
      "     |          ROC curves.\n",
      "     |      \n",
      "     |      response_method : {'predict_proba', 'decision_function', 'auto'}                 default='auto'\n",
      "     |          Specifies whether to use :term:`predict_proba` or\n",
      "     |          :term:`decision_function` as the target response. If set to 'auto',\n",
      "     |          :term:`predict_proba` is tried first and if it does not exist\n",
      "     |          :term:`decision_function` is tried next.\n",
      "     |      \n",
      "     |      pos_label : int, float, bool or str, default=None\n",
      "     |          The class considered as the positive class when computing the roc auc\n",
      "     |          metrics. By default, `estimators.classes_[1]` is considered\n",
      "     |          as the positive class.\n",
      "     |      \n",
      "     |      name : str, default=None\n",
      "     |          Name of ROC Curve for labeling. If `None`, use the name of the\n",
      "     |          estimator.\n",
      "     |      \n",
      "     |      ax : matplotlib axes, default=None\n",
      "     |          Axes object to plot on. If `None`, a new figure and axes is created.\n",
      "     |      \n",
      "     |      plot_chance_level : bool, default=False\n",
      "     |          Whether to plot the chance level.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      chance_level_kw : dict, default=None\n",
      "     |          Keyword arguments to be passed to matplotlib's `plot` for rendering\n",
      "     |          the chance level line.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      despine : bool, default=False\n",
      "     |          Whether to remove the top and right spines from the plot.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.6\n",
      "     |      \n",
      "     |      **kwargs : dict\n",
      "     |          Keyword arguments to be passed to matplotlib's `plot`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      display : :class:`~sklearn.metrics.RocCurveDisplay`\n",
      "     |          The ROC Curve display.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      roc_curve : Compute Receiver operating characteristic (ROC) curve.\n",
      "     |      RocCurveDisplay.from_predictions : ROC Curve visualization given the\n",
      "     |          probabilities of scores of a classifier.\n",
      "     |      roc_auc_score : Compute the area under the ROC curve.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> from sklearn.datasets import make_classification\n",
      "     |      >>> from sklearn.metrics import RocCurveDisplay\n",
      "     |      >>> from sklearn.model_selection import train_test_split\n",
      "     |      >>> from sklearn.svm import SVC\n",
      "     |      >>> X, y = make_classification(random_state=0)\n",
      "     |      >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "     |      ...     X, y, random_state=0)\n",
      "     |      >>> clf = SVC(random_state=0).fit(X_train, y_train)\n",
      "     |      >>> RocCurveDisplay.from_estimator(\n",
      "     |      ...    clf, X_test, y_test)\n",
      "     |      <...>\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  from_predictions(y_true, y_pred, *, sample_weight=None, drop_intermediate=True, pos_label=None, name=None, ax=None, plot_chance_level=False, chance_level_kw=None, despine=False, **kwargs) from builtins.type\n",
      "     |      Plot ROC curve given the true and predicted values.\n",
      "     |      \n",
      "     |      Read more in the :ref:`User Guide <visualizations>`.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      y_true : array-like of shape (n_samples,)\n",
      "     |          True labels.\n",
      "     |      \n",
      "     |      y_pred : array-like of shape (n_samples,)\n",
      "     |          Target scores, can either be probability estimates of the positive\n",
      "     |          class, confidence values, or non-thresholded measure of decisions\n",
      "     |          (as returned by “decision_function” on some classifiers).\n",
      "     |      \n",
      "     |      sample_weight : array-like of shape (n_samples,), default=None\n",
      "     |          Sample weights.\n",
      "     |      \n",
      "     |      drop_intermediate : bool, default=True\n",
      "     |          Whether to drop some suboptimal thresholds which would not appear\n",
      "     |          on a plotted ROC curve. This is useful in order to create lighter\n",
      "     |          ROC curves.\n",
      "     |      \n",
      "     |      pos_label : int, float, bool or str, default=None\n",
      "     |          The label of the positive class. When `pos_label=None`, if `y_true`\n",
      "     |          is in {-1, 1} or {0, 1}, `pos_label` is set to 1, otherwise an\n",
      "     |          error will be raised.\n",
      "     |      \n",
      "     |      name : str, default=None\n",
      "     |          Name of ROC curve for labeling. If `None`, name will be set to\n",
      "     |          `\"Classifier\"`.\n",
      "     |      \n",
      "     |      ax : matplotlib axes, default=None\n",
      "     |          Axes object to plot on. If `None`, a new figure and axes is\n",
      "     |          created.\n",
      "     |      \n",
      "     |      plot_chance_level : bool, default=False\n",
      "     |          Whether to plot the chance level.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      chance_level_kw : dict, default=None\n",
      "     |          Keyword arguments to be passed to matplotlib's `plot` for rendering\n",
      "     |          the chance level line.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.3\n",
      "     |      \n",
      "     |      despine : bool, default=False\n",
      "     |          Whether to remove the top and right spines from the plot.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.6\n",
      "     |      \n",
      "     |      **kwargs : dict\n",
      "     |          Additional keywords arguments passed to matplotlib `plot` function.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      display : :class:`~sklearn.metrics.RocCurveDisplay`\n",
      "     |          Object that stores computed values.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      roc_curve : Compute Receiver operating characteristic (ROC) curve.\n",
      "     |      RocCurveDisplay.from_estimator : ROC Curve visualization given an\n",
      "     |          estimator and some data.\n",
      "     |      roc_auc_score : Compute the area under the ROC curve.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> from sklearn.datasets import make_classification\n",
      "     |      >>> from sklearn.metrics import RocCurveDisplay\n",
      "     |      >>> from sklearn.model_selection import train_test_split\n",
      "     |      >>> from sklearn.svm import SVC\n",
      "     |      >>> X, y = make_classification(random_state=0)\n",
      "     |      >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "     |      ...     X, y, random_state=0)\n",
      "     |      >>> clf = SVC(random_state=0).fit(X_train, y_train)\n",
      "     |      >>> y_pred = clf.decision_function(X_test)\n",
      "     |      >>> RocCurveDisplay.from_predictions(\n",
      "     |      ...    y_test, y_pred)\n",
      "     |      <...>\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.utils._plotting._BinaryClassifierCurveDisplayMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None)\n",
      "        Accuracy classification score.\n",
      "        \n",
      "        In multilabel classification, this function computes subset accuracy:\n",
      "        the set of labels predicted for a sample must *exactly* match the\n",
      "        corresponding set of labels in y_true.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <accuracy_score>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "            Ground truth (correct) labels.\n",
      "        \n",
      "        y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "            Predicted labels, as returned by a classifier.\n",
      "        \n",
      "        normalize : bool, default=True\n",
      "            If ``False``, return the number of correctly classified samples.\n",
      "            Otherwise, return the fraction of correctly classified samples.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        score : float or int\n",
      "            If ``normalize == True``, return the fraction of correctly\n",
      "            classified samples (float), else returns the number of correctly\n",
      "            classified samples (int).\n",
      "        \n",
      "            The best performance is 1 with ``normalize == True`` and the number\n",
      "            of samples with ``normalize == False``.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        balanced_accuracy_score : Compute the balanced accuracy to deal with\n",
      "            imbalanced datasets.\n",
      "        jaccard_score : Compute the Jaccard similarity coefficient score.\n",
      "        hamming_loss : Compute the average Hamming loss or Hamming distance between\n",
      "            two sets of samples.\n",
      "        zero_one_loss : Compute the Zero-one classification loss. By default, the\n",
      "            function will return the percentage of imperfectly predicted subsets.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import accuracy_score\n",
      "        >>> y_pred = [0, 2, 1, 3]\n",
      "        >>> y_true = [0, 1, 2, 3]\n",
      "        >>> accuracy_score(y_true, y_pred)\n",
      "        0.5\n",
      "        >>> accuracy_score(y_true, y_pred, normalize=False)\n",
      "        2.0\n",
      "        \n",
      "        In the multilabel case with binary label indicators:\n",
      "        \n",
      "        >>> import numpy as np\n",
      "        >>> accuracy_score(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))\n",
      "        0.5\n",
      "    \n",
      "    adjusted_mutual_info_score(labels_true, labels_pred, *, average_method='arithmetic')\n",
      "        Adjusted Mutual Information between two clusterings.\n",
      "        \n",
      "        Adjusted Mutual Information (AMI) is an adjustment of the Mutual\n",
      "        Information (MI) score to account for chance. It accounts for the fact that\n",
      "        the MI is generally higher for two clusterings with a larger number of\n",
      "        clusters, regardless of whether there is actually more information shared.\n",
      "        For two clusterings :math:`U` and :math:`V`, the AMI is given as::\n",
      "        \n",
      "            AMI(U, V) = [MI(U, V) - E(MI(U, V))] / [avg(H(U), H(V)) - E(MI(U, V))]\n",
      "        \n",
      "        This metric is independent of the absolute values of the labels:\n",
      "        a permutation of the class or cluster label values won't change the\n",
      "        score value in any way.\n",
      "        \n",
      "        This metric is furthermore symmetric: switching :math:`U` (``label_true``)\n",
      "        with :math:`V` (``labels_pred``) will return the same score value. This can\n",
      "        be useful to measure the agreement of two independent label assignments\n",
      "        strategies on the same dataset when the real ground truth is not known.\n",
      "        \n",
      "        Be mindful that this function is an order of magnitude slower than other\n",
      "        metrics, such as the Adjusted Rand Index.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <mutual_info_score>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        labels_true : int array-like of shape (n_samples,)\n",
      "            A clustering of the data into disjoint subsets, called :math:`U` in\n",
      "            the above formula.\n",
      "        \n",
      "        labels_pred : int array-like of shape (n_samples,)\n",
      "            A clustering of the data into disjoint subsets, called :math:`V` in\n",
      "            the above formula.\n",
      "        \n",
      "        average_method : {'min', 'geometric', 'arithmetic', 'max'}, default='arithmetic'\n",
      "            How to compute the normalizer in the denominator.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "            .. versionchanged:: 0.22\n",
      "               The default value of ``average_method`` changed from 'max' to\n",
      "               'arithmetic'.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ami: float (upperlimited by 1.0)\n",
      "           The AMI returns a value of 1 when the two partitions are identical\n",
      "           (ie perfectly matched). Random partitions (independent labellings) have\n",
      "           an expected AMI around 0 on average hence can be negative. The value is\n",
      "           in adjusted nats (based on the natural logarithm).\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        adjusted_rand_score : Adjusted Rand Index.\n",
      "        mutual_info_score : Mutual Information (not adjusted for chance).\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] `Vinh, Epps, and Bailey, (2010). Information Theoretic Measures for\n",
      "           Clusterings Comparison: Variants, Properties, Normalization and\n",
      "           Correction for Chance, JMLR\n",
      "           <http://jmlr.csail.mit.edu/papers/volume11/vinh10a/vinh10a.pdf>`_\n",
      "        \n",
      "        .. [2] `Wikipedia entry for the Adjusted Mutual Information\n",
      "           <https://en.wikipedia.org/wiki/Adjusted_Mutual_Information>`_\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        \n",
      "        Perfect labelings are both homogeneous and complete, hence have\n",
      "        score 1.0::\n",
      "        \n",
      "          >>> from sklearn.metrics.cluster import adjusted_mutual_info_score\n",
      "          >>> adjusted_mutual_info_score([0, 0, 1, 1], [0, 0, 1, 1])\n",
      "          ... # doctest: +SKIP\n",
      "          1.0\n",
      "          >>> adjusted_mutual_info_score([0, 0, 1, 1], [1, 1, 0, 0])\n",
      "          ... # doctest: +SKIP\n",
      "          1.0\n",
      "        \n",
      "        If classes members are completely split across different clusters,\n",
      "        the assignment is totally in-complete, hence the AMI is null::\n",
      "        \n",
      "          >>> adjusted_mutual_info_score([0, 0, 0, 0], [0, 1, 2, 3])\n",
      "          ... # doctest: +SKIP\n",
      "          0.0\n",
      "    \n",
      "    adjusted_rand_score(labels_true, labels_pred)\n",
      "        Rand index adjusted for chance.\n",
      "        \n",
      "        The Rand Index computes a similarity measure between two clusterings\n",
      "        by considering all pairs of samples and counting pairs that are\n",
      "        assigned in the same or different clusters in the predicted and\n",
      "        true clusterings.\n",
      "        \n",
      "        The raw RI score is then \"adjusted for chance\" into the ARI score\n",
      "        using the following scheme::\n",
      "        \n",
      "            ARI = (RI - Expected_RI) / (max(RI) - Expected_RI)\n",
      "        \n",
      "        The adjusted Rand index is thus ensured to have a value close to\n",
      "        0.0 for random labeling independently of the number of clusters and\n",
      "        samples and exactly 1.0 when the clusterings are identical (up to\n",
      "        a permutation). The adjusted Rand index is bounded below by -0.5 for\n",
      "        especially discordant clusterings.\n",
      "        \n",
      "        ARI is a symmetric measure::\n",
      "        \n",
      "            adjusted_rand_score(a, b) == adjusted_rand_score(b, a)\n",
      "        \n",
      "        Read more in the :ref:`User Guide <adjusted_rand_score>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        labels_true : array-like of shape (n_samples,), dtype=int\n",
      "            Ground truth class labels to be used as a reference.\n",
      "        \n",
      "        labels_pred : array-like of shape (n_samples,), dtype=int\n",
      "            Cluster labels to evaluate.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ARI : float\n",
      "           Similarity score between -0.5 and 1.0. Random labelings have an ARI\n",
      "           close to 0.0. 1.0 stands for perfect match.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        adjusted_mutual_info_score : Adjusted Mutual Information.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [Hubert1985] L. Hubert and P. Arabie, Comparing Partitions,\n",
      "          Journal of Classification 1985\n",
      "          https://link.springer.com/article/10.1007%2FBF01908075\n",
      "        \n",
      "        .. [Steinley2004] D. Steinley, Properties of the Hubert-Arabie\n",
      "          adjusted Rand index, Psychological Methods 2004\n",
      "        \n",
      "        .. [wk] https://en.wikipedia.org/wiki/Rand_index#Adjusted_Rand_index\n",
      "        \n",
      "        .. [Chacon] :doi:`Minimum adjusted Rand index for two clusterings of a given size,\n",
      "          2022, J. E. Chacón and A. I. Rastrojo <10.1007/s11634-022-00491-w>`\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Perfectly matching labelings have a score of 1 even\n",
      "        \n",
      "          >>> from sklearn.metrics.cluster import adjusted_rand_score\n",
      "          >>> adjusted_rand_score([0, 0, 1, 1], [0, 0, 1, 1])\n",
      "          1.0\n",
      "          >>> adjusted_rand_score([0, 0, 1, 1], [1, 1, 0, 0])\n",
      "          1.0\n",
      "        \n",
      "        Labelings that assign all classes members to the same clusters\n",
      "        are complete but may not always be pure, hence penalized::\n",
      "        \n",
      "          >>> adjusted_rand_score([0, 0, 1, 2], [0, 0, 1, 1])\n",
      "          0.57...\n",
      "        \n",
      "        ARI is symmetric, so labelings that have pure clusters with members\n",
      "        coming from the same classes but unnecessary splits are penalized::\n",
      "        \n",
      "          >>> adjusted_rand_score([0, 0, 1, 1], [0, 0, 1, 2])\n",
      "          0.57...\n",
      "        \n",
      "        If classes members are completely split across different clusters, the\n",
      "        assignment is totally incomplete, hence the ARI is very low::\n",
      "        \n",
      "          >>> adjusted_rand_score([0, 0, 0, 0], [0, 1, 2, 3])\n",
      "          0.0\n",
      "        \n",
      "        ARI may take a negative value for especially discordant labelings that\n",
      "        are a worse choice than the expected value of random labels::\n",
      "        \n",
      "          >>> adjusted_rand_score([0, 0, 1, 1], [0, 1, 0, 1])\n",
      "          -0.5\n",
      "        \n",
      "        See :ref:`sphx_glr_auto_examples_cluster_plot_adjusted_for_chance_measures.py`\n",
      "        for a more detailed example.\n",
      "    \n",
      "    auc(x, y)\n",
      "        Compute Area Under the Curve (AUC) using the trapezoidal rule.\n",
      "        \n",
      "        This is a general function, given points on a curve.  For computing the\n",
      "        area under the ROC-curve, see :func:`roc_auc_score`.  For an alternative\n",
      "        way to summarize a precision-recall curve, see\n",
      "        :func:`average_precision_score`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array-like of shape (n,)\n",
      "            X coordinates. These must be either monotonic increasing or monotonic\n",
      "            decreasing.\n",
      "        y : array-like of shape (n,)\n",
      "            Y coordinates.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        auc : float\n",
      "            Area Under the Curve.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        roc_auc_score : Compute the area under the ROC curve.\n",
      "        average_precision_score : Compute average precision from prediction scores.\n",
      "        precision_recall_curve : Compute precision-recall pairs for different\n",
      "            probability thresholds.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn import metrics\n",
      "        >>> y = np.array([1, 1, 2, 2])\n",
      "        >>> pred = np.array([0.1, 0.4, 0.35, 0.8])\n",
      "        >>> fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=2)\n",
      "        >>> metrics.auc(fpr, tpr)\n",
      "        np.float64(0.75)\n",
      "    \n",
      "    average_precision_score(y_true, y_score, *, average='macro', pos_label=1, sample_weight=None)\n",
      "        Compute average precision (AP) from prediction scores.\n",
      "        \n",
      "        AP summarizes a precision-recall curve as the weighted mean of precisions\n",
      "        achieved at each threshold, with the increase in recall from the previous\n",
      "        threshold used as the weight:\n",
      "        \n",
      "        .. math::\n",
      "            \\text{AP} = \\sum_n (R_n - R_{n-1}) P_n\n",
      "        \n",
      "        where :math:`P_n` and :math:`R_n` are the precision and recall at the nth\n",
      "        threshold [1]_. This implementation is not interpolated and is different\n",
      "        from computing the area under the precision-recall curve with the\n",
      "        trapezoidal rule, which uses linear interpolation and can be too\n",
      "        optimistic.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,) or (n_samples, n_classes)\n",
      "            True binary labels or binary label indicators.\n",
      "        \n",
      "        y_score : array-like of shape (n_samples,) or (n_samples, n_classes)\n",
      "            Target scores, can either be probability estimates of the positive\n",
      "            class, confidence values, or non-thresholded measure of decisions\n",
      "            (as returned by :term:`decision_function` on some classifiers).\n",
      "            For :term:`decision_function` scores, values greater than or equal to\n",
      "            zero should indicate the positive class.\n",
      "        \n",
      "        average : {'micro', 'samples', 'weighted', 'macro'} or None,             default='macro'\n",
      "            If ``None``, the scores for each class are returned. Otherwise,\n",
      "            this determines the type of averaging performed on the data:\n",
      "        \n",
      "            ``'micro'``:\n",
      "                Calculate metrics globally by considering each element of the label\n",
      "                indicator matrix as a label.\n",
      "            ``'macro'``:\n",
      "                Calculate metrics for each label, and find their unweighted\n",
      "                mean.  This does not take label imbalance into account.\n",
      "            ``'weighted'``:\n",
      "                Calculate metrics for each label, and find their average, weighted\n",
      "                by support (the number of true instances for each label).\n",
      "            ``'samples'``:\n",
      "                Calculate metrics for each instance, and find their average.\n",
      "        \n",
      "            Will be ignored when ``y_true`` is binary.\n",
      "        \n",
      "        pos_label : int, float, bool or str, default=1\n",
      "            The label of the positive class. Only applied to binary ``y_true``.\n",
      "            For multilabel-indicator ``y_true``, ``pos_label`` is fixed to 1.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        average_precision : float\n",
      "            Average precision score.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        roc_auc_score : Compute the area under the ROC curve.\n",
      "        precision_recall_curve : Compute precision-recall pairs for different\n",
      "            probability thresholds.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        .. versionchanged:: 0.19\n",
      "          Instead of linearly interpolating between operating points, precisions\n",
      "          are weighted by the change in recall since the last operating point.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] `Wikipedia entry for the Average precision\n",
      "               <https://en.wikipedia.org/w/index.php?title=Information_retrieval&\n",
      "               oldid=793358396#Average_precision>`_\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.metrics import average_precision_score\n",
      "        >>> y_true = np.array([0, 0, 1, 1])\n",
      "        >>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
      "        >>> average_precision_score(y_true, y_scores)\n",
      "        np.float64(0.83...)\n",
      "        >>> y_true = np.array([0, 0, 1, 1, 2, 2])\n",
      "        >>> y_scores = np.array([\n",
      "        ...     [0.7, 0.2, 0.1],\n",
      "        ...     [0.4, 0.3, 0.3],\n",
      "        ...     [0.1, 0.8, 0.1],\n",
      "        ...     [0.2, 0.3, 0.5],\n",
      "        ...     [0.4, 0.4, 0.2],\n",
      "        ...     [0.1, 0.2, 0.7],\n",
      "        ... ])\n",
      "        >>> average_precision_score(y_true, y_scores)\n",
      "        np.float64(0.77...)\n",
      "    \n",
      "    balanced_accuracy_score(y_true, y_pred, *, sample_weight=None, adjusted=False)\n",
      "        Compute the balanced accuracy.\n",
      "        \n",
      "        The balanced accuracy in binary and multiclass classification problems to\n",
      "        deal with imbalanced datasets. It is defined as the average of recall\n",
      "        obtained on each class.\n",
      "        \n",
      "        The best value is 1 and the worst value is 0 when ``adjusted=False``.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <balanced_accuracy_score>`.\n",
      "        \n",
      "        .. versionadded:: 0.20\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples,)\n",
      "            Estimated targets as returned by a classifier.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        adjusted : bool, default=False\n",
      "            When true, the result is adjusted for chance, so that random\n",
      "            performance would score 0, while keeping perfect performance at a score\n",
      "            of 1.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        balanced_accuracy : float\n",
      "            Balanced accuracy score.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        average_precision_score : Compute average precision (AP) from prediction\n",
      "            scores.\n",
      "        precision_score : Compute the precision score.\n",
      "        recall_score : Compute the recall score.\n",
      "        roc_auc_score : Compute Area Under the Receiver Operating Characteristic\n",
      "            Curve (ROC AUC) from prediction scores.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Some literature promotes alternative definitions of balanced accuracy. Our\n",
      "        definition is equivalent to :func:`accuracy_score` with class-balanced\n",
      "        sample weights, and shares desirable properties with the binary case.\n",
      "        See the :ref:`User Guide <balanced_accuracy_score>`.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Brodersen, K.H.; Ong, C.S.; Stephan, K.E.; Buhmann, J.M. (2010).\n",
      "               The balanced accuracy and its posterior distribution.\n",
      "               Proceedings of the 20th International Conference on Pattern\n",
      "               Recognition, 3121-24.\n",
      "        .. [2] John. D. Kelleher, Brian Mac Namee, Aoife D'Arcy, (2015).\n",
      "               `Fundamentals of Machine Learning for Predictive Data Analytics:\n",
      "               Algorithms, Worked Examples, and Case Studies\n",
      "               <https://mitpress.mit.edu/books/fundamentals-machine-learning-predictive-data-analytics>`_.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import balanced_accuracy_score\n",
      "        >>> y_true = [0, 1, 0, 0, 1, 0]\n",
      "        >>> y_pred = [0, 1, 0, 0, 0, 1]\n",
      "        >>> balanced_accuracy_score(y_true, y_pred)\n",
      "        np.float64(0.625)\n",
      "    \n",
      "    brier_score_loss(y_true, y_proba=None, *, sample_weight=None, pos_label=None, y_prob='deprecated')\n",
      "        Compute the Brier score loss.\n",
      "        \n",
      "        The smaller the Brier score loss, the better, hence the naming with \"loss\".\n",
      "        The Brier score measures the mean squared difference between the predicted\n",
      "        probability and the actual outcome. The Brier score always\n",
      "        takes on a value between zero and one, since this is the largest\n",
      "        possible difference between a predicted probability (which must be\n",
      "        between zero and one) and the actual outcome (which can take on values\n",
      "        of only 0 and 1). It can be decomposed as the sum of refinement loss and\n",
      "        calibration loss.\n",
      "        \n",
      "        The Brier score is appropriate for binary and categorical outcomes that\n",
      "        can be structured as true or false, but is inappropriate for ordinal\n",
      "        variables which can take on three or more values (this is because the\n",
      "        Brier score assumes that all possible outcomes are equivalently\n",
      "        \"distant\" from one another). Which label is considered to be the positive\n",
      "        label is controlled via the parameter `pos_label`, which defaults to\n",
      "        the greater label unless `y_true` is all 0 or all -1, in which case\n",
      "        `pos_label` defaults to 1.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <brier_score_loss>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,)\n",
      "            True targets.\n",
      "        \n",
      "        y_proba : array-like of shape (n_samples,)\n",
      "            Probabilities of the positive class.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        pos_label : int, float, bool or str, default=None\n",
      "            Label of the positive class. `pos_label` will be inferred in the\n",
      "            following manner:\n",
      "        \n",
      "            * if `y_true` in {-1, 1} or {0, 1}, `pos_label` defaults to 1;\n",
      "            * else if `y_true` contains string, an error will be raised and\n",
      "              `pos_label` should be explicitly specified;\n",
      "            * otherwise, `pos_label` defaults to the greater label,\n",
      "              i.e. `np.unique(y_true)[-1]`.\n",
      "        \n",
      "        y_prob : array-like of shape (n_samples,)\n",
      "            Probabilities of the positive class.\n",
      "        \n",
      "            .. deprecated:: 1.5\n",
      "                `y_prob` is deprecated and will be removed in 1.7. Use\n",
      "                `y_proba` instead.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        score : float\n",
      "            Brier score loss.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] `Wikipedia entry for the Brier score\n",
      "                <https://en.wikipedia.org/wiki/Brier_score>`_.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.metrics import brier_score_loss\n",
      "        >>> y_true = np.array([0, 1, 1, 0])\n",
      "        >>> y_true_categorical = np.array([\"spam\", \"ham\", \"ham\", \"spam\"])\n",
      "        >>> y_prob = np.array([0.1, 0.9, 0.8, 0.3])\n",
      "        >>> brier_score_loss(y_true, y_prob)\n",
      "        np.float64(0.037...)\n",
      "        >>> brier_score_loss(y_true, 1-y_prob, pos_label=0)\n",
      "        np.float64(0.037...)\n",
      "        >>> brier_score_loss(y_true_categorical, y_prob, pos_label=\"ham\")\n",
      "        np.float64(0.037...)\n",
      "        >>> brier_score_loss(y_true, np.array(y_prob) > 0.5)\n",
      "        np.float64(0.0)\n",
      "    \n",
      "    calinski_harabasz_score(X, labels)\n",
      "        Compute the Calinski and Harabasz score.\n",
      "        \n",
      "        It is also known as the Variance Ratio Criterion.\n",
      "        \n",
      "        The score is defined as ratio of the sum of between-cluster dispersion and\n",
      "        of within-cluster dispersion.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <calinski_harabasz_index>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            A list of ``n_features``-dimensional data points. Each row corresponds\n",
      "            to a single data point.\n",
      "        \n",
      "        labels : array-like of shape (n_samples,)\n",
      "            Predicted labels for each sample.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        score : float\n",
      "            The resulting Calinski-Harabasz score.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] `T. Calinski and J. Harabasz, 1974. \"A dendrite method for cluster\n",
      "           analysis\". Communications in Statistics\n",
      "           <https://www.tandfonline.com/doi/abs/10.1080/03610927408827101>`_\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.datasets import make_blobs\n",
      "        >>> from sklearn.cluster import KMeans\n",
      "        >>> from sklearn.metrics import calinski_harabasz_score\n",
      "        >>> X, _ = make_blobs(random_state=0)\n",
      "        >>> kmeans = KMeans(n_clusters=3, random_state=0,).fit(X)\n",
      "        >>> calinski_harabasz_score(X, kmeans.labels_)\n",
      "        np.float64(114.8...)\n",
      "    \n",
      "    check_scoring(estimator=None, scoring=None, *, allow_none=False, raise_exc=True)\n",
      "        Determine scorer from user options.\n",
      "        \n",
      "        A TypeError will be thrown if the estimator cannot be scored.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        estimator : estimator object implementing 'fit' or None, default=None\n",
      "            The object to use to fit the data. If `None`, then this function may error\n",
      "            depending on `allow_none`.\n",
      "        \n",
      "        scoring : str, callable, list, tuple, set, or dict, default=None\n",
      "            Scorer to use. If `scoring` represents a single score, one can use:\n",
      "        \n",
      "            - a single string (see :ref:`scoring_parameter`);\n",
      "            - a callable (see :ref:`scoring_callable`) that returns a single value.\n",
      "        \n",
      "            If `scoring` represents multiple scores, one can use:\n",
      "        \n",
      "            - a list, tuple or set of unique strings;\n",
      "            - a callable returning a dictionary where the keys are the metric names and the\n",
      "              values are the metric scorers;\n",
      "            - a dictionary with metric names as keys and callables a values. The callables\n",
      "              need to have the signature `callable(estimator, X, y)`.\n",
      "        \n",
      "            If None, the provided estimator object's `score` method is used.\n",
      "        \n",
      "        allow_none : bool, default=False\n",
      "            Whether to return None or raise an error if no `scoring` is specified and the\n",
      "            estimator has no `score` method.\n",
      "        \n",
      "        raise_exc : bool, default=True\n",
      "            Whether to raise an exception (if a subset of the scorers in multimetric scoring\n",
      "            fails) or to return an error code.\n",
      "        \n",
      "            - If set to `True`, raises the failing scorer's exception.\n",
      "            - If set to `False`, a formatted string of the exception details is passed as\n",
      "              result of the failing scorer(s).\n",
      "        \n",
      "            This applies if `scoring` is list, tuple, set, or dict. Ignored if `scoring` is\n",
      "            a str or a callable.\n",
      "        \n",
      "            .. versionadded:: 1.6\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        scoring : callable\n",
      "            A scorer callable object / function with signature ``scorer(estimator, X, y)``.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.datasets import load_iris\n",
      "        >>> from sklearn.metrics import check_scoring\n",
      "        >>> from sklearn.tree import DecisionTreeClassifier\n",
      "        >>> X, y = load_iris(return_X_y=True)\n",
      "        >>> classifier = DecisionTreeClassifier(max_depth=2).fit(X, y)\n",
      "        >>> scorer = check_scoring(classifier, scoring='accuracy')\n",
      "        >>> scorer(classifier, X, y)\n",
      "        0.96...\n",
      "        \n",
      "        >>> from sklearn.metrics import make_scorer, accuracy_score, mean_squared_log_error\n",
      "        >>> X, y = load_iris(return_X_y=True)\n",
      "        >>> y *= -1\n",
      "        >>> clf = DecisionTreeClassifier().fit(X, y)\n",
      "        >>> scoring = {\n",
      "        ...     \"accuracy\": make_scorer(accuracy_score),\n",
      "        ...     \"mean_squared_log_error\": make_scorer(mean_squared_log_error),\n",
      "        ... }\n",
      "        >>> scoring_call = check_scoring(estimator=clf, scoring=scoring, raise_exc=False)\n",
      "        >>> scores = scoring_call(clf, X, y)\n",
      "        >>> scores\n",
      "        {'accuracy': 1.0, 'mean_squared_log_error': 'Traceback ...'}\n",
      "    \n",
      "    class_likelihood_ratios(y_true, y_pred, *, labels=None, sample_weight=None, raise_warning=True)\n",
      "        Compute binary classification positive and negative likelihood ratios.\n",
      "        \n",
      "        The positive likelihood ratio is `LR+ = sensitivity / (1 - specificity)`\n",
      "        where the sensitivity or recall is the ratio `tp / (tp + fn)` and the\n",
      "        specificity is `tn / (tn + fp)`. The negative likelihood ratio is `LR- = (1\n",
      "        - sensitivity) / specificity`. Here `tp` is the number of true positives,\n",
      "        `fp` the number of false positives, `tn` is the number of true negatives and\n",
      "        `fn` the number of false negatives. Both class likelihood ratios can be used\n",
      "        to obtain post-test probabilities given a pre-test probability.\n",
      "        \n",
      "        `LR+` ranges from 1 to infinity. A `LR+` of 1 indicates that the probability\n",
      "        of predicting the positive class is the same for samples belonging to either\n",
      "        class; therefore, the test is useless. The greater `LR+` is, the more a\n",
      "        positive prediction is likely to be a true positive when compared with the\n",
      "        pre-test probability. A value of `LR+` lower than 1 is invalid as it would\n",
      "        indicate that the odds of a sample being a true positive decrease with\n",
      "        respect to the pre-test odds.\n",
      "        \n",
      "        `LR-` ranges from 0 to 1. The closer it is to 0, the lower the probability\n",
      "        of a given sample to be a false negative. A `LR-` of 1 means the test is\n",
      "        useless because the odds of having the condition did not change after the\n",
      "        test. A value of `LR-` greater than 1 invalidates the classifier as it\n",
      "        indicates an increase in the odds of a sample belonging to the positive\n",
      "        class after being classified as negative. This is the case when the\n",
      "        classifier systematically predicts the opposite of the true label.\n",
      "        \n",
      "        A typical application in medicine is to identify the positive/negative class\n",
      "        to the presence/absence of a disease, respectively; the classifier being a\n",
      "        diagnostic test; the pre-test probability of an individual having the\n",
      "        disease can be the prevalence of such disease (proportion of a particular\n",
      "        population found to be affected by a medical condition); and the post-test\n",
      "        probabilities would be the probability that the condition is truly present\n",
      "        given a positive test result.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <class_likelihood_ratios>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "            Estimated targets as returned by a classifier.\n",
      "        \n",
      "        labels : array-like, default=None\n",
      "            List of labels to index the matrix. This may be used to select the\n",
      "            positive and negative classes with the ordering `labels=[negative_class,\n",
      "            positive_class]`. If `None` is given, those that appear at least once in\n",
      "            `y_true` or `y_pred` are used in sorted order.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        raise_warning : bool, default=True\n",
      "            Whether or not a case-specific warning message is raised when there is a\n",
      "            zero division. Even if the error is not raised, the function will return\n",
      "            nan in such cases.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        (positive_likelihood_ratio, negative_likelihood_ratio) : tuple\n",
      "            A tuple of two float, the first containing the Positive likelihood ratio\n",
      "            and the second the Negative likelihood ratio.\n",
      "        \n",
      "        Warns\n",
      "        -----\n",
      "        When `false positive == 0`, the positive likelihood ratio is undefined.\n",
      "        When `true negative == 0`, the negative likelihood ratio is undefined.\n",
      "        When `true positive + false negative == 0` both ratios are undefined.\n",
      "        In such cases, `UserWarning` will be raised if raise_warning=True.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] `Wikipedia entry for the Likelihood ratios in diagnostic testing\n",
      "               <https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing>`_.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.metrics import class_likelihood_ratios\n",
      "        >>> class_likelihood_ratios([0, 1, 0, 1, 0], [1, 1, 0, 0, 0])\n",
      "        (np.float64(1.5), np.float64(0.75))\n",
      "        >>> y_true = np.array([\"non-cat\", \"cat\", \"non-cat\", \"cat\", \"non-cat\"])\n",
      "        >>> y_pred = np.array([\"cat\", \"cat\", \"non-cat\", \"non-cat\", \"non-cat\"])\n",
      "        >>> class_likelihood_ratios(y_true, y_pred)\n",
      "        (np.float64(1.33...), np.float64(0.66...))\n",
      "        >>> y_true = np.array([\"non-zebra\", \"zebra\", \"non-zebra\", \"zebra\", \"non-zebra\"])\n",
      "        >>> y_pred = np.array([\"zebra\", \"zebra\", \"non-zebra\", \"non-zebra\", \"non-zebra\"])\n",
      "        >>> class_likelihood_ratios(y_true, y_pred)\n",
      "        (np.float64(1.5), np.float64(0.75))\n",
      "        \n",
      "        To avoid ambiguities, use the notation `labels=[negative_class,\n",
      "        positive_class]`\n",
      "        \n",
      "        >>> y_true = np.array([\"non-cat\", \"cat\", \"non-cat\", \"cat\", \"non-cat\"])\n",
      "        >>> y_pred = np.array([\"cat\", \"cat\", \"non-cat\", \"non-cat\", \"non-cat\"])\n",
      "        >>> class_likelihood_ratios(y_true, y_pred, labels=[\"non-cat\", \"cat\"])\n",
      "        (np.float64(1.5), np.float64(0.75))\n",
      "    \n",
      "    classification_report(y_true, y_pred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
      "        Build a text report showing the main classification metrics.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <classification_report>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "            Estimated targets as returned by a classifier.\n",
      "        \n",
      "        labels : array-like of shape (n_labels,), default=None\n",
      "            Optional list of label indices to include in the report.\n",
      "        \n",
      "        target_names : array-like of shape (n_labels,), default=None\n",
      "            Optional display names matching the labels (same order).\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        digits : int, default=2\n",
      "            Number of digits for formatting output floating point values.\n",
      "            When ``output_dict`` is ``True``, this will be ignored and the\n",
      "            returned values will not be rounded.\n",
      "        \n",
      "        output_dict : bool, default=False\n",
      "            If True, return output as dict.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        zero_division : {\"warn\", 0.0, 1.0, np.nan}, default=\"warn\"\n",
      "            Sets the value to return when there is a zero division. If set to\n",
      "            \"warn\", this acts as 0, but warnings are also raised.\n",
      "        \n",
      "            .. versionadded:: 1.3\n",
      "               `np.nan` option was added.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        report : str or dict\n",
      "            Text summary of the precision, recall, F1 score for each class.\n",
      "            Dictionary returned if output_dict is True. Dictionary has the\n",
      "            following structure::\n",
      "        \n",
      "                {'label 1': {'precision':0.5,\n",
      "                             'recall':1.0,\n",
      "                             'f1-score':0.67,\n",
      "                             'support':1},\n",
      "                 'label 2': { ... },\n",
      "                  ...\n",
      "                }\n",
      "        \n",
      "            The reported averages include macro average (averaging the unweighted\n",
      "            mean per label), weighted average (averaging the support-weighted mean\n",
      "            per label), and sample average (only for multilabel classification).\n",
      "            Micro average (averaging the total true positives, false negatives and\n",
      "            false positives) is only shown for multi-label or multi-class\n",
      "            with a subset of classes, because it corresponds to accuracy\n",
      "            otherwise and would be the same for all metrics.\n",
      "            See also :func:`precision_recall_fscore_support` for more details\n",
      "            on averages.\n",
      "        \n",
      "            Note that in binary classification, recall of the positive class\n",
      "            is also known as \"sensitivity\"; recall of the negative class is\n",
      "            \"specificity\".\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        precision_recall_fscore_support: Compute precision, recall, F-measure and\n",
      "            support for each class.\n",
      "        confusion_matrix: Compute confusion matrix to evaluate the accuracy of a\n",
      "            classification.\n",
      "        multilabel_confusion_matrix: Compute a confusion matrix for each class or sample.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import classification_report\n",
      "        >>> y_true = [0, 1, 2, 2, 2]\n",
      "        >>> y_pred = [0, 0, 2, 2, 1]\n",
      "        >>> target_names = ['class 0', 'class 1', 'class 2']\n",
      "        >>> print(classification_report(y_true, y_pred, target_names=target_names))\n",
      "                      precision    recall  f1-score   support\n",
      "        <BLANKLINE>\n",
      "             class 0       0.50      1.00      0.67         1\n",
      "             class 1       0.00      0.00      0.00         1\n",
      "             class 2       1.00      0.67      0.80         3\n",
      "        <BLANKLINE>\n",
      "            accuracy                           0.60         5\n",
      "           macro avg       0.50      0.56      0.49         5\n",
      "        weighted avg       0.70      0.60      0.61         5\n",
      "        <BLANKLINE>\n",
      "        >>> y_pred = [1, 1, 0]\n",
      "        >>> y_true = [1, 1, 1]\n",
      "        >>> print(classification_report(y_true, y_pred, labels=[1, 2, 3]))\n",
      "                      precision    recall  f1-score   support\n",
      "        <BLANKLINE>\n",
      "                   1       1.00      0.67      0.80         3\n",
      "                   2       0.00      0.00      0.00         0\n",
      "                   3       0.00      0.00      0.00         0\n",
      "        <BLANKLINE>\n",
      "           micro avg       1.00      0.67      0.80         3\n",
      "           macro avg       0.33      0.22      0.27         3\n",
      "        weighted avg       1.00      0.67      0.80         3\n",
      "        <BLANKLINE>\n",
      "    \n",
      "    cohen_kappa_score(y1, y2, *, labels=None, weights=None, sample_weight=None)\n",
      "        Compute Cohen's kappa: a statistic that measures inter-annotator agreement.\n",
      "        \n",
      "        This function computes Cohen's kappa [1]_, a score that expresses the level\n",
      "        of agreement between two annotators on a classification problem. It is\n",
      "        defined as\n",
      "        \n",
      "        .. math::\n",
      "            \\kappa = (p_o - p_e) / (1 - p_e)\n",
      "        \n",
      "        where :math:`p_o` is the empirical probability of agreement on the label\n",
      "        assigned to any sample (the observed agreement ratio), and :math:`p_e` is\n",
      "        the expected agreement when both annotators assign labels randomly.\n",
      "        :math:`p_e` is estimated using a per-annotator empirical prior over the\n",
      "        class labels [2]_.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <cohen_kappa>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y1 : array-like of shape (n_samples,)\n",
      "            Labels assigned by the first annotator.\n",
      "        \n",
      "        y2 : array-like of shape (n_samples,)\n",
      "            Labels assigned by the second annotator. The kappa statistic is\n",
      "            symmetric, so swapping ``y1`` and ``y2`` doesn't change the value.\n",
      "        \n",
      "        labels : array-like of shape (n_classes,), default=None\n",
      "            List of labels to index the matrix. This may be used to select a\n",
      "            subset of labels. If `None`, all labels that appear at least once in\n",
      "            ``y1`` or ``y2`` are used.\n",
      "        \n",
      "        weights : {'linear', 'quadratic'}, default=None\n",
      "            Weighting type to calculate the score. `None` means not weighted;\n",
      "            \"linear\" means linear weighting; \"quadratic\" means quadratic weighting.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        kappa : float\n",
      "            The kappa statistic, which is a number between -1 and 1. The maximum\n",
      "            value means complete agreement; zero or lower means chance agreement.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] :doi:`J. Cohen (1960). \"A coefficient of agreement for nominal scales\".\n",
      "               Educational and Psychological Measurement 20(1):37-46.\n",
      "               <10.1177/001316446002000104>`\n",
      "        .. [2] `R. Artstein and M. Poesio (2008). \"Inter-coder agreement for\n",
      "               computational linguistics\". Computational Linguistics 34(4):555-596\n",
      "               <https://www.mitpressjournals.org/doi/pdf/10.1162/coli.07-034-R2>`_.\n",
      "        .. [3] `Wikipedia entry for the Cohen's kappa\n",
      "                <https://en.wikipedia.org/wiki/Cohen%27s_kappa>`_.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import cohen_kappa_score\n",
      "        >>> y1 = [\"negative\", \"positive\", \"negative\", \"neutral\", \"positive\"]\n",
      "        >>> y2 = [\"negative\", \"positive\", \"negative\", \"neutral\", \"negative\"]\n",
      "        >>> cohen_kappa_score(y1, y2)\n",
      "        np.float64(0.6875)\n",
      "    \n",
      "    completeness_score(labels_true, labels_pred)\n",
      "        Compute completeness metric of a cluster labeling given a ground truth.\n",
      "        \n",
      "        A clustering result satisfies completeness if all the data points\n",
      "        that are members of a given class are elements of the same cluster.\n",
      "        \n",
      "        This metric is independent of the absolute values of the labels:\n",
      "        a permutation of the class or cluster label values won't change the\n",
      "        score value in any way.\n",
      "        \n",
      "        This metric is not symmetric: switching ``label_true`` with ``label_pred``\n",
      "        will return the :func:`homogeneity_score` which will be different in\n",
      "        general.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <homogeneity_completeness>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        labels_true : array-like of shape (n_samples,)\n",
      "            Ground truth class labels to be used as a reference.\n",
      "        \n",
      "        labels_pred : array-like of shape (n_samples,)\n",
      "            Cluster labels to evaluate.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        completeness : float\n",
      "           Score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        homogeneity_score : Homogeneity metric of cluster labeling.\n",
      "        v_measure_score : V-Measure (NMI with arithmetic mean option).\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        \n",
      "        .. [1] `Andrew Rosenberg and Julia Hirschberg, 2007. V-Measure: A\n",
      "           conditional entropy-based external cluster evaluation measure\n",
      "           <https://aclweb.org/anthology/D/D07/D07-1043.pdf>`_\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        \n",
      "        Perfect labelings are complete::\n",
      "        \n",
      "          >>> from sklearn.metrics.cluster import completeness_score\n",
      "          >>> completeness_score([0, 0, 1, 1], [1, 1, 0, 0])\n",
      "          np.float64(1.0)\n",
      "        \n",
      "        Non-perfect labelings that assign all classes members to the same clusters\n",
      "        are still complete::\n",
      "        \n",
      "          >>> print(completeness_score([0, 0, 1, 1], [0, 0, 0, 0]))\n",
      "          1.0\n",
      "          >>> print(completeness_score([0, 1, 2, 3], [0, 0, 1, 1]))\n",
      "          0.999...\n",
      "        \n",
      "        If classes members are split across different clusters, the\n",
      "        assignment cannot be complete::\n",
      "        \n",
      "          >>> print(completeness_score([0, 0, 1, 1], [0, 1, 0, 1]))\n",
      "          0.0\n",
      "          >>> print(completeness_score([0, 0, 0, 0], [0, 1, 2, 3]))\n",
      "          0.0\n",
      "    \n",
      "    confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)\n",
      "        Compute confusion matrix to evaluate the accuracy of a classification.\n",
      "        \n",
      "        By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\n",
      "        is equal to the number of observations known to be in group :math:`i` and\n",
      "        predicted to be in group :math:`j`.\n",
      "        \n",
      "        Thus in binary classification, the count of true negatives is\n",
      "        :math:`C_{0,0}`, false negatives is :math:`C_{1,0}`, true positives is\n",
      "        :math:`C_{1,1}` and false positives is :math:`C_{0,1}`.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <confusion_matrix>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples,)\n",
      "            Estimated targets as returned by a classifier.\n",
      "        \n",
      "        labels : array-like of shape (n_classes), default=None\n",
      "            List of labels to index the matrix. This may be used to reorder\n",
      "            or select a subset of labels.\n",
      "            If ``None`` is given, those that appear at least once\n",
      "            in ``y_true`` or ``y_pred`` are used in sorted order.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        normalize : {'true', 'pred', 'all'}, default=None\n",
      "            Normalizes confusion matrix over the true (rows), predicted (columns)\n",
      "            conditions or all the population. If None, confusion matrix will not be\n",
      "            normalized.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        C : ndarray of shape (n_classes, n_classes)\n",
      "            Confusion matrix whose i-th row and j-th\n",
      "            column entry indicates the number of\n",
      "            samples with true label being i-th class\n",
      "            and predicted label being j-th class.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        ConfusionMatrixDisplay.from_estimator : Plot the confusion matrix\n",
      "            given an estimator, the data, and the label.\n",
      "        ConfusionMatrixDisplay.from_predictions : Plot the confusion matrix\n",
      "            given the true and predicted labels.\n",
      "        ConfusionMatrixDisplay : Confusion Matrix visualization.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] `Wikipedia entry for the Confusion matrix\n",
      "               <https://en.wikipedia.org/wiki/Confusion_matrix>`_\n",
      "               (Wikipedia and other references may use a different\n",
      "               convention for axes).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import confusion_matrix\n",
      "        >>> y_true = [2, 0, 2, 2, 0, 1]\n",
      "        >>> y_pred = [0, 0, 2, 2, 0, 2]\n",
      "        >>> confusion_matrix(y_true, y_pred)\n",
      "        array([[2, 0, 0],\n",
      "               [0, 0, 1],\n",
      "               [1, 0, 2]])\n",
      "        \n",
      "        >>> y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
      "        >>> y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
      "        >>> confusion_matrix(y_true, y_pred, labels=[\"ant\", \"bird\", \"cat\"])\n",
      "        array([[2, 0, 0],\n",
      "               [0, 0, 1],\n",
      "               [1, 0, 2]])\n",
      "        \n",
      "        In the binary case, we can extract true positives, etc. as follows:\n",
      "        \n",
      "        >>> tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
      "        >>> (tn, fp, fn, tp)\n",
      "        (np.int64(0), np.int64(2), np.int64(1), np.int64(1))\n",
      "    \n",
      "    consensus_score(a, b, *, similarity='jaccard')\n",
      "        The similarity of two sets of biclusters.\n",
      "        \n",
      "        Similarity between individual biclusters is computed. Then the best\n",
      "        matching between sets is found by solving a linear sum assignment problem,\n",
      "        using a modified Jonker-Volgenant algorithm.\n",
      "        The final score is the sum of similarities divided by the size of\n",
      "        the larger set.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <biclustering>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : tuple (rows, columns)\n",
      "            Tuple of row and column indicators for a set of biclusters.\n",
      "        \n",
      "        b : tuple (rows, columns)\n",
      "            Another set of biclusters like ``a``.\n",
      "        \n",
      "        similarity : 'jaccard' or callable, default='jaccard'\n",
      "            May be the string \"jaccard\" to use the Jaccard coefficient, or\n",
      "            any function that takes four arguments, each of which is a 1d\n",
      "            indicator vector: (a_rows, a_columns, b_rows, b_columns).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        consensus_score : float\n",
      "           Consensus score, a non-negative value, sum of similarities\n",
      "           divided by size of larger set.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.optimize.linear_sum_assignment : Solve the linear sum assignment problem.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        * Hochreiter, Bodenhofer, et. al., 2010. `FABIA: factor analysis\n",
      "          for bicluster acquisition\n",
      "          <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2881408/>`__.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import consensus_score\n",
      "        >>> a = ([[True, False], [False, True]], [[False, True], [True, False]])\n",
      "        >>> b = ([[False, True], [True, False]], [[True, False], [False, True]])\n",
      "        >>> consensus_score(a, b, similarity='jaccard')\n",
      "        np.float64(1.0)\n",
      "    \n",
      "    coverage_error(y_true, y_score, *, sample_weight=None)\n",
      "        Coverage error measure.\n",
      "        \n",
      "        Compute how far we need to go through the ranked scores to cover all\n",
      "        true labels. The best value is equal to the average number\n",
      "        of labels in ``y_true`` per sample.\n",
      "        \n",
      "        Ties in ``y_scores`` are broken by giving maximal rank that would have\n",
      "        been assigned to all tied values.\n",
      "        \n",
      "        Note: Our implementation's score is 1 greater than the one given in\n",
      "        Tsoumakas et al., 2010. This extends it to handle the degenerate case\n",
      "        in which an instance has 0 true labels.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <coverage_error>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples, n_labels)\n",
      "            True binary labels in binary indicator format.\n",
      "        \n",
      "        y_score : array-like of shape (n_samples, n_labels)\n",
      "            Target scores, can either be probability estimates of the positive\n",
      "            class, confidence values, or non-thresholded measure of decisions\n",
      "            (as returned by \"decision_function\" on some classifiers).\n",
      "            For :term:`decision_function` scores, values greater than or equal to\n",
      "            zero should indicate the positive class.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        coverage_error : float\n",
      "            The coverage error.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Tsoumakas, G., Katakis, I., & Vlahavas, I. (2010).\n",
      "               Mining multi-label data. In Data mining and knowledge discovery\n",
      "               handbook (pp. 667-685). Springer US.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import coverage_error\n",
      "        >>> y_true = [[1, 0, 0], [0, 1, 1]]\n",
      "        >>> y_score = [[1, 0, 0], [0, 1, 1]]\n",
      "        >>> coverage_error(y_true, y_score)\n",
      "        np.float64(1.5)\n",
      "    \n",
      "    d2_absolute_error_score(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average')\n",
      "        :math:`D^2` regression score function, fraction of absolute error explained.\n",
      "        \n",
      "        Best possible score is 1.0 and it can be negative (because the model can be\n",
      "        arbitrarily worse). A model that always uses the empirical median of `y_true`\n",
      "        as constant prediction, disregarding the input features,\n",
      "        gets a :math:`D^2` score of 0.0.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <d2_score>`.\n",
      "        \n",
      "        .. versionadded:: 1.1\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Estimated target values.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        multioutput : {'raw_values', 'uniform_average'} or array-like of shape             (n_outputs,), default='uniform_average'\n",
      "            Defines aggregating of multiple output values.\n",
      "            Array-like value defines weights used to average scores.\n",
      "        \n",
      "            'raw_values' :\n",
      "                Returns a full set of errors in case of multioutput input.\n",
      "        \n",
      "            'uniform_average' :\n",
      "                Scores of all outputs are averaged with uniform weight.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        score : float or ndarray of floats\n",
      "            The :math:`D^2` score with an absolute error deviance\n",
      "            or ndarray of scores if 'multioutput' is 'raw_values'.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Like :math:`R^2`, :math:`D^2` score may be negative\n",
      "        (it need not actually be the square of a quantity D).\n",
      "        \n",
      "        This metric is not well-defined for single samples and will return a NaN\n",
      "        value if n_samples is less than two.\n",
      "        \n",
      "         References\n",
      "        ----------\n",
      "        .. [1] Eq. (3.11) of Hastie, Trevor J., Robert Tibshirani and Martin J.\n",
      "               Wainwright. \"Statistical Learning with Sparsity: The Lasso and\n",
      "               Generalizations.\" (2015). https://hastie.su.domains/StatLearnSparsity/\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import d2_absolute_error_score\n",
      "        >>> y_true = [3, -0.5, 2, 7]\n",
      "        >>> y_pred = [2.5, 0.0, 2, 8]\n",
      "        >>> d2_absolute_error_score(y_true, y_pred)\n",
      "        np.float64(0.764...)\n",
      "        >>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n",
      "        >>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n",
      "        >>> d2_absolute_error_score(y_true, y_pred, multioutput='uniform_average')\n",
      "        np.float64(0.691...)\n",
      "        >>> d2_absolute_error_score(y_true, y_pred, multioutput='raw_values')\n",
      "        array([0.8125    , 0.57142857])\n",
      "        >>> y_true = [1, 2, 3]\n",
      "        >>> y_pred = [1, 2, 3]\n",
      "        >>> d2_absolute_error_score(y_true, y_pred)\n",
      "        np.float64(1.0)\n",
      "        >>> y_true = [1, 2, 3]\n",
      "        >>> y_pred = [2, 2, 2]\n",
      "        >>> d2_absolute_error_score(y_true, y_pred)\n",
      "        np.float64(0.0)\n",
      "        >>> y_true = [1, 2, 3]\n",
      "        >>> y_pred = [3, 2, 1]\n",
      "        >>> d2_absolute_error_score(y_true, y_pred)\n",
      "        np.float64(-1.0)\n",
      "    \n",
      "    d2_log_loss_score(y_true, y_pred, *, sample_weight=None, labels=None)\n",
      "        :math:`D^2` score function, fraction of log loss explained.\n",
      "        \n",
      "        Best possible score is 1.0 and it can be negative (because the model can be\n",
      "        arbitrarily worse). A model that always predicts the per-class proportions\n",
      "        of `y_true`, disregarding the input features, gets a D^2 score of 0.0.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <d2_score_classification>`.\n",
      "        \n",
      "        .. versionadded:: 1.5\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like or label indicator matrix\n",
      "            The actuals labels for the n_samples samples.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples, n_classes) or (n_samples,)\n",
      "            Predicted probabilities, as returned by a classifier's\n",
      "            predict_proba method. If ``y_pred.shape = (n_samples,)``\n",
      "            the probabilities provided are assumed to be that of the\n",
      "            positive class. The labels in ``y_pred`` are assumed to be\n",
      "            ordered alphabetically, as done by\n",
      "            :class:`~sklearn.preprocessing.LabelBinarizer`.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        labels : array-like, default=None\n",
      "            If not provided, labels will be inferred from y_true. If ``labels``\n",
      "            is ``None`` and ``y_pred`` has shape (n_samples,) the labels are\n",
      "            assumed to be binary and are inferred from ``y_true``.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        d2 : float or ndarray of floats\n",
      "            The D^2 score.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This is not a symmetric function.\n",
      "        \n",
      "        Like R^2, D^2 score may be negative (it need not actually be the square of\n",
      "        a quantity D).\n",
      "        \n",
      "        This metric is not well-defined for a single sample and will return a NaN\n",
      "        value if n_samples is less than two.\n",
      "    \n",
      "    d2_pinball_score(y_true, y_pred, *, sample_weight=None, alpha=0.5, multioutput='uniform_average')\n",
      "        :math:`D^2` regression score function, fraction of pinball loss explained.\n",
      "        \n",
      "        Best possible score is 1.0 and it can be negative (because the model can be\n",
      "        arbitrarily worse). A model that always uses the empirical alpha-quantile of\n",
      "        `y_true` as constant prediction, disregarding the input features,\n",
      "        gets a :math:`D^2` score of 0.0.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <d2_score>`.\n",
      "        \n",
      "        .. versionadded:: 1.1\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Estimated target values.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        alpha : float, default=0.5\n",
      "            Slope of the pinball deviance. It determines the quantile level alpha\n",
      "            for which the pinball deviance and also D2 are optimal.\n",
      "            The default `alpha=0.5` is equivalent to `d2_absolute_error_score`.\n",
      "        \n",
      "        multioutput : {'raw_values', 'uniform_average'} or array-like of shape             (n_outputs,), default='uniform_average'\n",
      "            Defines aggregating of multiple output values.\n",
      "            Array-like value defines weights used to average scores.\n",
      "        \n",
      "            'raw_values' :\n",
      "                Returns a full set of errors in case of multioutput input.\n",
      "        \n",
      "            'uniform_average' :\n",
      "                Scores of all outputs are averaged with uniform weight.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        score : float or ndarray of floats\n",
      "            The :math:`D^2` score with a pinball deviance\n",
      "            or ndarray of scores if `multioutput='raw_values'`.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Like :math:`R^2`, :math:`D^2` score may be negative\n",
      "        (it need not actually be the square of a quantity D).\n",
      "        \n",
      "        This metric is not well-defined for a single point and will return a NaN\n",
      "        value if n_samples is less than two.\n",
      "        \n",
      "         References\n",
      "        ----------\n",
      "        .. [1] Eq. (7) of `Koenker, Roger; Machado, José A. F. (1999).\n",
      "               \"Goodness of Fit and Related Inference Processes for Quantile Regression\"\n",
      "               <https://doi.org/10.1080/01621459.1999.10473882>`_\n",
      "        .. [2] Eq. (3.11) of Hastie, Trevor J., Robert Tibshirani and Martin J.\n",
      "               Wainwright. \"Statistical Learning with Sparsity: The Lasso and\n",
      "               Generalizations.\" (2015). https://hastie.su.domains/StatLearnSparsity/\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import d2_pinball_score\n",
      "        >>> y_true = [1, 2, 3]\n",
      "        >>> y_pred = [1, 3, 3]\n",
      "        >>> d2_pinball_score(y_true, y_pred)\n",
      "        np.float64(0.5)\n",
      "        >>> d2_pinball_score(y_true, y_pred, alpha=0.9)\n",
      "        np.float64(0.772...)\n",
      "        >>> d2_pinball_score(y_true, y_pred, alpha=0.1)\n",
      "        np.float64(-1.045...)\n",
      "        >>> d2_pinball_score(y_true, y_true, alpha=0.1)\n",
      "        np.float64(1.0)\n",
      "    \n",
      "    d2_tweedie_score(y_true, y_pred, *, sample_weight=None, power=0)\n",
      "        :math:`D^2` regression score function, fraction of Tweedie deviance explained.\n",
      "        \n",
      "        Best possible score is 1.0 and it can be negative (because the model can be\n",
      "        arbitrarily worse). A model that always uses the empirical mean of `y_true` as\n",
      "        constant prediction, disregarding the input features, gets a D^2 score of 0.0.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <d2_score>`.\n",
      "        \n",
      "        .. versionadded:: 1.0\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples,)\n",
      "            Estimated target values.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        power : float, default=0\n",
      "            Tweedie power parameter. Either power <= 0 or power >= 1.\n",
      "        \n",
      "            The higher `p` the less weight is given to extreme\n",
      "            deviations between true and predicted targets.\n",
      "        \n",
      "            - power < 0: Extreme stable distribution. Requires: y_pred > 0.\n",
      "            - power = 0 : Normal distribution, output corresponds to r2_score.\n",
      "              y_true and y_pred can be any real numbers.\n",
      "            - power = 1 : Poisson distribution. Requires: y_true >= 0 and\n",
      "              y_pred > 0.\n",
      "            - 1 < p < 2 : Compound Poisson distribution. Requires: y_true >= 0\n",
      "              and y_pred > 0.\n",
      "            - power = 2 : Gamma distribution. Requires: y_true > 0 and y_pred > 0.\n",
      "            - power = 3 : Inverse Gaussian distribution. Requires: y_true > 0\n",
      "              and y_pred > 0.\n",
      "            - otherwise : Positive stable distribution. Requires: y_true > 0\n",
      "              and y_pred > 0.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        z : float or ndarray of floats\n",
      "            The D^2 score.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This is not a symmetric function.\n",
      "        \n",
      "        Like R^2, D^2 score may be negative (it need not actually be the square of\n",
      "        a quantity D).\n",
      "        \n",
      "        This metric is not well-defined for single samples and will return a NaN\n",
      "        value if n_samples is less than two.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Eq. (3.11) of Hastie, Trevor J., Robert Tibshirani and Martin J.\n",
      "               Wainwright. \"Statistical Learning with Sparsity: The Lasso and\n",
      "               Generalizations.\" (2015). https://hastie.su.domains/StatLearnSparsity/\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import d2_tweedie_score\n",
      "        >>> y_true = [0.5, 1, 2.5, 7]\n",
      "        >>> y_pred = [1, 1, 5, 3.5]\n",
      "        >>> d2_tweedie_score(y_true, y_pred)\n",
      "        0.285...\n",
      "        >>> d2_tweedie_score(y_true, y_pred, power=1)\n",
      "        0.487...\n",
      "        >>> d2_tweedie_score(y_true, y_pred, power=2)\n",
      "        0.630...\n",
      "        >>> d2_tweedie_score(y_true, y_true, power=2)\n",
      "        1.0\n",
      "    \n",
      "    davies_bouldin_score(X, labels)\n",
      "        Compute the Davies-Bouldin score.\n",
      "        \n",
      "        The score is defined as the average similarity measure of each cluster with\n",
      "        its most similar cluster, where similarity is the ratio of within-cluster\n",
      "        distances to between-cluster distances. Thus, clusters which are farther\n",
      "        apart and less dispersed will result in a better score.\n",
      "        \n",
      "        The minimum score is zero, with lower values indicating better clustering.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <davies-bouldin_index>`.\n",
      "        \n",
      "        .. versionadded:: 0.20\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            A list of ``n_features``-dimensional data points. Each row corresponds\n",
      "            to a single data point.\n",
      "        \n",
      "        labels : array-like of shape (n_samples,)\n",
      "            Predicted labels for each sample.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        score: float\n",
      "            The resulting Davies-Bouldin score.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Davies, David L.; Bouldin, Donald W. (1979).\n",
      "           `\"A Cluster Separation Measure\"\n",
      "           <https://ieeexplore.ieee.org/document/4766909>`__.\n",
      "           IEEE Transactions on Pattern Analysis and Machine Intelligence.\n",
      "           PAMI-1 (2): 224-227\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import davies_bouldin_score\n",
      "        >>> X = [[0, 1], [1, 1], [3, 4]]\n",
      "        >>> labels = [0, 0, 1]\n",
      "        >>> davies_bouldin_score(X, labels)\n",
      "        np.float64(0.12...)\n",
      "    \n",
      "    dcg_score(y_true, y_score, *, k=None, log_base=2, sample_weight=None, ignore_ties=False)\n",
      "        Compute Discounted Cumulative Gain.\n",
      "        \n",
      "        Sum the true scores ranked in the order induced by the predicted scores,\n",
      "        after applying a logarithmic discount.\n",
      "        \n",
      "        This ranking metric yields a high value if true labels are ranked high by\n",
      "        ``y_score``.\n",
      "        \n",
      "        Usually the Normalized Discounted Cumulative Gain (NDCG, computed by\n",
      "        ndcg_score) is preferred.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples, n_labels)\n",
      "            True targets of multilabel classification, or true scores of entities\n",
      "            to be ranked.\n",
      "        \n",
      "        y_score : array-like of shape (n_samples, n_labels)\n",
      "            Target scores, can either be probability estimates, confidence values,\n",
      "            or non-thresholded measure of decisions (as returned by\n",
      "            \"decision_function\" on some classifiers).\n",
      "        \n",
      "        k : int, default=None\n",
      "            Only consider the highest k scores in the ranking. If None, use all\n",
      "            outputs.\n",
      "        \n",
      "        log_base : float, default=2\n",
      "            Base of the logarithm used for the discount. A low value means a\n",
      "            sharper discount (top results are more important).\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights. If `None`, all samples are given the same weight.\n",
      "        \n",
      "        ignore_ties : bool, default=False\n",
      "            Assume that there are no ties in y_score (which is likely to be the\n",
      "            case if y_score is continuous) for efficiency gains.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        discounted_cumulative_gain : float\n",
      "            The averaged sample DCG scores.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        ndcg_score : The Discounted Cumulative Gain divided by the Ideal Discounted\n",
      "            Cumulative Gain (the DCG obtained for a perfect ranking), in order to\n",
      "            have a score between 0 and 1.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        `Wikipedia entry for Discounted Cumulative Gain\n",
      "        <https://en.wikipedia.org/wiki/Discounted_cumulative_gain>`_.\n",
      "        \n",
      "        Jarvelin, K., & Kekalainen, J. (2002).\n",
      "        Cumulated gain-based evaluation of IR techniques. ACM Transactions on\n",
      "        Information Systems (TOIS), 20(4), 422-446.\n",
      "        \n",
      "        Wang, Y., Wang, L., Li, Y., He, D., Chen, W., & Liu, T. Y. (2013, May).\n",
      "        A theoretical analysis of NDCG ranking measures. In Proceedings of the 26th\n",
      "        Annual Conference on Learning Theory (COLT 2013).\n",
      "        \n",
      "        McSherry, F., & Najork, M. (2008, March). Computing information retrieval\n",
      "        performance measures efficiently in the presence of tied scores. In\n",
      "        European conference on information retrieval (pp. 414-421). Springer,\n",
      "        Berlin, Heidelberg.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.metrics import dcg_score\n",
      "        >>> # we have ground-truth relevance of some answers to a query:\n",
      "        >>> true_relevance = np.asarray([[10, 0, 0, 1, 5]])\n",
      "        >>> # we predict scores for the answers\n",
      "        >>> scores = np.asarray([[.1, .2, .3, 4, 70]])\n",
      "        >>> dcg_score(true_relevance, scores)\n",
      "        np.float64(9.49...)\n",
      "        >>> # we can set k to truncate the sum; only top k answers contribute\n",
      "        >>> dcg_score(true_relevance, scores, k=2)\n",
      "        np.float64(5.63...)\n",
      "        >>> # now we have some ties in our prediction\n",
      "        >>> scores = np.asarray([[1, 0, 0, 0, 1]])\n",
      "        >>> # by default ties are averaged, so here we get the average true\n",
      "        >>> # relevance of our top predictions: (10 + 5) / 2 = 7.5\n",
      "        >>> dcg_score(true_relevance, scores, k=1)\n",
      "        np.float64(7.5)\n",
      "        >>> # we can choose to ignore ties for faster results, but only\n",
      "        >>> # if we know there aren't ties in our scores, otherwise we get\n",
      "        >>> # wrong results:\n",
      "        >>> dcg_score(true_relevance,\n",
      "        ...           scores, k=1, ignore_ties=True)\n",
      "        np.float64(5.0)\n",
      "    \n",
      "    det_curve(y_true, y_score, pos_label=None, sample_weight=None)\n",
      "        Compute error rates for different probability thresholds.\n",
      "        \n",
      "        .. note::\n",
      "           This metric is used for evaluation of ranking and error tradeoffs of\n",
      "           a binary classification task.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <det_curve>`.\n",
      "        \n",
      "        .. versionadded:: 0.24\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : ndarray of shape (n_samples,)\n",
      "            True binary labels. If labels are not either {-1, 1} or {0, 1}, then\n",
      "            pos_label should be explicitly given.\n",
      "        \n",
      "        y_score : ndarray of shape of (n_samples,)\n",
      "            Target scores, can either be probability estimates of the positive\n",
      "            class, confidence values, or non-thresholded measure of decisions\n",
      "            (as returned by \"decision_function\" on some classifiers).\n",
      "            For :term:`decision_function` scores, values greater than or equal to\n",
      "            zero should indicate the positive class.\n",
      "        \n",
      "        pos_label : int, float, bool or str, default=None\n",
      "            The label of the positive class.\n",
      "            When ``pos_label=None``, if `y_true` is in {-1, 1} or {0, 1},\n",
      "            ``pos_label`` is set to 1, otherwise an error will be raised.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        fpr : ndarray of shape (n_thresholds,)\n",
      "            False positive rate (FPR) such that element i is the false positive\n",
      "            rate of predictions with score >= thresholds[i]. This is occasionally\n",
      "            referred to as false acceptance probability or fall-out.\n",
      "        \n",
      "        fnr : ndarray of shape (n_thresholds,)\n",
      "            False negative rate (FNR) such that element i is the false negative\n",
      "            rate of predictions with score >= thresholds[i]. This is occasionally\n",
      "            referred to as false rejection or miss rate.\n",
      "        \n",
      "        thresholds : ndarray of shape (n_thresholds,)\n",
      "            Decreasing score values.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        DetCurveDisplay.from_estimator : Plot DET curve given an estimator and\n",
      "            some data.\n",
      "        DetCurveDisplay.from_predictions : Plot DET curve given the true and\n",
      "            predicted labels.\n",
      "        DetCurveDisplay : DET curve visualization.\n",
      "        roc_curve : Compute Receiver operating characteristic (ROC) curve.\n",
      "        precision_recall_curve : Compute precision-recall curve.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.metrics import det_curve\n",
      "        >>> y_true = np.array([0, 0, 1, 1])\n",
      "        >>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
      "        >>> fpr, fnr, thresholds = det_curve(y_true, y_scores)\n",
      "        >>> fpr\n",
      "        array([0.5, 0.5, 0. ])\n",
      "        >>> fnr\n",
      "        array([0. , 0.5, 0.5])\n",
      "        >>> thresholds\n",
      "        array([0.35, 0.4 , 0.8 ])\n",
      "    \n",
      "    euclidean_distances(X, Y=None, *, Y_norm_squared=None, squared=False, X_norm_squared=None)\n",
      "        Compute the distance matrix between each pair from a vector array X and Y.\n",
      "        \n",
      "        For efficiency reasons, the euclidean distance between a pair of row\n",
      "        vector x and y is computed as::\n",
      "        \n",
      "            dist(x, y) = sqrt(dot(x, x) - 2 * dot(x, y) + dot(y, y))\n",
      "        \n",
      "        This formulation has two advantages over other ways of computing distances.\n",
      "        First, it is computationally efficient when dealing with sparse data.\n",
      "        Second, if one argument varies but the other remains unchanged, then\n",
      "        `dot(x, x)` and/or `dot(y, y)` can be pre-computed.\n",
      "        \n",
      "        However, this is not the most precise way of doing this computation,\n",
      "        because this equation potentially suffers from \"catastrophic cancellation\".\n",
      "        Also, the distance matrix returned by this function may not be exactly\n",
      "        symmetric as required by, e.g., ``scipy.spatial.distance`` functions.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <metrics>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples_X, n_features)\n",
      "            An array where each row is a sample and each column is a feature.\n",
      "        \n",
      "        Y : {array-like, sparse matrix} of shape (n_samples_Y, n_features),             default=None\n",
      "            An array where each row is a sample and each column is a feature.\n",
      "            If `None`, method uses `Y=X`.\n",
      "        \n",
      "        Y_norm_squared : array-like of shape (n_samples_Y,) or (n_samples_Y, 1)             or (1, n_samples_Y), default=None\n",
      "            Pre-computed dot-products of vectors in Y (e.g.,\n",
      "            ``(Y**2).sum(axis=1)``)\n",
      "            May be ignored in some cases, see the note below.\n",
      "        \n",
      "        squared : bool, default=False\n",
      "            Return squared Euclidean distances.\n",
      "        \n",
      "        X_norm_squared : array-like of shape (n_samples_X,) or (n_samples_X, 1)             or (1, n_samples_X), default=None\n",
      "            Pre-computed dot-products of vectors in X (e.g.,\n",
      "            ``(X**2).sum(axis=1)``)\n",
      "            May be ignored in some cases, see the note below.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        distances : ndarray of shape (n_samples_X, n_samples_Y)\n",
      "            Returns the distances between the row vectors of `X`\n",
      "            and the row vectors of `Y`.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        paired_distances : Distances between pairs of elements of X and Y.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        To achieve a better accuracy, `X_norm_squared` and `Y_norm_squared` may be\n",
      "        unused if they are passed as `np.float32`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics.pairwise import euclidean_distances\n",
      "        >>> X = [[0, 1], [1, 1]]\n",
      "        >>> # distance between rows of X\n",
      "        >>> euclidean_distances(X, X)\n",
      "        array([[0., 1.],\n",
      "               [1., 0.]])\n",
      "        >>> # get distance to origin\n",
      "        >>> euclidean_distances(X, [[0, 0]])\n",
      "        array([[1.        ],\n",
      "               [1.41421356]])\n",
      "    \n",
      "    explained_variance_score(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average', force_finite=True)\n",
      "        Explained variance regression score function.\n",
      "        \n",
      "        Best possible score is 1.0, lower values are worse.\n",
      "        \n",
      "        In the particular case when ``y_true`` is constant, the explained variance\n",
      "        score is not finite: it is either ``NaN`` (perfect predictions) or\n",
      "        ``-Inf`` (imperfect predictions). To prevent such non-finite numbers to\n",
      "        pollute higher-level experiments such as a grid search cross-validation,\n",
      "        by default these cases are replaced with 1.0 (perfect predictions) or 0.0\n",
      "        (imperfect predictions) respectively. If ``force_finite``\n",
      "        is set to ``False``, this score falls back on the original :math:`R^2`\n",
      "        definition.\n",
      "        \n",
      "        .. note::\n",
      "           The Explained Variance score is similar to the\n",
      "           :func:`R^2 score <r2_score>`, with the notable difference that it\n",
      "           does not account for systematic offsets in the prediction. Most often\n",
      "           the :func:`R^2 score <r2_score>` should be preferred.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <explained_variance_score>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Estimated target values.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        multioutput : {'raw_values', 'uniform_average', 'variance_weighted'} or             array-like of shape (n_outputs,), default='uniform_average'\n",
      "            Defines aggregating of multiple output scores.\n",
      "            Array-like value defines weights used to average scores.\n",
      "        \n",
      "            'raw_values' :\n",
      "                Returns a full set of scores in case of multioutput input.\n",
      "        \n",
      "            'uniform_average' :\n",
      "                Scores of all outputs are averaged with uniform weight.\n",
      "        \n",
      "            'variance_weighted' :\n",
      "                Scores of all outputs are averaged, weighted by the variances\n",
      "                of each individual output.\n",
      "        \n",
      "        force_finite : bool, default=True\n",
      "            Flag indicating if ``NaN`` and ``-Inf`` scores resulting from constant\n",
      "            data should be replaced with real numbers (``1.0`` if prediction is\n",
      "            perfect, ``0.0`` otherwise). Default is ``True``, a convenient setting\n",
      "            for hyperparameters' search procedures (e.g. grid search\n",
      "            cross-validation).\n",
      "        \n",
      "            .. versionadded:: 1.1\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        score : float or ndarray of floats\n",
      "            The explained variance or ndarray if 'multioutput' is 'raw_values'.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        r2_score :\n",
      "            Similar metric, but accounting for systematic offsets in\n",
      "            prediction.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This is not a symmetric function.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import explained_variance_score\n",
      "        >>> y_true = [3, -0.5, 2, 7]\n",
      "        >>> y_pred = [2.5, 0.0, 2, 8]\n",
      "        >>> explained_variance_score(y_true, y_pred)\n",
      "        0.957...\n",
      "        >>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n",
      "        >>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n",
      "        >>> explained_variance_score(y_true, y_pred, multioutput='uniform_average')\n",
      "        0.983...\n",
      "        >>> y_true = [-2, -2, -2]\n",
      "        >>> y_pred = [-2, -2, -2]\n",
      "        >>> explained_variance_score(y_true, y_pred)\n",
      "        1.0\n",
      "        >>> explained_variance_score(y_true, y_pred, force_finite=False)\n",
      "        nan\n",
      "        >>> y_true = [-2, -2, -2]\n",
      "        >>> y_pred = [-2, -2, -2 + 1e-8]\n",
      "        >>> explained_variance_score(y_true, y_pred)\n",
      "        0.0\n",
      "        >>> explained_variance_score(y_true, y_pred, force_finite=False)\n",
      "        -inf\n",
      "    \n",
      "    f1_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')\n",
      "        Compute the F1 score, also known as balanced F-score or F-measure.\n",
      "        \n",
      "        The F1 score can be interpreted as a harmonic mean of the precision and\n",
      "        recall, where an F1 score reaches its best value at 1 and worst score at 0.\n",
      "        The relative contribution of precision and recall to the F1 score are\n",
      "        equal. The formula for the F1 score is:\n",
      "        \n",
      "        .. math::\n",
      "            \\text{F1} = \\frac{2 * \\text{TP}}{2 * \\text{TP} + \\text{FP} + \\text{FN}}\n",
      "        \n",
      "        Where :math:`\\text{TP}` is the number of true positives, :math:`\\text{FN}` is the\n",
      "        number of false negatives, and :math:`\\text{FP}` is the number of false positives.\n",
      "        F1 is by default\n",
      "        calculated as 0.0 when there are no true positives, false negatives, or\n",
      "        false positives.\n",
      "        \n",
      "        Support beyond :term:`binary` targets is achieved by treating :term:`multiclass`\n",
      "        and :term:`multilabel` data as a collection of binary problems, one for each\n",
      "        label. For the :term:`binary` case, setting `average='binary'` will return\n",
      "        F1 score for `pos_label`. If `average` is not `'binary'`, `pos_label` is ignored\n",
      "        and F1 score for both classes are computed, then averaged or both returned (when\n",
      "        `average=None`). Similarly, for :term:`multiclass` and :term:`multilabel` targets,\n",
      "        F1 score for all `labels` are either returned or averaged depending on the\n",
      "        `average` parameter. Use `labels` specify the set of labels to calculate F1 score\n",
      "        for.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "            Estimated targets as returned by a classifier.\n",
      "        \n",
      "        labels : array-like, default=None\n",
      "            The set of labels to include when `average != 'binary'`, and their\n",
      "            order if `average is None`. Labels present in the data can be\n",
      "            excluded, for example in multiclass classification to exclude a \"negative\n",
      "            class\". Labels not present in the data can be included and will be\n",
      "            \"assigned\" 0 samples. For multilabel targets, labels are column indices.\n",
      "            By default, all labels in `y_true` and `y_pred` are used in sorted order.\n",
      "        \n",
      "            .. versionchanged:: 0.17\n",
      "               Parameter `labels` improved for multiclass problem.\n",
      "        \n",
      "        pos_label : int, float, bool or str, default=1\n",
      "            The class to report if `average='binary'` and the data is binary,\n",
      "            otherwise this parameter is ignored.\n",
      "            For multiclass or multilabel targets, set `labels=[pos_label]` and\n",
      "            `average != 'binary'` to report metrics for one label only.\n",
      "        \n",
      "        average : {'micro', 'macro', 'samples', 'weighted', 'binary'} or None,             default='binary'\n",
      "            This parameter is required for multiclass/multilabel targets.\n",
      "            If ``None``, the metrics for each class are returned. Otherwise, this\n",
      "            determines the type of averaging performed on the data:\n",
      "        \n",
      "            ``'binary'``:\n",
      "                Only report results for the class specified by ``pos_label``.\n",
      "                This is applicable only if targets (``y_{true,pred}``) are binary.\n",
      "            ``'micro'``:\n",
      "                Calculate metrics globally by counting the total true positives,\n",
      "                false negatives and false positives.\n",
      "            ``'macro'``:\n",
      "                Calculate metrics for each label, and find their unweighted\n",
      "                mean.  This does not take label imbalance into account.\n",
      "            ``'weighted'``:\n",
      "                Calculate metrics for each label, and find their average weighted\n",
      "                by support (the number of true instances for each label). This\n",
      "                alters 'macro' to account for label imbalance; it can result in an\n",
      "                F-score that is not between precision and recall.\n",
      "            ``'samples'``:\n",
      "                Calculate metrics for each instance, and find their average (only\n",
      "                meaningful for multilabel classification where this differs from\n",
      "                :func:`accuracy_score`).\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        zero_division : {\"warn\", 0.0, 1.0, np.nan}, default=\"warn\"\n",
      "            Sets the value to return when there is a zero division, i.e. when all\n",
      "            predictions and labels are negative.\n",
      "        \n",
      "            Notes:\n",
      "            - If set to \"warn\", this acts like 0, but a warning is also raised.\n",
      "            - If set to `np.nan`, such values will be excluded from the average.\n",
      "        \n",
      "            .. versionadded:: 1.3\n",
      "               `np.nan` option was added.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        f1_score : float or array of float, shape = [n_unique_labels]\n",
      "            F1 score of the positive class in binary classification or weighted\n",
      "            average of the F1 scores of each class for the multiclass task.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        fbeta_score : Compute the F-beta score.\n",
      "        precision_recall_fscore_support : Compute the precision, recall, F-score,\n",
      "            and support.\n",
      "        jaccard_score : Compute the Jaccard similarity coefficient score.\n",
      "        multilabel_confusion_matrix : Compute a confusion matrix for each class or\n",
      "            sample.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        When ``true positive + false positive + false negative == 0`` (i.e. a class\n",
      "        is completely absent from both ``y_true`` or ``y_pred``), f-score is\n",
      "        undefined. In such cases, by default f-score will be set to 0.0, and\n",
      "        ``UndefinedMetricWarning`` will be raised. This behavior can be modified by\n",
      "        setting the ``zero_division`` parameter.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] `Wikipedia entry for the F1-score\n",
      "               <https://en.wikipedia.org/wiki/F1_score>`_.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.metrics import f1_score\n",
      "        >>> y_true = [0, 1, 2, 0, 1, 2]\n",
      "        >>> y_pred = [0, 2, 1, 0, 0, 1]\n",
      "        >>> f1_score(y_true, y_pred, average='macro')\n",
      "        0.26...\n",
      "        >>> f1_score(y_true, y_pred, average='micro')\n",
      "        0.33...\n",
      "        >>> f1_score(y_true, y_pred, average='weighted')\n",
      "        0.26...\n",
      "        >>> f1_score(y_true, y_pred, average=None)\n",
      "        array([0.8, 0. , 0. ])\n",
      "        \n",
      "        >>> # binary classification\n",
      "        >>> y_true_empty = [0, 0, 0, 0, 0, 0]\n",
      "        >>> y_pred_empty = [0, 0, 0, 0, 0, 0]\n",
      "        >>> f1_score(y_true_empty, y_pred_empty)\n",
      "        0.0...\n",
      "        >>> f1_score(y_true_empty, y_pred_empty, zero_division=1.0)\n",
      "        1.0...\n",
      "        >>> f1_score(y_true_empty, y_pred_empty, zero_division=np.nan)\n",
      "        nan...\n",
      "        \n",
      "        >>> # multilabel classification\n",
      "        >>> y_true = [[0, 0, 0], [1, 1, 1], [0, 1, 1]]\n",
      "        >>> y_pred = [[0, 0, 0], [1, 1, 1], [1, 1, 0]]\n",
      "        >>> f1_score(y_true, y_pred, average=None)\n",
      "        array([0.66666667, 1.        , 0.66666667])\n",
      "    \n",
      "    fbeta_score(y_true, y_pred, *, beta, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')\n",
      "        Compute the F-beta score.\n",
      "        \n",
      "        The F-beta score is the weighted harmonic mean of precision and recall,\n",
      "        reaching its optimal value at 1 and its worst value at 0.\n",
      "        \n",
      "        The `beta` parameter represents the ratio of recall importance to\n",
      "        precision importance. `beta > 1` gives more weight to recall, while\n",
      "        `beta < 1` favors precision. For example, `beta = 2` makes recall twice\n",
      "        as important as precision, while `beta = 0.5` does the opposite.\n",
      "        Asymptotically, `beta -> +inf` considers only recall, and `beta -> 0`\n",
      "        only precision.\n",
      "        \n",
      "        The formula for F-beta score is:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "           F_\\beta = \\frac{(1 + \\beta^2) \\text{tp}}\n",
      "                            {(1 + \\beta^2) \\text{tp} + \\text{fp} + \\beta^2 \\text{fn}}\n",
      "        \n",
      "        Where :math:`\\text{tp}` is the number of true positives, :math:`\\text{fp}` is the\n",
      "        number of false positives, and :math:`\\text{fn}` is the number of false negatives.\n",
      "        \n",
      "        Support beyond term:`binary` targets is achieved by treating :term:`multiclass`\n",
      "        and :term:`multilabel` data as a collection of binary problems, one for each\n",
      "        label. For the :term:`binary` case, setting `average='binary'` will return\n",
      "        F-beta score for `pos_label`. If `average` is not `'binary'`, `pos_label` is\n",
      "        ignored and F-beta score for both classes are computed, then averaged or both\n",
      "        returned (when `average=None`). Similarly, for :term:`multiclass` and\n",
      "        :term:`multilabel` targets, F-beta score for all `labels` are either returned or\n",
      "        averaged depending on the `average` parameter. Use `labels` specify the set of\n",
      "        labels to calculate F-beta score for.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "            Estimated targets as returned by a classifier.\n",
      "        \n",
      "        beta : float\n",
      "            Determines the weight of recall in the combined score.\n",
      "        \n",
      "        labels : array-like, default=None\n",
      "            The set of labels to include when `average != 'binary'`, and their\n",
      "            order if `average is None`. Labels present in the data can be\n",
      "            excluded, for example in multiclass classification to exclude a \"negative\n",
      "            class\". Labels not present in the data can be included and will be\n",
      "            \"assigned\" 0 samples. For multilabel targets, labels are column indices.\n",
      "            By default, all labels in `y_true` and `y_pred` are used in sorted order.\n",
      "        \n",
      "            .. versionchanged:: 0.17\n",
      "               Parameter `labels` improved for multiclass problem.\n",
      "        \n",
      "        pos_label : int, float, bool or str, default=1\n",
      "            The class to report if `average='binary'` and the data is binary,\n",
      "            otherwise this parameter is ignored.\n",
      "            For multiclass or multilabel targets, set `labels=[pos_label]` and\n",
      "            `average != 'binary'` to report metrics for one label only.\n",
      "        \n",
      "        average : {'micro', 'macro', 'samples', 'weighted', 'binary'} or None,             default='binary'\n",
      "            This parameter is required for multiclass/multilabel targets.\n",
      "            If ``None``, the metrics for each class are returned. Otherwise, this\n",
      "            determines the type of averaging performed on the data:\n",
      "        \n",
      "            ``'binary'``:\n",
      "                Only report results for the class specified by ``pos_label``.\n",
      "                This is applicable only if targets (``y_{true,pred}``) are binary.\n",
      "            ``'micro'``:\n",
      "                Calculate metrics globally by counting the total true positives,\n",
      "                false negatives and false positives.\n",
      "            ``'macro'``:\n",
      "                Calculate metrics for each label, and find their unweighted\n",
      "                mean.  This does not take label imbalance into account.\n",
      "            ``'weighted'``:\n",
      "                Calculate metrics for each label, and find their average weighted\n",
      "                by support (the number of true instances for each label). This\n",
      "                alters 'macro' to account for label imbalance; it can result in an\n",
      "                F-score that is not between precision and recall.\n",
      "            ``'samples'``:\n",
      "                Calculate metrics for each instance, and find their average (only\n",
      "                meaningful for multilabel classification where this differs from\n",
      "                :func:`accuracy_score`).\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        zero_division : {\"warn\", 0.0, 1.0, np.nan}, default=\"warn\"\n",
      "            Sets the value to return when there is a zero division, i.e. when all\n",
      "            predictions and labels are negative.\n",
      "        \n",
      "            Notes:\n",
      "        \n",
      "            - If set to \"warn\", this acts like 0, but a warning is also raised.\n",
      "            - If set to `np.nan`, such values will be excluded from the average.\n",
      "        \n",
      "            .. versionadded:: 1.3\n",
      "               `np.nan` option was added.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        fbeta_score : float (if average is not None) or array of float, shape =        [n_unique_labels]\n",
      "            F-beta score of the positive class in binary classification or weighted\n",
      "            average of the F-beta score of each class for the multiclass task.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        precision_recall_fscore_support : Compute the precision, recall, F-score,\n",
      "            and support.\n",
      "        multilabel_confusion_matrix : Compute a confusion matrix for each class or\n",
      "            sample.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        When ``true positive + false positive + false negative == 0``, f-score\n",
      "        returns 0.0 and raises ``UndefinedMetricWarning``. This behavior can be\n",
      "        modified by setting ``zero_division``.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] R. Baeza-Yates and B. Ribeiro-Neto (2011).\n",
      "               Modern Information Retrieval. Addison Wesley, pp. 327-328.\n",
      "        \n",
      "        .. [2] `Wikipedia entry for the F1-score\n",
      "               <https://en.wikipedia.org/wiki/F1_score>`_.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.metrics import fbeta_score\n",
      "        >>> y_true = [0, 1, 2, 0, 1, 2]\n",
      "        >>> y_pred = [0, 2, 1, 0, 0, 1]\n",
      "        >>> fbeta_score(y_true, y_pred, average='macro', beta=0.5)\n",
      "        0.23...\n",
      "        >>> fbeta_score(y_true, y_pred, average='micro', beta=0.5)\n",
      "        0.33...\n",
      "        >>> fbeta_score(y_true, y_pred, average='weighted', beta=0.5)\n",
      "        0.23...\n",
      "        >>> fbeta_score(y_true, y_pred, average=None, beta=0.5)\n",
      "        array([0.71..., 0.        , 0.        ])\n",
      "        >>> y_pred_empty = [0, 0, 0, 0, 0, 0]\n",
      "        >>> fbeta_score(y_true, y_pred_empty,\n",
      "        ...             average=\"macro\", zero_division=np.nan, beta=0.5)\n",
      "        0.12...\n",
      "    \n",
      "    fowlkes_mallows_score(labels_true, labels_pred, *, sparse=False)\n",
      "        Measure the similarity of two clusterings of a set of points.\n",
      "        \n",
      "        .. versionadded:: 0.18\n",
      "        \n",
      "        The Fowlkes-Mallows index (FMI) is defined as the geometric mean between of\n",
      "        the precision and recall::\n",
      "        \n",
      "            FMI = TP / sqrt((TP + FP) * (TP + FN))\n",
      "        \n",
      "        Where ``TP`` is the number of **True Positive** (i.e. the number of pairs of\n",
      "        points that belong to the same cluster in both ``labels_true`` and\n",
      "        ``labels_pred``), ``FP`` is the number of **False Positive** (i.e. the\n",
      "        number of pairs of points that belong to the same cluster in\n",
      "        ``labels_pred`` but not in ``labels_true``) and ``FN`` is the number of\n",
      "        **False Negative** (i.e. the number of pairs of points that belong to the\n",
      "        same cluster in ``labels_true`` but not in ``labels_pred``).\n",
      "        \n",
      "        The score ranges from 0 to 1. A high value indicates a good similarity\n",
      "        between two clusters.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <fowlkes_mallows_scores>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        labels_true : array-like of shape (n_samples,), dtype=int\n",
      "            A clustering of the data into disjoint subsets.\n",
      "        \n",
      "        labels_pred : array-like of shape (n_samples,), dtype=int\n",
      "            A clustering of the data into disjoint subsets.\n",
      "        \n",
      "        sparse : bool, default=False\n",
      "            Compute contingency matrix internally with sparse matrix.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        score : float\n",
      "           The resulting Fowlkes-Mallows score.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] `E. B. Fowkles and C. L. Mallows, 1983. \"A method for comparing two\n",
      "           hierarchical clusterings\". Journal of the American Statistical\n",
      "           Association\n",
      "           <https://www.tandfonline.com/doi/abs/10.1080/01621459.1983.10478008>`_\n",
      "        \n",
      "        .. [2] `Wikipedia entry for the Fowlkes-Mallows Index\n",
      "               <https://en.wikipedia.org/wiki/Fowlkes-Mallows_index>`_\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        \n",
      "        Perfect labelings are both homogeneous and complete, hence have\n",
      "        score 1.0::\n",
      "        \n",
      "          >>> from sklearn.metrics.cluster import fowlkes_mallows_score\n",
      "          >>> fowlkes_mallows_score([0, 0, 1, 1], [0, 0, 1, 1])\n",
      "          np.float64(1.0)\n",
      "          >>> fowlkes_mallows_score([0, 0, 1, 1], [1, 1, 0, 0])\n",
      "          np.float64(1.0)\n",
      "        \n",
      "        If classes members are completely split across different clusters,\n",
      "        the assignment is totally random, hence the FMI is null::\n",
      "        \n",
      "          >>> fowlkes_mallows_score([0, 0, 0, 0], [0, 1, 2, 3])\n",
      "          0.0\n",
      "    \n",
      "    get_scorer(scoring)\n",
      "        Get a scorer from string.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <scoring_parameter>`.\n",
      "        :func:`~sklearn.metrics.get_scorer_names` can be used to retrieve the names\n",
      "        of all available scorers.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        scoring : str, callable or None\n",
      "            Scoring method as string. If callable it is returned as is.\n",
      "            If None, returns None.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        scorer : callable\n",
      "            The scorer.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        When passed a string, this function always returns a copy of the scorer\n",
      "        object. Calling `get_scorer` twice for the same scorer results in two\n",
      "        separate scorer objects.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.dummy import DummyClassifier\n",
      "        >>> from sklearn.metrics import get_scorer\n",
      "        >>> X = np.reshape([0, 1, -1, -0.5, 2], (-1, 1))\n",
      "        >>> y = np.array([0, 1, 1, 0, 1])\n",
      "        >>> classifier = DummyClassifier(strategy=\"constant\", constant=0).fit(X, y)\n",
      "        >>> accuracy = get_scorer(\"accuracy\")\n",
      "        >>> accuracy(classifier, X, y)\n",
      "        0.4\n",
      "    \n",
      "    get_scorer_names()\n",
      "        Get the names of all available scorers.\n",
      "        \n",
      "        These names can be passed to :func:`~sklearn.metrics.get_scorer` to\n",
      "        retrieve the scorer object.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        list of str\n",
      "            Names of all available scorers.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import get_scorer_names\n",
      "        >>> all_scorers = get_scorer_names()\n",
      "        >>> type(all_scorers)\n",
      "        <class 'list'>\n",
      "        >>> all_scorers[:3]\n",
      "        ['accuracy', 'adjusted_mutual_info_score', 'adjusted_rand_score']\n",
      "        >>> \"roc_auc\" in all_scorers\n",
      "        True\n",
      "    \n",
      "    hamming_loss(y_true, y_pred, *, sample_weight=None)\n",
      "        Compute the average Hamming loss.\n",
      "        \n",
      "        The Hamming loss is the fraction of labels that are incorrectly predicted.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <hamming_loss>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "            Ground truth (correct) labels.\n",
      "        \n",
      "        y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "            Predicted labels, as returned by a classifier.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : float or int\n",
      "            Return the average Hamming loss between element of ``y_true`` and\n",
      "            ``y_pred``.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        accuracy_score : Compute the accuracy score. By default, the function will\n",
      "            return the fraction of correct predictions divided by the total number\n",
      "            of predictions.\n",
      "        jaccard_score : Compute the Jaccard similarity coefficient score.\n",
      "        zero_one_loss : Compute the Zero-one classification loss. By default, the\n",
      "            function will return the percentage of imperfectly predicted subsets.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        In multiclass classification, the Hamming loss corresponds to the Hamming\n",
      "        distance between ``y_true`` and ``y_pred`` which is equivalent to the\n",
      "        subset ``zero_one_loss`` function, when `normalize` parameter is set to\n",
      "        True.\n",
      "        \n",
      "        In multilabel classification, the Hamming loss is different from the\n",
      "        subset zero-one loss. The zero-one loss considers the entire set of labels\n",
      "        for a given sample incorrect if it does not entirely match the true set of\n",
      "        labels. Hamming loss is more forgiving in that it penalizes only the\n",
      "        individual labels.\n",
      "        \n",
      "        The Hamming loss is upperbounded by the subset zero-one loss, when\n",
      "        `normalize` parameter is set to True. It is always between 0 and 1,\n",
      "        lower being better.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Grigorios Tsoumakas, Ioannis Katakis. Multi-Label Classification:\n",
      "               An Overview. International Journal of Data Warehousing & Mining,\n",
      "               3(3), 1-13, July-September 2007.\n",
      "        \n",
      "        .. [2] `Wikipedia entry on the Hamming distance\n",
      "               <https://en.wikipedia.org/wiki/Hamming_distance>`_.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import hamming_loss\n",
      "        >>> y_pred = [1, 2, 3, 4]\n",
      "        >>> y_true = [2, 2, 3, 4]\n",
      "        >>> hamming_loss(y_true, y_pred)\n",
      "        0.25\n",
      "        \n",
      "        In the multilabel case with binary label indicators:\n",
      "        \n",
      "        >>> import numpy as np\n",
      "        >>> hamming_loss(np.array([[0, 1], [1, 1]]), np.zeros((2, 2)))\n",
      "        0.75\n",
      "    \n",
      "    hinge_loss(y_true, pred_decision, *, labels=None, sample_weight=None)\n",
      "        Average hinge loss (non-regularized).\n",
      "        \n",
      "        In binary class case, assuming labels in y_true are encoded with +1 and -1,\n",
      "        when a prediction mistake is made, ``margin = y_true * pred_decision`` is\n",
      "        always negative (since the signs disagree), implying ``1 - margin`` is\n",
      "        always greater than 1.  The cumulated hinge loss is therefore an upper\n",
      "        bound of the number of mistakes made by the classifier.\n",
      "        \n",
      "        In multiclass case, the function expects that either all the labels are\n",
      "        included in y_true or an optional labels argument is provided which\n",
      "        contains all the labels. The multilabel margin is calculated according\n",
      "        to Crammer-Singer's method. As in the binary case, the cumulated hinge loss\n",
      "        is an upper bound of the number of mistakes made by the classifier.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <hinge_loss>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,)\n",
      "            True target, consisting of integers of two values. The positive label\n",
      "            must be greater than the negative label.\n",
      "        \n",
      "        pred_decision : array-like of shape (n_samples,) or (n_samples, n_classes)\n",
      "            Predicted decisions, as output by decision_function (floats).\n",
      "        \n",
      "        labels : array-like, default=None\n",
      "            Contains all the labels for the problem. Used in multiclass hinge loss.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : float\n",
      "            Average hinge loss.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] `Wikipedia entry on the Hinge loss\n",
      "               <https://en.wikipedia.org/wiki/Hinge_loss>`_.\n",
      "        \n",
      "        .. [2] Koby Crammer, Yoram Singer. On the Algorithmic\n",
      "               Implementation of Multiclass Kernel-based Vector\n",
      "               Machines. Journal of Machine Learning Research 2,\n",
      "               (2001), 265-292.\n",
      "        \n",
      "        .. [3] `L1 AND L2 Regularization for Multiclass Hinge Loss Models\n",
      "               by Robert C. Moore, John DeNero\n",
      "               <https://storage.googleapis.com/pub-tools-public-publication-data/pdf/37362.pdf>`_.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn import svm\n",
      "        >>> from sklearn.metrics import hinge_loss\n",
      "        >>> X = [[0], [1]]\n",
      "        >>> y = [-1, 1]\n",
      "        >>> est = svm.LinearSVC(random_state=0)\n",
      "        >>> est.fit(X, y)\n",
      "        LinearSVC(random_state=0)\n",
      "        >>> pred_decision = est.decision_function([[-2], [3], [0.5]])\n",
      "        >>> pred_decision\n",
      "        array([-2.18...,  2.36...,  0.09...])\n",
      "        >>> hinge_loss([-1, 1, 1], pred_decision)\n",
      "        np.float64(0.30...)\n",
      "        \n",
      "        In the multiclass case:\n",
      "        \n",
      "        >>> import numpy as np\n",
      "        >>> X = np.array([[0], [1], [2], [3]])\n",
      "        >>> Y = np.array([0, 1, 2, 3])\n",
      "        >>> labels = np.array([0, 1, 2, 3])\n",
      "        >>> est = svm.LinearSVC()\n",
      "        >>> est.fit(X, Y)\n",
      "        LinearSVC()\n",
      "        >>> pred_decision = est.decision_function([[-1], [2], [3]])\n",
      "        >>> y_true = [0, 2, 3]\n",
      "        >>> hinge_loss(y_true, pred_decision, labels=labels)\n",
      "        np.float64(0.56...)\n",
      "    \n",
      "    homogeneity_completeness_v_measure(labels_true, labels_pred, *, beta=1.0)\n",
      "        Compute the homogeneity and completeness and V-Measure scores at once.\n",
      "        \n",
      "        Those metrics are based on normalized conditional entropy measures of\n",
      "        the clustering labeling to evaluate given the knowledge of a Ground\n",
      "        Truth class labels of the same samples.\n",
      "        \n",
      "        A clustering result satisfies homogeneity if all of its clusters\n",
      "        contain only data points which are members of a single class.\n",
      "        \n",
      "        A clustering result satisfies completeness if all the data points\n",
      "        that are members of a given class are elements of the same cluster.\n",
      "        \n",
      "        Both scores have positive values between 0.0 and 1.0, larger values\n",
      "        being desirable.\n",
      "        \n",
      "        Those 3 metrics are independent of the absolute values of the labels:\n",
      "        a permutation of the class or cluster label values won't change the\n",
      "        score values in any way.\n",
      "        \n",
      "        V-Measure is furthermore symmetric: swapping ``labels_true`` and\n",
      "        ``label_pred`` will give the same score. This does not hold for\n",
      "        homogeneity and completeness. V-Measure is identical to\n",
      "        :func:`normalized_mutual_info_score` with the arithmetic averaging\n",
      "        method.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <homogeneity_completeness>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        labels_true : array-like of shape (n_samples,)\n",
      "            Ground truth class labels to be used as a reference.\n",
      "        \n",
      "        labels_pred : array-like of shape (n_samples,)\n",
      "            Cluster labels to evaluate.\n",
      "        \n",
      "        beta : float, default=1.0\n",
      "            Ratio of weight attributed to ``homogeneity`` vs ``completeness``.\n",
      "            If ``beta`` is greater than 1, ``completeness`` is weighted more\n",
      "            strongly in the calculation. If ``beta`` is less than 1,\n",
      "            ``homogeneity`` is weighted more strongly.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        homogeneity : float\n",
      "            Score between 0.0 and 1.0. 1.0 stands for perfectly homogeneous labeling.\n",
      "        \n",
      "        completeness : float\n",
      "            Score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling.\n",
      "        \n",
      "        v_measure : float\n",
      "            Harmonic mean of the first two.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        homogeneity_score : Homogeneity metric of cluster labeling.\n",
      "        completeness_score : Completeness metric of cluster labeling.\n",
      "        v_measure_score : V-Measure (NMI with arithmetic mean option).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import homogeneity_completeness_v_measure\n",
      "        >>> y_true, y_pred = [0, 0, 1, 1, 2, 2], [0, 0, 1, 2, 2, 2]\n",
      "        >>> homogeneity_completeness_v_measure(y_true, y_pred)\n",
      "        (np.float64(0.71...), np.float64(0.77...), np.float64(0.73...))\n",
      "    \n",
      "    homogeneity_score(labels_true, labels_pred)\n",
      "        Homogeneity metric of a cluster labeling given a ground truth.\n",
      "        \n",
      "        A clustering result satisfies homogeneity if all of its clusters\n",
      "        contain only data points which are members of a single class.\n",
      "        \n",
      "        This metric is independent of the absolute values of the labels:\n",
      "        a permutation of the class or cluster label values won't change the\n",
      "        score value in any way.\n",
      "        \n",
      "        This metric is not symmetric: switching ``label_true`` with ``label_pred``\n",
      "        will return the :func:`completeness_score` which will be different in\n",
      "        general.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <homogeneity_completeness>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        labels_true : array-like of shape (n_samples,)\n",
      "            Ground truth class labels to be used as a reference.\n",
      "        \n",
      "        labels_pred : array-like of shape (n_samples,)\n",
      "            Cluster labels to evaluate.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        homogeneity : float\n",
      "           Score between 0.0 and 1.0. 1.0 stands for perfectly homogeneous labeling.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        completeness_score : Completeness metric of cluster labeling.\n",
      "        v_measure_score : V-Measure (NMI with arithmetic mean option).\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        \n",
      "        .. [1] `Andrew Rosenberg and Julia Hirschberg, 2007. V-Measure: A\n",
      "           conditional entropy-based external cluster evaluation measure\n",
      "           <https://aclweb.org/anthology/D/D07/D07-1043.pdf>`_\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        \n",
      "        Perfect labelings are homogeneous::\n",
      "        \n",
      "          >>> from sklearn.metrics.cluster import homogeneity_score\n",
      "          >>> homogeneity_score([0, 0, 1, 1], [1, 1, 0, 0])\n",
      "          np.float64(1.0)\n",
      "        \n",
      "        Non-perfect labelings that further split classes into more clusters can be\n",
      "        perfectly homogeneous::\n",
      "        \n",
      "          >>> print(\"%.6f\" % homogeneity_score([0, 0, 1, 1], [0, 0, 1, 2]))\n",
      "          1.000000\n",
      "          >>> print(\"%.6f\" % homogeneity_score([0, 0, 1, 1], [0, 1, 2, 3]))\n",
      "          1.000000\n",
      "        \n",
      "        Clusters that include samples from different classes do not make for an\n",
      "        homogeneous labeling::\n",
      "        \n",
      "          >>> print(\"%.6f\" % homogeneity_score([0, 0, 1, 1], [0, 1, 0, 1]))\n",
      "          0.0...\n",
      "          >>> print(\"%.6f\" % homogeneity_score([0, 0, 1, 1], [0, 0, 0, 0]))\n",
      "          0.0...\n",
      "    \n",
      "    jaccard_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')\n",
      "        Jaccard similarity coefficient score.\n",
      "        \n",
      "        The Jaccard index [1], or Jaccard similarity coefficient, defined as\n",
      "        the size of the intersection divided by the size of the union of two label\n",
      "        sets, is used to compare set of predicted labels for a sample to the\n",
      "        corresponding set of labels in ``y_true``.\n",
      "        \n",
      "        Support beyond term:`binary` targets is achieved by treating :term:`multiclass`\n",
      "        and :term:`multilabel` data as a collection of binary problems, one for each\n",
      "        label. For the :term:`binary` case, setting `average='binary'` will return the\n",
      "        Jaccard similarity coefficient for `pos_label`. If `average` is not `'binary'`,\n",
      "        `pos_label` is ignored and scores for both classes are computed, then averaged or\n",
      "        both returned (when `average=None`). Similarly, for :term:`multiclass` and\n",
      "        :term:`multilabel` targets, scores for all `labels` are either returned or\n",
      "        averaged depending on the `average` parameter. Use `labels` specify the set of\n",
      "        labels to calculate the score for.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <jaccard_similarity_score>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "            Ground truth (correct) labels.\n",
      "        \n",
      "        y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "            Predicted labels, as returned by a classifier.\n",
      "        \n",
      "        labels : array-like of shape (n_classes,), default=None\n",
      "            The set of labels to include when `average != 'binary'`, and their\n",
      "            order if `average is None`. Labels present in the data can be\n",
      "            excluded, for example in multiclass classification to exclude a \"negative\n",
      "            class\". Labels not present in the data can be included and will be\n",
      "            \"assigned\" 0 samples. For multilabel targets, labels are column indices.\n",
      "            By default, all labels in `y_true` and `y_pred` are used in sorted order.\n",
      "        \n",
      "        pos_label : int, float, bool or str, default=1\n",
      "            The class to report if `average='binary'` and the data is binary,\n",
      "            otherwise this parameter is ignored.\n",
      "            For multiclass or multilabel targets, set `labels=[pos_label]` and\n",
      "            `average != 'binary'` to report metrics for one label only.\n",
      "        \n",
      "        average : {'micro', 'macro', 'samples', 'weighted',             'binary'} or None, default='binary'\n",
      "            If ``None``, the scores for each class are returned. Otherwise, this\n",
      "            determines the type of averaging performed on the data:\n",
      "        \n",
      "            ``'binary'``:\n",
      "                Only report results for the class specified by ``pos_label``.\n",
      "                This is applicable only if targets (``y_{true,pred}``) are binary.\n",
      "            ``'micro'``:\n",
      "                Calculate metrics globally by counting the total true positives,\n",
      "                false negatives and false positives.\n",
      "            ``'macro'``:\n",
      "                Calculate metrics for each label, and find their unweighted\n",
      "                mean.  This does not take label imbalance into account.\n",
      "            ``'weighted'``:\n",
      "                Calculate metrics for each label, and find their average, weighted\n",
      "                by support (the number of true instances for each label). This\n",
      "                alters 'macro' to account for label imbalance.\n",
      "            ``'samples'``:\n",
      "                Calculate metrics for each instance, and find their average (only\n",
      "                meaningful for multilabel classification).\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        zero_division : \"warn\", {0.0, 1.0}, default=\"warn\"\n",
      "            Sets the value to return when there is a zero division, i.e. when there\n",
      "            there are no negative values in predictions and labels. If set to\n",
      "            \"warn\", this acts like 0, but a warning is also raised.\n",
      "        \n",
      "            .. versionadded:: 0.24\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        score : float or ndarray of shape (n_unique_labels,), dtype=np.float64\n",
      "            The Jaccard score. When `average` is not `None`, a single scalar is\n",
      "            returned.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        accuracy_score : Function for calculating the accuracy score.\n",
      "        f1_score : Function for calculating the F1 score.\n",
      "        multilabel_confusion_matrix : Function for computing a confusion matrix                                  for each class or sample.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        :func:`jaccard_score` may be a poor metric if there are no\n",
      "        positives for some samples or classes. Jaccard is undefined if there are\n",
      "        no true or predicted labels, and our implementation will return a score\n",
      "        of 0 with a warning.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] `Wikipedia entry for the Jaccard index\n",
      "               <https://en.wikipedia.org/wiki/Jaccard_index>`_.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.metrics import jaccard_score\n",
      "        >>> y_true = np.array([[0, 1, 1],\n",
      "        ...                    [1, 1, 0]])\n",
      "        >>> y_pred = np.array([[1, 1, 1],\n",
      "        ...                    [1, 0, 0]])\n",
      "        \n",
      "        In the binary case:\n",
      "        \n",
      "        >>> jaccard_score(y_true[0], y_pred[0])\n",
      "        np.float64(0.6666...)\n",
      "        \n",
      "        In the 2D comparison case (e.g. image similarity):\n",
      "        \n",
      "        >>> jaccard_score(y_true, y_pred, average=\"micro\")\n",
      "        np.float64(0.6)\n",
      "        \n",
      "        In the multilabel case:\n",
      "        \n",
      "        >>> jaccard_score(y_true, y_pred, average='samples')\n",
      "        np.float64(0.5833...)\n",
      "        >>> jaccard_score(y_true, y_pred, average='macro')\n",
      "        np.float64(0.6666...)\n",
      "        >>> jaccard_score(y_true, y_pred, average=None)\n",
      "        array([0.5, 0.5, 1. ])\n",
      "        \n",
      "        In the multiclass case:\n",
      "        \n",
      "        >>> y_pred = [0, 2, 1, 2]\n",
      "        >>> y_true = [0, 1, 2, 2]\n",
      "        >>> jaccard_score(y_true, y_pred, average=None)\n",
      "        array([1. , 0. , 0.33...])\n",
      "    \n",
      "    label_ranking_average_precision_score(y_true, y_score, *, sample_weight=None)\n",
      "        Compute ranking-based average precision.\n",
      "        \n",
      "        Label ranking average precision (LRAP) is the average over each ground\n",
      "        truth label assigned to each sample, of the ratio of true vs. total\n",
      "        labels with lower score.\n",
      "        \n",
      "        This metric is used in multilabel ranking problem, where the goal\n",
      "        is to give better rank to the labels associated to each sample.\n",
      "        \n",
      "        The obtained score is always strictly greater than 0 and\n",
      "        the best value is 1.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <label_ranking_average_precision>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : {array-like, sparse matrix} of shape (n_samples, n_labels)\n",
      "            True binary labels in binary indicator format.\n",
      "        \n",
      "        y_score : array-like of shape (n_samples, n_labels)\n",
      "            Target scores, can either be probability estimates of the positive\n",
      "            class, confidence values, or non-thresholded measure of decisions\n",
      "            (as returned by \"decision_function\" on some classifiers).\n",
      "            For :term:`decision_function` scores, values greater than or equal to\n",
      "            zero should indicate the positive class.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        score : float\n",
      "            Ranking-based average precision score.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.metrics import label_ranking_average_precision_score\n",
      "        >>> y_true = np.array([[1, 0, 0], [0, 0, 1]])\n",
      "        >>> y_score = np.array([[0.75, 0.5, 1], [1, 0.2, 0.1]])\n",
      "        >>> label_ranking_average_precision_score(y_true, y_score)\n",
      "        np.float64(0.416...)\n",
      "    \n",
      "    label_ranking_loss(y_true, y_score, *, sample_weight=None)\n",
      "        Compute Ranking loss measure.\n",
      "        \n",
      "        Compute the average number of label pairs that are incorrectly ordered\n",
      "        given y_score weighted by the size of the label set and the number of\n",
      "        labels not in the label set.\n",
      "        \n",
      "        This is similar to the error set size, but weighted by the number of\n",
      "        relevant and irrelevant labels. The best performance is achieved with\n",
      "        a ranking loss of zero.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <label_ranking_loss>`.\n",
      "        \n",
      "        .. versionadded:: 0.17\n",
      "           A function *label_ranking_loss*\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : {array-like, sparse matrix} of shape (n_samples, n_labels)\n",
      "            True binary labels in binary indicator format.\n",
      "        \n",
      "        y_score : array-like of shape (n_samples, n_labels)\n",
      "            Target scores, can either be probability estimates of the positive\n",
      "            class, confidence values, or non-thresholded measure of decisions\n",
      "            (as returned by \"decision_function\" on some classifiers).\n",
      "            For :term:`decision_function` scores, values greater than or equal to\n",
      "            zero should indicate the positive class.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : float\n",
      "            Average number of label pairs that are incorrectly ordered given\n",
      "            y_score weighted by the size of the label set and the number of labels not\n",
      "            in the label set.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Tsoumakas, G., Katakis, I., & Vlahavas, I. (2010).\n",
      "               Mining multi-label data. In Data mining and knowledge discovery\n",
      "               handbook (pp. 667-685). Springer US.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import label_ranking_loss\n",
      "        >>> y_true = [[1, 0, 0], [0, 0, 1]]\n",
      "        >>> y_score = [[0.75, 0.5, 1], [1, 0.2, 0.1]]\n",
      "        >>> label_ranking_loss(y_true, y_score)\n",
      "        np.float64(0.75...)\n",
      "    \n",
      "    log_loss(y_true, y_pred, *, normalize=True, sample_weight=None, labels=None)\n",
      "        Log loss, aka logistic loss or cross-entropy loss.\n",
      "        \n",
      "        This is the loss function used in (multinomial) logistic regression\n",
      "        and extensions of it such as neural networks, defined as the negative\n",
      "        log-likelihood of a logistic model that returns ``y_pred`` probabilities\n",
      "        for its training data ``y_true``.\n",
      "        The log loss is only defined for two or more labels.\n",
      "        For a single sample with true label :math:`y \\in \\{0,1\\}` and\n",
      "        a probability estimate :math:`p = \\operatorname{Pr}(y = 1)`, the log\n",
      "        loss is:\n",
      "        \n",
      "        .. math::\n",
      "            L_{\\log}(y, p) = -(y \\log (p) + (1 - y) \\log (1 - p))\n",
      "        \n",
      "        Read more in the :ref:`User Guide <log_loss>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like or label indicator matrix\n",
      "            Ground truth (correct) labels for n_samples samples.\n",
      "        \n",
      "        y_pred : array-like of float, shape = (n_samples, n_classes) or (n_samples,)\n",
      "            Predicted probabilities, as returned by a classifier's\n",
      "            predict_proba method. If ``y_pred.shape = (n_samples,)``\n",
      "            the probabilities provided are assumed to be that of the\n",
      "            positive class. The labels in ``y_pred`` are assumed to be\n",
      "            ordered alphabetically, as done by\n",
      "            :class:`~sklearn.preprocessing.LabelBinarizer`.\n",
      "        \n",
      "            `y_pred` values are clipped to `[eps, 1-eps]` where `eps` is the machine\n",
      "            precision for `y_pred`'s dtype.\n",
      "        \n",
      "        normalize : bool, default=True\n",
      "            If true, return the mean loss per sample.\n",
      "            Otherwise, return the sum of the per-sample losses.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        labels : array-like, default=None\n",
      "            If not provided, labels will be inferred from y_true. If ``labels``\n",
      "            is ``None`` and ``y_pred`` has shape (n_samples,) the labels are\n",
      "            assumed to be binary and are inferred from ``y_true``.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : float\n",
      "            Log loss, aka logistic loss or cross-entropy loss.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The logarithm used is the natural logarithm (base-e).\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        C.M. Bishop (2006). Pattern Recognition and Machine Learning. Springer,\n",
      "        p. 209.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import log_loss\n",
      "        >>> log_loss([\"spam\", \"ham\", \"ham\", \"spam\"],\n",
      "        ...          [[.1, .9], [.9, .1], [.8, .2], [.35, .65]])\n",
      "        0.21616...\n",
      "    \n",
      "    make_scorer(score_func, *, response_method='default', greater_is_better=True, **kwargs)\n",
      "        Make a scorer from a performance metric or loss function.\n",
      "        \n",
      "        A scorer is a wrapper around an arbitrary metric or loss function that is called\n",
      "        with the signature `scorer(estimator, X, y_true, **kwargs)`.\n",
      "        \n",
      "        It is accepted in all scikit-learn estimators or functions allowing a `scoring`\n",
      "        parameter.\n",
      "        \n",
      "        The parameter `response_method` allows to specify which method of the estimator\n",
      "        should be used to feed the scoring/loss function.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <scoring_callable>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        score_func : callable\n",
      "            Score function (or loss function) with signature\n",
      "            ``score_func(y, y_pred, **kwargs)``.\n",
      "        \n",
      "        response_method : {\"predict_proba\", \"decision_function\", \"predict\"} or             list/tuple of such str, default=None\n",
      "        \n",
      "            Specifies the response method to use get prediction from an estimator\n",
      "            (i.e. :term:`predict_proba`, :term:`decision_function` or\n",
      "            :term:`predict`). Possible choices are:\n",
      "        \n",
      "            - if `str`, it corresponds to the name to the method to return;\n",
      "            - if a list or tuple of `str`, it provides the method names in order of\n",
      "              preference. The method returned corresponds to the first method in\n",
      "              the list and which is implemented by `estimator`.\n",
      "            - if `None`, it is equivalent to `\"predict\"`.\n",
      "        \n",
      "            .. versionadded:: 1.4\n",
      "        \n",
      "            .. deprecated:: 1.6\n",
      "                None is equivalent to 'predict' and is deprecated. It will be removed in\n",
      "                version 1.8.\n",
      "        \n",
      "        greater_is_better : bool, default=True\n",
      "            Whether `score_func` is a score function (default), meaning high is\n",
      "            good, or a loss function, meaning low is good. In the latter case, the\n",
      "            scorer object will sign-flip the outcome of the `score_func`.\n",
      "        \n",
      "        **kwargs : additional arguments\n",
      "            Additional parameters to be passed to `score_func`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        scorer : callable\n",
      "            Callable object that returns a scalar score; greater is better.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import fbeta_score, make_scorer\n",
      "        >>> ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
      "        >>> ftwo_scorer\n",
      "        make_scorer(fbeta_score, response_method='predict', beta=2)\n",
      "        >>> from sklearn.model_selection import GridSearchCV\n",
      "        >>> from sklearn.svm import LinearSVC\n",
      "        >>> grid = GridSearchCV(LinearSVC(), param_grid={'C': [1, 10]},\n",
      "        ...                     scoring=ftwo_scorer)\n",
      "    \n",
      "    matthews_corrcoef(y_true, y_pred, *, sample_weight=None)\n",
      "        Compute the Matthews correlation coefficient (MCC).\n",
      "        \n",
      "        The Matthews correlation coefficient is used in machine learning as a\n",
      "        measure of the quality of binary and multiclass classifications. It takes\n",
      "        into account true and false positives and negatives and is generally\n",
      "        regarded as a balanced measure which can be used even if the classes are of\n",
      "        very different sizes. The MCC is in essence a correlation coefficient value\n",
      "        between -1 and +1. A coefficient of +1 represents a perfect prediction, 0\n",
      "        an average random prediction and -1 an inverse prediction.  The statistic\n",
      "        is also known as the phi coefficient. [source: Wikipedia]\n",
      "        \n",
      "        Binary and multiclass labels are supported.  Only in the binary case does\n",
      "        this relate to information about true and false positives and negatives.\n",
      "        See references below.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <matthews_corrcoef>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples,)\n",
      "            Estimated targets as returned by a classifier.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "            .. versionadded:: 0.18\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        mcc : float\n",
      "            The Matthews correlation coefficient (+1 represents a perfect\n",
      "            prediction, 0 an average random prediction and -1 and inverse\n",
      "            prediction).\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] :doi:`Baldi, Brunak, Chauvin, Andersen and Nielsen, (2000). Assessing the\n",
      "           accuracy of prediction algorithms for classification: an overview.\n",
      "           <10.1093/bioinformatics/16.5.412>`\n",
      "        \n",
      "        .. [2] `Wikipedia entry for the Matthews Correlation Coefficient (phi coefficient)\n",
      "           <https://en.wikipedia.org/wiki/Phi_coefficient>`_.\n",
      "        \n",
      "        .. [3] `Gorodkin, (2004). Comparing two K-category assignments by a\n",
      "            K-category correlation coefficient\n",
      "            <https://www.sciencedirect.com/science/article/pii/S1476927104000799>`_.\n",
      "        \n",
      "        .. [4] `Jurman, Riccadonna, Furlanello, (2012). A Comparison of MCC and CEN\n",
      "            Error Measures in MultiClass Prediction\n",
      "            <https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0041882>`_.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import matthews_corrcoef\n",
      "        >>> y_true = [+1, +1, +1, -1]\n",
      "        >>> y_pred = [+1, -1, +1, +1]\n",
      "        >>> matthews_corrcoef(y_true, y_pred)\n",
      "        np.float64(-0.33...)\n",
      "    \n",
      "    max_error(y_true, y_pred)\n",
      "        The max_error metric calculates the maximum residual error.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <max_error>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples,)\n",
      "            Estimated target values.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        max_error : float\n",
      "            A positive floating point value (the best value is 0.0).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import max_error\n",
      "        >>> y_true = [3, 2, 7, 1]\n",
      "        >>> y_pred = [4, 2, 7, 1]\n",
      "        >>> max_error(y_true, y_pred)\n",
      "        np.int64(1)\n",
      "    \n",
      "    mean_absolute_error(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average')\n",
      "        Mean absolute error regression loss.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <mean_absolute_error>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Estimated target values.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        multioutput : {'raw_values', 'uniform_average'}  or array-like of shape             (n_outputs,), default='uniform_average'\n",
      "            Defines aggregating of multiple output values.\n",
      "            Array-like value defines weights used to average errors.\n",
      "        \n",
      "            'raw_values' :\n",
      "                Returns a full set of errors in case of multioutput input.\n",
      "        \n",
      "            'uniform_average' :\n",
      "                Errors of all outputs are averaged with uniform weight.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : float or array of floats\n",
      "            If multioutput is 'raw_values', then mean absolute error is returned\n",
      "            for each output separately.\n",
      "            If multioutput is 'uniform_average' or an ndarray of weights, then the\n",
      "            weighted average of all output errors is returned.\n",
      "        \n",
      "            MAE output is non-negative floating point. The best value is 0.0.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import mean_absolute_error\n",
      "        >>> y_true = [3, -0.5, 2, 7]\n",
      "        >>> y_pred = [2.5, 0.0, 2, 8]\n",
      "        >>> mean_absolute_error(y_true, y_pred)\n",
      "        0.5\n",
      "        >>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n",
      "        >>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n",
      "        >>> mean_absolute_error(y_true, y_pred)\n",
      "        0.75\n",
      "        >>> mean_absolute_error(y_true, y_pred, multioutput='raw_values')\n",
      "        array([0.5, 1. ])\n",
      "        >>> mean_absolute_error(y_true, y_pred, multioutput=[0.3, 0.7])\n",
      "        0.85...\n",
      "    \n",
      "    mean_absolute_percentage_error(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average')\n",
      "        Mean absolute percentage error (MAPE) regression loss.\n",
      "        \n",
      "        Note that we are not using the common \"percentage\" definition: the percentage\n",
      "        in the range [0, 100] is converted to a relative value in the range [0, 1]\n",
      "        by dividing by 100. Thus, an error of 200% corresponds to a relative error of 2.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <mean_absolute_percentage_error>`.\n",
      "        \n",
      "        .. versionadded:: 0.24\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Estimated target values.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        multioutput : {'raw_values', 'uniform_average'} or array-like\n",
      "            Defines aggregating of multiple output values.\n",
      "            Array-like value defines weights used to average errors.\n",
      "            If input is list then the shape must be (n_outputs,).\n",
      "        \n",
      "            'raw_values' :\n",
      "                Returns a full set of errors in case of multioutput input.\n",
      "        \n",
      "            'uniform_average' :\n",
      "                Errors of all outputs are averaged with uniform weight.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : float or ndarray of floats\n",
      "            If multioutput is 'raw_values', then mean absolute percentage error\n",
      "            is returned for each output separately.\n",
      "            If multioutput is 'uniform_average' or an ndarray of weights, then the\n",
      "            weighted average of all output errors is returned.\n",
      "        \n",
      "            MAPE output is non-negative floating point. The best value is 0.0.\n",
      "            But note that bad predictions can lead to arbitrarily large\n",
      "            MAPE values, especially if some `y_true` values are very close to zero.\n",
      "            Note that we return a large value instead of `inf` when `y_true` is zero.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import mean_absolute_percentage_error\n",
      "        >>> y_true = [3, -0.5, 2, 7]\n",
      "        >>> y_pred = [2.5, 0.0, 2, 8]\n",
      "        >>> mean_absolute_percentage_error(y_true, y_pred)\n",
      "        0.3273...\n",
      "        >>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n",
      "        >>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n",
      "        >>> mean_absolute_percentage_error(y_true, y_pred)\n",
      "        0.5515...\n",
      "        >>> mean_absolute_percentage_error(y_true, y_pred, multioutput=[0.3, 0.7])\n",
      "        0.6198...\n",
      "        >>> # the value when some element of the y_true is zero is arbitrarily high because\n",
      "        >>> # of the division by epsilon\n",
      "        >>> y_true = [1., 0., 2.4, 7.]\n",
      "        >>> y_pred = [1.2, 0.1, 2.4, 8.]\n",
      "        >>> mean_absolute_percentage_error(y_true, y_pred)\n",
      "        112589990684262.48\n",
      "    \n",
      "    mean_gamma_deviance(y_true, y_pred, *, sample_weight=None)\n",
      "        Mean Gamma deviance regression loss.\n",
      "        \n",
      "        Gamma deviance is equivalent to the Tweedie deviance with\n",
      "        the power parameter `power=2`. It is invariant to scaling of\n",
      "        the target variable, and measures relative errors.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <mean_tweedie_deviance>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,)\n",
      "            Ground truth (correct) target values. Requires y_true > 0.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples,)\n",
      "            Estimated target values. Requires y_pred > 0.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : float\n",
      "            A non-negative floating point value (the best value is 0.0).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import mean_gamma_deviance\n",
      "        >>> y_true = [2, 0.5, 1, 4]\n",
      "        >>> y_pred = [0.5, 0.5, 2., 2.]\n",
      "        >>> mean_gamma_deviance(y_true, y_pred)\n",
      "        1.0568...\n",
      "    \n",
      "    mean_pinball_loss(y_true, y_pred, *, sample_weight=None, alpha=0.5, multioutput='uniform_average')\n",
      "        Pinball loss for quantile regression.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <pinball_loss>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Estimated target values.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        alpha : float, slope of the pinball loss, default=0.5,\n",
      "            This loss is equivalent to :ref:`mean_absolute_error` when `alpha=0.5`,\n",
      "            `alpha=0.95` is minimized by estimators of the 95th percentile.\n",
      "        \n",
      "        multioutput : {'raw_values', 'uniform_average'}  or array-like of shape             (n_outputs,), default='uniform_average'\n",
      "            Defines aggregating of multiple output values.\n",
      "            Array-like value defines weights used to average errors.\n",
      "        \n",
      "            'raw_values' :\n",
      "                Returns a full set of errors in case of multioutput input.\n",
      "        \n",
      "            'uniform_average' :\n",
      "                Errors of all outputs are averaged with uniform weight.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : float or ndarray of floats\n",
      "            If multioutput is 'raw_values', then mean absolute error is returned\n",
      "            for each output separately.\n",
      "            If multioutput is 'uniform_average' or an ndarray of weights, then the\n",
      "            weighted average of all output errors is returned.\n",
      "        \n",
      "            The pinball loss output is a non-negative floating point. The best\n",
      "            value is 0.0.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import mean_pinball_loss\n",
      "        >>> y_true = [1, 2, 3]\n",
      "        >>> mean_pinball_loss(y_true, [0, 2, 3], alpha=0.1)\n",
      "        np.float64(0.03...)\n",
      "        >>> mean_pinball_loss(y_true, [1, 2, 4], alpha=0.1)\n",
      "        np.float64(0.3...)\n",
      "        >>> mean_pinball_loss(y_true, [0, 2, 3], alpha=0.9)\n",
      "        np.float64(0.3...)\n",
      "        >>> mean_pinball_loss(y_true, [1, 2, 4], alpha=0.9)\n",
      "        np.float64(0.03...)\n",
      "        >>> mean_pinball_loss(y_true, y_true, alpha=0.1)\n",
      "        np.float64(0.0)\n",
      "        >>> mean_pinball_loss(y_true, y_true, alpha=0.9)\n",
      "        np.float64(0.0)\n",
      "    \n",
      "    mean_poisson_deviance(y_true, y_pred, *, sample_weight=None)\n",
      "        Mean Poisson deviance regression loss.\n",
      "        \n",
      "        Poisson deviance is equivalent to the Tweedie deviance with\n",
      "        the power parameter `power=1`.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <mean_tweedie_deviance>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,)\n",
      "            Ground truth (correct) target values. Requires y_true >= 0.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples,)\n",
      "            Estimated target values. Requires y_pred > 0.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : float\n",
      "            A non-negative floating point value (the best value is 0.0).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import mean_poisson_deviance\n",
      "        >>> y_true = [2, 0, 1, 4]\n",
      "        >>> y_pred = [0.5, 0.5, 2., 2.]\n",
      "        >>> mean_poisson_deviance(y_true, y_pred)\n",
      "        1.4260...\n",
      "    \n",
      "    mean_squared_error(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average')\n",
      "        Mean squared error regression loss.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <mean_squared_error>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Estimated target values.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        multioutput : {'raw_values', 'uniform_average'} or array-like of shape             (n_outputs,), default='uniform_average'\n",
      "            Defines aggregating of multiple output values.\n",
      "            Array-like value defines weights used to average errors.\n",
      "        \n",
      "            'raw_values' :\n",
      "                Returns a full set of errors in case of multioutput input.\n",
      "        \n",
      "            'uniform_average' :\n",
      "                Errors of all outputs are averaged with uniform weight.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : float or array of floats\n",
      "            A non-negative floating point value (the best value is 0.0), or an\n",
      "            array of floating point values, one for each individual target.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import mean_squared_error\n",
      "        >>> y_true = [3, -0.5, 2, 7]\n",
      "        >>> y_pred = [2.5, 0.0, 2, 8]\n",
      "        >>> mean_squared_error(y_true, y_pred)\n",
      "        0.375\n",
      "        >>> y_true = [[0.5, 1],[-1, 1],[7, -6]]\n",
      "        >>> y_pred = [[0, 2],[-1, 2],[8, -5]]\n",
      "        >>> mean_squared_error(y_true, y_pred)\n",
      "        0.708...\n",
      "        >>> mean_squared_error(y_true, y_pred, multioutput='raw_values')\n",
      "        array([0.41666667, 1.        ])\n",
      "        >>> mean_squared_error(y_true, y_pred, multioutput=[0.3, 0.7])\n",
      "        0.825...\n",
      "    \n",
      "    mean_squared_log_error(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average')\n",
      "        Mean squared logarithmic error regression loss.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <mean_squared_log_error>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Estimated target values.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        multioutput : {'raw_values', 'uniform_average'} or array-like of shape             (n_outputs,), default='uniform_average'\n",
      "        \n",
      "            Defines aggregating of multiple output values.\n",
      "            Array-like value defines weights used to average errors.\n",
      "        \n",
      "            'raw_values' :\n",
      "                Returns a full set of errors when the input is of multioutput\n",
      "                format.\n",
      "        \n",
      "            'uniform_average' :\n",
      "                Errors of all outputs are averaged with uniform weight.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : float or ndarray of floats\n",
      "            A non-negative floating point value (the best value is 0.0), or an\n",
      "            array of floating point values, one for each individual target.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import mean_squared_log_error\n",
      "        >>> y_true = [3, 5, 2.5, 7]\n",
      "        >>> y_pred = [2.5, 5, 4, 8]\n",
      "        >>> mean_squared_log_error(y_true, y_pred)\n",
      "        0.039...\n",
      "        >>> y_true = [[0.5, 1], [1, 2], [7, 6]]\n",
      "        >>> y_pred = [[0.5, 2], [1, 2.5], [8, 8]]\n",
      "        >>> mean_squared_log_error(y_true, y_pred)\n",
      "        0.044...\n",
      "        >>> mean_squared_log_error(y_true, y_pred, multioutput='raw_values')\n",
      "        array([0.00462428, 0.08377444])\n",
      "        >>> mean_squared_log_error(y_true, y_pred, multioutput=[0.3, 0.7])\n",
      "        0.060...\n",
      "    \n",
      "    mean_tweedie_deviance(y_true, y_pred, *, sample_weight=None, power=0)\n",
      "        Mean Tweedie deviance regression loss.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <mean_tweedie_deviance>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples,)\n",
      "            Estimated target values.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        power : float, default=0\n",
      "            Tweedie power parameter. Either power <= 0 or power >= 1.\n",
      "        \n",
      "            The higher `p` the less weight is given to extreme\n",
      "            deviations between true and predicted targets.\n",
      "        \n",
      "            - power < 0: Extreme stable distribution. Requires: y_pred > 0.\n",
      "            - power = 0 : Normal distribution, output corresponds to\n",
      "              mean_squared_error. y_true and y_pred can be any real numbers.\n",
      "            - power = 1 : Poisson distribution. Requires: y_true >= 0 and\n",
      "              y_pred > 0.\n",
      "            - 1 < p < 2 : Compound Poisson distribution. Requires: y_true >= 0\n",
      "              and y_pred > 0.\n",
      "            - power = 2 : Gamma distribution. Requires: y_true > 0 and y_pred > 0.\n",
      "            - power = 3 : Inverse Gaussian distribution. Requires: y_true > 0\n",
      "              and y_pred > 0.\n",
      "            - otherwise : Positive stable distribution. Requires: y_true > 0\n",
      "              and y_pred > 0.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : float\n",
      "            A non-negative floating point value (the best value is 0.0).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import mean_tweedie_deviance\n",
      "        >>> y_true = [2, 0, 1, 4]\n",
      "        >>> y_pred = [0.5, 0.5, 2., 2.]\n",
      "        >>> mean_tweedie_deviance(y_true, y_pred, power=1)\n",
      "        1.4260...\n",
      "    \n",
      "    median_absolute_error(y_true, y_pred, *, multioutput='uniform_average', sample_weight=None)\n",
      "        Median absolute error regression loss.\n",
      "        \n",
      "        Median absolute error output is non-negative floating point. The best value\n",
      "        is 0.0. Read more in the :ref:`User Guide <median_absolute_error>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Estimated target values.\n",
      "        \n",
      "        multioutput : {'raw_values', 'uniform_average'} or array-like of shape             (n_outputs,), default='uniform_average'\n",
      "            Defines aggregating of multiple output values. Array-like value defines\n",
      "            weights used to average errors.\n",
      "        \n",
      "            'raw_values' :\n",
      "                Returns a full set of errors in case of multioutput input.\n",
      "        \n",
      "            'uniform_average' :\n",
      "                Errors of all outputs are averaged with uniform weight.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "            .. versionadded:: 0.24\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : float or ndarray of floats\n",
      "            If multioutput is 'raw_values', then mean absolute error is returned\n",
      "            for each output separately.\n",
      "            If multioutput is 'uniform_average' or an ndarray of weights, then the\n",
      "            weighted average of all output errors is returned.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import median_absolute_error\n",
      "        >>> y_true = [3, -0.5, 2, 7]\n",
      "        >>> y_pred = [2.5, 0.0, 2, 8]\n",
      "        >>> median_absolute_error(y_true, y_pred)\n",
      "        np.float64(0.5)\n",
      "        >>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n",
      "        >>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n",
      "        >>> median_absolute_error(y_true, y_pred)\n",
      "        np.float64(0.75)\n",
      "        >>> median_absolute_error(y_true, y_pred, multioutput='raw_values')\n",
      "        array([0.5, 1. ])\n",
      "        >>> median_absolute_error(y_true, y_pred, multioutput=[0.3, 0.7])\n",
      "        np.float64(0.85)\n",
      "    \n",
      "    multilabel_confusion_matrix(y_true, y_pred, *, sample_weight=None, labels=None, samplewise=False)\n",
      "        Compute a confusion matrix for each class or sample.\n",
      "        \n",
      "        .. versionadded:: 0.21\n",
      "        \n",
      "        Compute class-wise (default) or sample-wise (samplewise=True) multilabel\n",
      "        confusion matrix to evaluate the accuracy of a classification, and output\n",
      "        confusion matrices for each class or sample.\n",
      "        \n",
      "        In multilabel confusion matrix :math:`MCM`, the count of true negatives\n",
      "        is :math:`MCM_{:,0,0}`, false negatives is :math:`MCM_{:,1,0}`,\n",
      "        true positives is :math:`MCM_{:,1,1}` and false positives is\n",
      "        :math:`MCM_{:,0,1}`.\n",
      "        \n",
      "        Multiclass data will be treated as if binarized under a one-vs-rest\n",
      "        transformation. Returned confusion matrices will be in the order of\n",
      "        sorted unique labels in the union of (y_true, y_pred).\n",
      "        \n",
      "        Read more in the :ref:`User Guide <multilabel_confusion_matrix>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : {array-like, sparse matrix} of shape (n_samples, n_outputs) or             (n_samples,)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : {array-like, sparse matrix} of shape (n_samples, n_outputs) or             (n_samples,)\n",
      "            Estimated targets as returned by a classifier.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        labels : array-like of shape (n_classes,), default=None\n",
      "            A list of classes or column indices to select some (or to force\n",
      "            inclusion of classes absent from the data).\n",
      "        \n",
      "        samplewise : bool, default=False\n",
      "            In the multilabel case, this calculates a confusion matrix per sample.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        multi_confusion : ndarray of shape (n_outputs, 2, 2)\n",
      "            A 2x2 confusion matrix corresponding to each output in the input.\n",
      "            When calculating class-wise multi_confusion (default), then\n",
      "            n_outputs = n_labels; when calculating sample-wise multi_confusion\n",
      "            (samplewise=True), n_outputs = n_samples. If ``labels`` is defined,\n",
      "            the results will be returned in the order specified in ``labels``,\n",
      "            otherwise the results will be returned in sorted order by default.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        confusion_matrix : Compute confusion matrix to evaluate the accuracy of a\n",
      "            classifier.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The `multilabel_confusion_matrix` calculates class-wise or sample-wise\n",
      "        multilabel confusion matrices, and in multiclass tasks, labels are\n",
      "        binarized under a one-vs-rest way; while\n",
      "        :func:`~sklearn.metrics.confusion_matrix` calculates one confusion matrix\n",
      "        for confusion between every two classes.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Multilabel-indicator case:\n",
      "        \n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.metrics import multilabel_confusion_matrix\n",
      "        >>> y_true = np.array([[1, 0, 1],\n",
      "        ...                    [0, 1, 0]])\n",
      "        >>> y_pred = np.array([[1, 0, 0],\n",
      "        ...                    [0, 1, 1]])\n",
      "        >>> multilabel_confusion_matrix(y_true, y_pred)\n",
      "        array([[[1, 0],\n",
      "                [0, 1]],\n",
      "        <BLANKLINE>\n",
      "               [[1, 0],\n",
      "                [0, 1]],\n",
      "        <BLANKLINE>\n",
      "               [[0, 1],\n",
      "                [1, 0]]])\n",
      "        \n",
      "        Multiclass case:\n",
      "        \n",
      "        >>> y_true = [\"cat\", \"ant\", \"cat\", \"cat\", \"ant\", \"bird\"]\n",
      "        >>> y_pred = [\"ant\", \"ant\", \"cat\", \"cat\", \"ant\", \"cat\"]\n",
      "        >>> multilabel_confusion_matrix(y_true, y_pred,\n",
      "        ...                             labels=[\"ant\", \"bird\", \"cat\"])\n",
      "        array([[[3, 1],\n",
      "                [0, 2]],\n",
      "        <BLANKLINE>\n",
      "               [[5, 0],\n",
      "                [1, 0]],\n",
      "        <BLANKLINE>\n",
      "               [[2, 1],\n",
      "                [1, 2]]])\n",
      "    \n",
      "    mutual_info_score(labels_true, labels_pred, *, contingency=None)\n",
      "        Mutual Information between two clusterings.\n",
      "        \n",
      "        The Mutual Information is a measure of the similarity between two labels\n",
      "        of the same data. Where :math:`|U_i|` is the number of the samples\n",
      "        in cluster :math:`U_i` and :math:`|V_j|` is the number of the\n",
      "        samples in cluster :math:`V_j`, the Mutual Information\n",
      "        between clusterings :math:`U` and :math:`V` is given as:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            MI(U,V)=\\sum_{i=1}^{|U|} \\sum_{j=1}^{|V|} \\frac{|U_i\\cap V_j|}{N}\n",
      "            \\log\\frac{N|U_i \\cap V_j|}{|U_i||V_j|}\n",
      "        \n",
      "        This metric is independent of the absolute values of the labels:\n",
      "        a permutation of the class or cluster label values won't change the\n",
      "        score value in any way.\n",
      "        \n",
      "        This metric is furthermore symmetric: switching :math:`U` (i.e\n",
      "        ``label_true``) with :math:`V` (i.e. ``label_pred``) will return the\n",
      "        same score value. This can be useful to measure the agreement of two\n",
      "        independent label assignments strategies on the same dataset when the\n",
      "        real ground truth is not known.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <mutual_info_score>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        labels_true : array-like of shape (n_samples,), dtype=integral\n",
      "            A clustering of the data into disjoint subsets, called :math:`U` in\n",
      "            the above formula.\n",
      "        \n",
      "        labels_pred : array-like of shape (n_samples,), dtype=integral\n",
      "            A clustering of the data into disjoint subsets, called :math:`V` in\n",
      "            the above formula.\n",
      "        \n",
      "        contingency : {array-like, sparse matrix} of shape             (n_classes_true, n_classes_pred), default=None\n",
      "            A contingency matrix given by the\n",
      "            :func:`~sklearn.metrics.cluster.contingency_matrix` function. If value\n",
      "            is ``None``, it will be computed, otherwise the given value is used,\n",
      "            with ``labels_true`` and ``labels_pred`` ignored.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        mi : float\n",
      "           Mutual information, a non-negative value, measured in nats using the\n",
      "           natural logarithm.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        adjusted_mutual_info_score : Adjusted against chance Mutual Information.\n",
      "        normalized_mutual_info_score : Normalized Mutual Information.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The logarithm used is the natural logarithm (base-e).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import mutual_info_score\n",
      "        >>> labels_true = [0, 1, 1, 0, 1, 0]\n",
      "        >>> labels_pred = [0, 1, 0, 0, 1, 1]\n",
      "        >>> mutual_info_score(labels_true, labels_pred)\n",
      "        np.float64(0.056...)\n",
      "    \n",
      "    nan_euclidean_distances(X, Y=None, *, squared=False, missing_values=nan, copy=True)\n",
      "        Calculate the euclidean distances in the presence of missing values.\n",
      "        \n",
      "        Compute the euclidean distance between each pair of samples in X and Y,\n",
      "        where Y=X is assumed if Y=None. When calculating the distance between a\n",
      "        pair of samples, this formulation ignores feature coordinates with a\n",
      "        missing value in either sample and scales up the weight of the remaining\n",
      "        coordinates:\n",
      "        \n",
      "        .. code-block:: text\n",
      "        \n",
      "            dist(x,y) = sqrt(weight * sq. distance from present coordinates)\n",
      "        \n",
      "        where:\n",
      "        \n",
      "        .. code-block:: text\n",
      "        \n",
      "            weight = Total # of coordinates / # of present coordinates\n",
      "        \n",
      "        For example, the distance between ``[3, na, na, 6]`` and ``[1, na, 4, 5]`` is:\n",
      "        \n",
      "        .. math::\n",
      "            \\sqrt{\\frac{4}{2}((3-1)^2 + (6-5)^2)}\n",
      "        \n",
      "        If all the coordinates are missing or if there are no common present\n",
      "        coordinates then NaN is returned for that pair.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <metrics>`.\n",
      "        \n",
      "        .. versionadded:: 0.22\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like of shape (n_samples_X, n_features)\n",
      "            An array where each row is a sample and each column is a feature.\n",
      "        \n",
      "        Y : array-like of shape (n_samples_Y, n_features), default=None\n",
      "            An array where each row is a sample and each column is a feature.\n",
      "            If `None`, method uses `Y=X`.\n",
      "        \n",
      "        squared : bool, default=False\n",
      "            Return squared Euclidean distances.\n",
      "        \n",
      "        missing_values : np.nan, float or int, default=np.nan\n",
      "            Representation of missing value.\n",
      "        \n",
      "        copy : bool, default=True\n",
      "            Make and use a deep copy of X and Y (if Y exists).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        distances : ndarray of shape (n_samples_X, n_samples_Y)\n",
      "            Returns the distances between the row vectors of `X`\n",
      "            and the row vectors of `Y`.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        paired_distances : Distances between pairs of elements of X and Y.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        * John K. Dixon, \"Pattern Recognition with Partly Missing Data\",\n",
      "          IEEE Transactions on Systems, Man, and Cybernetics, Volume: 9, Issue:\n",
      "          10, pp. 617 - 621, Oct. 1979.\n",
      "          http://ieeexplore.ieee.org/abstract/document/4310090/\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics.pairwise import nan_euclidean_distances\n",
      "        >>> nan = float(\"NaN\")\n",
      "        >>> X = [[0, 1], [1, nan]]\n",
      "        >>> nan_euclidean_distances(X, X) # distance between rows of X\n",
      "        array([[0.        , 1.41421356],\n",
      "               [1.41421356, 0.        ]])\n",
      "        \n",
      "        >>> # get distance to origin\n",
      "        >>> nan_euclidean_distances(X, [[0, 0]])\n",
      "        array([[1.        ],\n",
      "               [1.41421356]])\n",
      "    \n",
      "    ndcg_score(y_true, y_score, *, k=None, sample_weight=None, ignore_ties=False)\n",
      "        Compute Normalized Discounted Cumulative Gain.\n",
      "        \n",
      "        Sum the true scores ranked in the order induced by the predicted scores,\n",
      "        after applying a logarithmic discount. Then divide by the best possible\n",
      "        score (Ideal DCG, obtained for a perfect ranking) to obtain a score between\n",
      "        0 and 1.\n",
      "        \n",
      "        This ranking metric returns a high value if true labels are ranked high by\n",
      "        ``y_score``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples, n_labels)\n",
      "            True targets of multilabel classification, or true scores of entities\n",
      "            to be ranked. Negative values in `y_true` may result in an output\n",
      "            that is not between 0 and 1.\n",
      "        \n",
      "        y_score : array-like of shape (n_samples, n_labels)\n",
      "            Target scores, can either be probability estimates, confidence values,\n",
      "            or non-thresholded measure of decisions (as returned by\n",
      "            \"decision_function\" on some classifiers).\n",
      "        \n",
      "        k : int, default=None\n",
      "            Only consider the highest k scores in the ranking. If `None`, use all\n",
      "            outputs.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights. If `None`, all samples are given the same weight.\n",
      "        \n",
      "        ignore_ties : bool, default=False\n",
      "            Assume that there are no ties in y_score (which is likely to be the\n",
      "            case if y_score is continuous) for efficiency gains.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        normalized_discounted_cumulative_gain : float in [0., 1.]\n",
      "            The averaged NDCG scores for all samples.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        dcg_score : Discounted Cumulative Gain (not normalized).\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        `Wikipedia entry for Discounted Cumulative Gain\n",
      "        <https://en.wikipedia.org/wiki/Discounted_cumulative_gain>`_\n",
      "        \n",
      "        Jarvelin, K., & Kekalainen, J. (2002).\n",
      "        Cumulated gain-based evaluation of IR techniques. ACM Transactions on\n",
      "        Information Systems (TOIS), 20(4), 422-446.\n",
      "        \n",
      "        Wang, Y., Wang, L., Li, Y., He, D., Chen, W., & Liu, T. Y. (2013, May).\n",
      "        A theoretical analysis of NDCG ranking measures. In Proceedings of the 26th\n",
      "        Annual Conference on Learning Theory (COLT 2013)\n",
      "        \n",
      "        McSherry, F., & Najork, M. (2008, March). Computing information retrieval\n",
      "        performance measures efficiently in the presence of tied scores. In\n",
      "        European conference on information retrieval (pp. 414-421). Springer,\n",
      "        Berlin, Heidelberg.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.metrics import ndcg_score\n",
      "        >>> # we have ground-truth relevance of some answers to a query:\n",
      "        >>> true_relevance = np.asarray([[10, 0, 0, 1, 5]])\n",
      "        >>> # we predict some scores (relevance) for the answers\n",
      "        >>> scores = np.asarray([[.1, .2, .3, 4, 70]])\n",
      "        >>> ndcg_score(true_relevance, scores)\n",
      "        np.float64(0.69...)\n",
      "        >>> scores = np.asarray([[.05, 1.1, 1., .5, .0]])\n",
      "        >>> ndcg_score(true_relevance, scores)\n",
      "        np.float64(0.49...)\n",
      "        >>> # we can set k to truncate the sum; only top k answers contribute.\n",
      "        >>> ndcg_score(true_relevance, scores, k=4)\n",
      "        np.float64(0.35...)\n",
      "        >>> # the normalization takes k into account so a perfect answer\n",
      "        >>> # would still get 1.0\n",
      "        >>> ndcg_score(true_relevance, true_relevance, k=4)\n",
      "        np.float64(1.0...)\n",
      "        >>> # now we have some ties in our prediction\n",
      "        >>> scores = np.asarray([[1, 0, 0, 0, 1]])\n",
      "        >>> # by default ties are averaged, so here we get the average (normalized)\n",
      "        >>> # true relevance of our top predictions: (10 / 10 + 5 / 10) / 2 = .75\n",
      "        >>> ndcg_score(true_relevance, scores, k=1)\n",
      "        np.float64(0.75...)\n",
      "        >>> # we can choose to ignore ties for faster results, but only\n",
      "        >>> # if we know there aren't ties in our scores, otherwise we get\n",
      "        >>> # wrong results:\n",
      "        >>> ndcg_score(true_relevance,\n",
      "        ...           scores, k=1, ignore_ties=True)\n",
      "        np.float64(0.5...)\n",
      "    \n",
      "    normalized_mutual_info_score(labels_true, labels_pred, *, average_method='arithmetic')\n",
      "        Normalized Mutual Information between two clusterings.\n",
      "        \n",
      "        Normalized Mutual Information (NMI) is a normalization of the Mutual\n",
      "        Information (MI) score to scale the results between 0 (no mutual\n",
      "        information) and 1 (perfect correlation). In this function, mutual\n",
      "        information is normalized by some generalized mean of ``H(labels_true)``\n",
      "        and ``H(labels_pred))``, defined by the `average_method`.\n",
      "        \n",
      "        This measure is not adjusted for chance. Therefore\n",
      "        :func:`adjusted_mutual_info_score` might be preferred.\n",
      "        \n",
      "        This metric is independent of the absolute values of the labels:\n",
      "        a permutation of the class or cluster label values won't change the\n",
      "        score value in any way.\n",
      "        \n",
      "        This metric is furthermore symmetric: switching ``label_true`` with\n",
      "        ``label_pred`` will return the same score value. This can be useful to\n",
      "        measure the agreement of two independent label assignments strategies\n",
      "        on the same dataset when the real ground truth is not known.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <mutual_info_score>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        labels_true : int array-like of shape (n_samples,)\n",
      "            A clustering of the data into disjoint subsets.\n",
      "        \n",
      "        labels_pred : int array-like of shape (n_samples,)\n",
      "            A clustering of the data into disjoint subsets.\n",
      "        \n",
      "        average_method : {'min', 'geometric', 'arithmetic', 'max'}, default='arithmetic'\n",
      "            How to compute the normalizer in the denominator.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "            .. versionchanged:: 0.22\n",
      "               The default value of ``average_method`` changed from 'geometric' to\n",
      "               'arithmetic'.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        nmi : float\n",
      "           Score between 0.0 and 1.0 in normalized nats (based on the natural\n",
      "           logarithm). 1.0 stands for perfectly complete labeling.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        v_measure_score : V-Measure (NMI with arithmetic mean option).\n",
      "        adjusted_rand_score : Adjusted Rand Index.\n",
      "        adjusted_mutual_info_score : Adjusted Mutual Information (adjusted\n",
      "            against chance).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        \n",
      "        Perfect labelings are both homogeneous and complete, hence have\n",
      "        score 1.0::\n",
      "        \n",
      "          >>> from sklearn.metrics.cluster import normalized_mutual_info_score\n",
      "          >>> normalized_mutual_info_score([0, 0, 1, 1], [0, 0, 1, 1])\n",
      "          ... # doctest: +SKIP\n",
      "          1.0\n",
      "          >>> normalized_mutual_info_score([0, 0, 1, 1], [1, 1, 0, 0])\n",
      "          ... # doctest: +SKIP\n",
      "          1.0\n",
      "        \n",
      "        If classes members are completely split across different clusters,\n",
      "        the assignment is totally in-complete, hence the NMI is null::\n",
      "        \n",
      "          >>> normalized_mutual_info_score([0, 0, 0, 0], [0, 1, 2, 3])\n",
      "          ... # doctest: +SKIP\n",
      "          0.0\n",
      "    \n",
      "    pair_confusion_matrix(labels_true, labels_pred)\n",
      "        Pair confusion matrix arising from two clusterings.\n",
      "        \n",
      "        The pair confusion matrix :math:`C` computes a 2 by 2 similarity matrix\n",
      "        between two clusterings by considering all pairs of samples and counting\n",
      "        pairs that are assigned into the same or into different clusters under\n",
      "        the true and predicted clusterings [1]_.\n",
      "        \n",
      "        Considering a pair of samples that is clustered together a positive pair,\n",
      "        then as in binary classification the count of true negatives is\n",
      "        :math:`C_{00}`, false negatives is :math:`C_{10}`, true positives is\n",
      "        :math:`C_{11}` and false positives is :math:`C_{01}`.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <pair_confusion_matrix>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        labels_true : array-like of shape (n_samples,), dtype=integral\n",
      "            Ground truth class labels to be used as a reference.\n",
      "        \n",
      "        labels_pred : array-like of shape (n_samples,), dtype=integral\n",
      "            Cluster labels to evaluate.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        C : ndarray of shape (2, 2), dtype=np.int64\n",
      "            The contingency matrix.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        sklearn.metrics.rand_score : Rand Score.\n",
      "        sklearn.metrics.adjusted_rand_score : Adjusted Rand Score.\n",
      "        sklearn.metrics.adjusted_mutual_info_score : Adjusted Mutual Information.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] :doi:`Hubert, L., Arabie, P. \"Comparing partitions.\"\n",
      "               Journal of Classification 2, 193–218 (1985).\n",
      "               <10.1007/BF01908075>`\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Perfectly matching labelings have all non-zero entries on the\n",
      "        diagonal regardless of actual label values:\n",
      "        \n",
      "          >>> from sklearn.metrics.cluster import pair_confusion_matrix\n",
      "          >>> pair_confusion_matrix([0, 0, 1, 1], [1, 1, 0, 0])\n",
      "          array([[8, 0],\n",
      "                 [0, 4]]...\n",
      "        \n",
      "        Labelings that assign all classes members to the same clusters\n",
      "        are complete but may be not always pure, hence penalized, and\n",
      "        have some off-diagonal non-zero entries:\n",
      "        \n",
      "          >>> pair_confusion_matrix([0, 0, 1, 2], [0, 0, 1, 1])\n",
      "          array([[8, 2],\n",
      "                 [0, 2]]...\n",
      "        \n",
      "        Note that the matrix is not symmetric.\n",
      "    \n",
      "    pairwise_distances(X, Y=None, metric='euclidean', *, n_jobs=None, force_all_finite='deprecated', ensure_all_finite=None, **kwds)\n",
      "        Compute the distance matrix from a vector array X and optional Y.\n",
      "        \n",
      "        This method takes either a vector array or a distance matrix, and returns\n",
      "        a distance matrix.\n",
      "        If the input is a vector array, the distances are computed.\n",
      "        If the input is a distances matrix, it is returned instead.\n",
      "        If the input is a collection of non-numeric data (e.g. a list of strings or a\n",
      "        boolean array), a custom metric must be passed.\n",
      "        \n",
      "        This method provides a safe way to take a distance matrix as input, while\n",
      "        preserving compatibility with many other algorithms that take a vector\n",
      "        array.\n",
      "        \n",
      "        If Y is given (default is None), then the returned matrix is the pairwise\n",
      "        distance between the arrays from both X and Y.\n",
      "        \n",
      "        Valid values for metric are:\n",
      "        \n",
      "        - From scikit-learn: ['cityblock', 'cosine', 'euclidean', 'l1', 'l2',\n",
      "          'manhattan']. These metrics support sparse matrix\n",
      "          inputs.\n",
      "          ['nan_euclidean'] but it does not yet support sparse matrices.\n",
      "        \n",
      "        - From scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev',\n",
      "          'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis',\n",
      "          'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean',\n",
      "          'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule']\n",
      "          See the documentation for scipy.spatial.distance for details on these\n",
      "          metrics. These metrics do not support sparse matrix inputs.\n",
      "        \n",
      "        .. note::\n",
      "            `'kulsinski'` is deprecated from SciPy 1.9 and will be removed in SciPy 1.11.\n",
      "        \n",
      "        .. note::\n",
      "            `'matching'` has been removed in SciPy 1.9 (use `'hamming'` instead).\n",
      "        \n",
      "        Note that in the case of 'cityblock', 'cosine' and 'euclidean' (which are\n",
      "        valid scipy.spatial.distance metrics), the scikit-learn implementation\n",
      "        will be used, which is faster and has support for sparse matrices (except\n",
      "        for 'cityblock'). For a verbose description of the metrics from\n",
      "        scikit-learn, see :func:`sklearn.metrics.pairwise.distance_metrics`\n",
      "        function.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <metrics>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples_X, n_samples_X) or             (n_samples_X, n_features)\n",
      "            Array of pairwise distances between samples, or a feature array.\n",
      "            The shape of the array should be (n_samples_X, n_samples_X) if\n",
      "            metric == \"precomputed\" and (n_samples_X, n_features) otherwise.\n",
      "        \n",
      "        Y : {array-like, sparse matrix} of shape (n_samples_Y, n_features), default=None\n",
      "            An optional second feature array. Only allowed if\n",
      "            metric != \"precomputed\".\n",
      "        \n",
      "        metric : str or callable, default='euclidean'\n",
      "            The metric to use when calculating distance between instances in a\n",
      "            feature array. If metric is a string, it must be one of the options\n",
      "            allowed by scipy.spatial.distance.pdist for its metric parameter, or\n",
      "            a metric listed in ``pairwise.PAIRWISE_DISTANCE_FUNCTIONS``.\n",
      "            If metric is \"precomputed\", X is assumed to be a distance matrix.\n",
      "            Alternatively, if metric is a callable function, it is called on each\n",
      "            pair of instances (rows) and the resulting value recorded. The callable\n",
      "            should take two arrays from X as input and return a value indicating\n",
      "            the distance between them.\n",
      "        \n",
      "        n_jobs : int, default=None\n",
      "            The number of jobs to use for the computation. This works by breaking\n",
      "            down the pairwise matrix into n_jobs even slices and computing them\n",
      "            using multithreading.\n",
      "        \n",
      "            ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "            ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "            for more details.\n",
      "        \n",
      "            The \"euclidean\" and \"cosine\" metrics rely heavily on BLAS which is already\n",
      "            multithreaded. So, increasing `n_jobs` would likely cause oversubscription\n",
      "            and quickly degrade performance.\n",
      "        \n",
      "        force_all_finite : bool or 'allow-nan', default=True\n",
      "            Whether to raise an error on np.inf, np.nan, pd.NA in array. Ignored\n",
      "            for a metric listed in ``pairwise.PAIRWISE_DISTANCE_FUNCTIONS``. The\n",
      "            possibilities are:\n",
      "        \n",
      "            - True: Force all values of array to be finite.\n",
      "            - False: accepts np.inf, np.nan, pd.NA in array.\n",
      "            - 'allow-nan': accepts only np.nan and pd.NA values in array. Values\n",
      "              cannot be infinite.\n",
      "        \n",
      "            .. versionadded:: 0.22\n",
      "               ``force_all_finite`` accepts the string ``'allow-nan'``.\n",
      "        \n",
      "            .. versionchanged:: 0.23\n",
      "               Accepts `pd.NA` and converts it into `np.nan`.\n",
      "        \n",
      "            .. deprecated:: 1.6\n",
      "               `force_all_finite` was renamed to `ensure_all_finite` and will be removed\n",
      "               in 1.8.\n",
      "        \n",
      "        ensure_all_finite : bool or 'allow-nan', default=True\n",
      "            Whether to raise an error on np.inf, np.nan, pd.NA in array. Ignored\n",
      "            for a metric listed in ``pairwise.PAIRWISE_DISTANCE_FUNCTIONS``. The\n",
      "            possibilities are:\n",
      "        \n",
      "            - True: Force all values of array to be finite.\n",
      "            - False: accepts np.inf, np.nan, pd.NA in array.\n",
      "            - 'allow-nan': accepts only np.nan and pd.NA values in array. Values\n",
      "              cannot be infinite.\n",
      "        \n",
      "            .. versionadded:: 1.6\n",
      "               `force_all_finite` was renamed to `ensure_all_finite`.\n",
      "        \n",
      "        **kwds : optional keyword parameters\n",
      "            Any further parameters are passed directly to the distance function.\n",
      "            If using a scipy.spatial.distance metric, the parameters are still\n",
      "            metric dependent. See the scipy docs for usage examples.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        D : ndarray of shape (n_samples_X, n_samples_X) or             (n_samples_X, n_samples_Y)\n",
      "            A distance matrix D such that D_{i, j} is the distance between the\n",
      "            ith and jth vectors of the given matrix X, if Y is None.\n",
      "            If Y is not None, then D_{i, j} is the distance between the ith array\n",
      "            from X and the jth array from Y.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        pairwise_distances_chunked : Performs the same calculation as this\n",
      "            function, but returns a generator of chunks of the distance matrix, in\n",
      "            order to limit memory usage.\n",
      "        sklearn.metrics.pairwise.paired_distances : Computes the distances between\n",
      "            corresponding elements of two arrays.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics.pairwise import pairwise_distances\n",
      "        >>> X = [[0, 0, 0], [1, 1, 1]]\n",
      "        >>> Y = [[1, 0, 0], [1, 1, 0]]\n",
      "        >>> pairwise_distances(X, Y, metric='sqeuclidean')\n",
      "        array([[1., 2.],\n",
      "               [2., 1.]])\n",
      "    \n",
      "    pairwise_distances_argmin(X, Y, *, axis=1, metric='euclidean', metric_kwargs=None)\n",
      "        Compute minimum distances between one point and a set of points.\n",
      "        \n",
      "        This function computes for each row in X, the index of the row of Y which\n",
      "        is closest (according to the specified distance).\n",
      "        \n",
      "        This is mostly equivalent to calling::\n",
      "        \n",
      "            pairwise_distances(X, Y=Y, metric=metric).argmin(axis=axis)\n",
      "        \n",
      "        but uses much less memory, and is faster for large arrays.\n",
      "        \n",
      "        This function works with dense 2D arrays only.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples_X, n_features)\n",
      "            Array containing points.\n",
      "        \n",
      "        Y : {array-like, sparse matrix} of shape (n_samples_Y, n_features)\n",
      "            Arrays containing points.\n",
      "        \n",
      "        axis : int, default=1\n",
      "            Axis along which the argmin and distances are to be computed.\n",
      "        \n",
      "        metric : str or callable, default=\"euclidean\"\n",
      "            Metric to use for distance computation. Any metric from scikit-learn\n",
      "            or scipy.spatial.distance can be used.\n",
      "        \n",
      "            If metric is a callable function, it is called on each\n",
      "            pair of instances (rows) and the resulting value recorded. The callable\n",
      "            should take two arrays as input and return one value indicating the\n",
      "            distance between them. This works for Scipy's metrics, but is less\n",
      "            efficient than passing the metric name as a string.\n",
      "        \n",
      "            Distance matrices are not supported.\n",
      "        \n",
      "            Valid values for metric are:\n",
      "        \n",
      "            - from scikit-learn: ['cityblock', 'cosine', 'euclidean', 'l1', 'l2',\n",
      "              'manhattan', 'nan_euclidean']\n",
      "        \n",
      "            - from scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev',\n",
      "              'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski',\n",
      "              'mahalanobis', 'minkowski', 'rogerstanimoto', 'russellrao',\n",
      "              'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean',\n",
      "              'yule']\n",
      "        \n",
      "            See the documentation for scipy.spatial.distance for details on these\n",
      "            metrics.\n",
      "        \n",
      "            .. note::\n",
      "               `'kulsinski'` is deprecated from SciPy 1.9 and will be removed in SciPy 1.11.\n",
      "        \n",
      "            .. note::\n",
      "               `'matching'` has been removed in SciPy 1.9 (use `'hamming'` instead).\n",
      "        \n",
      "        metric_kwargs : dict, default=None\n",
      "            Keyword arguments to pass to specified metric function.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        argmin : numpy.ndarray\n",
      "            Y[argmin[i], :] is the row in Y that is closest to X[i, :].\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        pairwise_distances : Distances between every pair of samples of X and Y.\n",
      "        pairwise_distances_argmin_min : Same as `pairwise_distances_argmin` but also\n",
      "            returns the distances.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
      "        >>> X = [[0, 0, 0], [1, 1, 1]]\n",
      "        >>> Y = [[1, 0, 0], [1, 1, 0]]\n",
      "        >>> pairwise_distances_argmin(X, Y)\n",
      "        array([0, 1])\n",
      "    \n",
      "    pairwise_distances_argmin_min(X, Y, *, axis=1, metric='euclidean', metric_kwargs=None)\n",
      "        Compute minimum distances between one point and a set of points.\n",
      "        \n",
      "        This function computes for each row in X, the index of the row of Y which\n",
      "        is closest (according to the specified distance). The minimal distances are\n",
      "        also returned.\n",
      "        \n",
      "        This is mostly equivalent to calling::\n",
      "        \n",
      "            (pairwise_distances(X, Y=Y, metric=metric).argmin(axis=axis),\n",
      "             pairwise_distances(X, Y=Y, metric=metric).min(axis=axis))\n",
      "        \n",
      "        but uses much less memory, and is faster for large arrays.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples_X, n_features)\n",
      "            Array containing points.\n",
      "        \n",
      "        Y : {array-like, sparse matrix} of shape (n_samples_Y, n_features)\n",
      "            Array containing points.\n",
      "        \n",
      "        axis : int, default=1\n",
      "            Axis along which the argmin and distances are to be computed.\n",
      "        \n",
      "        metric : str or callable, default='euclidean'\n",
      "            Metric to use for distance computation. Any metric from scikit-learn\n",
      "            or scipy.spatial.distance can be used.\n",
      "        \n",
      "            If metric is a callable function, it is called on each\n",
      "            pair of instances (rows) and the resulting value recorded. The callable\n",
      "            should take two arrays as input and return one value indicating the\n",
      "            distance between them. This works for Scipy's metrics, but is less\n",
      "            efficient than passing the metric name as a string.\n",
      "        \n",
      "            Distance matrices are not supported.\n",
      "        \n",
      "            Valid values for metric are:\n",
      "        \n",
      "            - from scikit-learn: ['cityblock', 'cosine', 'euclidean', 'l1', 'l2',\n",
      "              'manhattan', 'nan_euclidean']\n",
      "        \n",
      "            - from scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev',\n",
      "              'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski',\n",
      "              'mahalanobis', 'minkowski', 'rogerstanimoto', 'russellrao',\n",
      "              'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean',\n",
      "              'yule']\n",
      "        \n",
      "            See the documentation for scipy.spatial.distance for details on these\n",
      "            metrics.\n",
      "        \n",
      "            .. note::\n",
      "               `'kulsinski'` is deprecated from SciPy 1.9 and will be removed in SciPy 1.11.\n",
      "        \n",
      "            .. note::\n",
      "               `'matching'` has been removed in SciPy 1.9 (use `'hamming'` instead).\n",
      "        \n",
      "        metric_kwargs : dict, default=None\n",
      "            Keyword arguments to pass to specified metric function.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        argmin : ndarray\n",
      "            Y[argmin[i], :] is the row in Y that is closest to X[i, :].\n",
      "        \n",
      "        distances : ndarray\n",
      "            The array of minimum distances. `distances[i]` is the distance between\n",
      "            the i-th row in X and the argmin[i]-th row in Y.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        pairwise_distances : Distances between every pair of samples of X and Y.\n",
      "        pairwise_distances_argmin : Same as `pairwise_distances_argmin_min` but only\n",
      "            returns the argmins.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics.pairwise import pairwise_distances_argmin_min\n",
      "        >>> X = [[0, 0, 0], [1, 1, 1]]\n",
      "        >>> Y = [[1, 0, 0], [1, 1, 0]]\n",
      "        >>> argmin, distances = pairwise_distances_argmin_min(X, Y)\n",
      "        >>> argmin\n",
      "        array([0, 1])\n",
      "        >>> distances\n",
      "        array([1., 1.])\n",
      "    \n",
      "    pairwise_distances_chunked(X, Y=None, *, reduce_func=None, metric='euclidean', n_jobs=None, working_memory=None, **kwds)\n",
      "        Generate a distance matrix chunk by chunk with optional reduction.\n",
      "        \n",
      "        In cases where not all of a pairwise distance matrix needs to be\n",
      "        stored at once, this is used to calculate pairwise distances in\n",
      "        ``working_memory``-sized chunks.  If ``reduce_func`` is given, it is\n",
      "        run on each chunk and its return values are concatenated into lists,\n",
      "        arrays or sparse matrices.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples_X, n_samples_X) or             (n_samples_X, n_features)\n",
      "            Array of pairwise distances between samples, or a feature array.\n",
      "            The shape the array should be (n_samples_X, n_samples_X) if\n",
      "            metric='precomputed' and (n_samples_X, n_features) otherwise.\n",
      "        \n",
      "        Y : {array-like, sparse matrix} of shape (n_samples_Y, n_features), default=None\n",
      "            An optional second feature array. Only allowed if\n",
      "            metric != \"precomputed\".\n",
      "        \n",
      "        reduce_func : callable, default=None\n",
      "            The function which is applied on each chunk of the distance matrix,\n",
      "            reducing it to needed values.  ``reduce_func(D_chunk, start)``\n",
      "            is called repeatedly, where ``D_chunk`` is a contiguous vertical\n",
      "            slice of the pairwise distance matrix, starting at row ``start``.\n",
      "            It should return one of: None; an array, a list, or a sparse matrix\n",
      "            of length ``D_chunk.shape[0]``; or a tuple of such objects.\n",
      "            Returning None is useful for in-place operations, rather than\n",
      "            reductions.\n",
      "        \n",
      "            If None, pairwise_distances_chunked returns a generator of vertical\n",
      "            chunks of the distance matrix.\n",
      "        \n",
      "        metric : str or callable, default='euclidean'\n",
      "            The metric to use when calculating distance between instances in a\n",
      "            feature array. If metric is a string, it must be one of the options\n",
      "            allowed by scipy.spatial.distance.pdist for its metric parameter,\n",
      "            or a metric listed in pairwise.PAIRWISE_DISTANCE_FUNCTIONS.\n",
      "            If metric is \"precomputed\", X is assumed to be a distance matrix.\n",
      "            Alternatively, if metric is a callable function, it is called on\n",
      "            each pair of instances (rows) and the resulting value recorded.\n",
      "            The callable should take two arrays from X as input and return a\n",
      "            value indicating the distance between them.\n",
      "        \n",
      "        n_jobs : int, default=None\n",
      "            The number of jobs to use for the computation. This works by\n",
      "            breaking down the pairwise matrix into n_jobs even slices and\n",
      "            computing them in parallel.\n",
      "        \n",
      "            ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "            ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "            for more details.\n",
      "        \n",
      "        working_memory : float, default=None\n",
      "            The sought maximum memory for temporary distance matrix chunks.\n",
      "            When None (default), the value of\n",
      "            ``sklearn.get_config()['working_memory']`` is used.\n",
      "        \n",
      "        **kwds : optional keyword parameters\n",
      "            Any further parameters are passed directly to the distance function.\n",
      "            If using a scipy.spatial.distance metric, the parameters are still\n",
      "            metric dependent. See the scipy docs for usage examples.\n",
      "        \n",
      "        Yields\n",
      "        ------\n",
      "        D_chunk : {ndarray, sparse matrix}\n",
      "            A contiguous slice of distance matrix, optionally processed by\n",
      "            ``reduce_func``.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Without reduce_func:\n",
      "        \n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.metrics import pairwise_distances_chunked\n",
      "        >>> X = np.random.RandomState(0).rand(5, 3)\n",
      "        >>> D_chunk = next(pairwise_distances_chunked(X))\n",
      "        >>> D_chunk\n",
      "        array([[0.  ..., 0.29..., 0.41..., 0.19..., 0.57...],\n",
      "               [0.29..., 0.  ..., 0.57..., 0.41..., 0.76...],\n",
      "               [0.41..., 0.57..., 0.  ..., 0.44..., 0.90...],\n",
      "               [0.19..., 0.41..., 0.44..., 0.  ..., 0.51...],\n",
      "               [0.57..., 0.76..., 0.90..., 0.51..., 0.  ...]])\n",
      "        \n",
      "        Retrieve all neighbors and average distance within radius r:\n",
      "        \n",
      "        >>> r = .2\n",
      "        >>> def reduce_func(D_chunk, start):\n",
      "        ...     neigh = [np.flatnonzero(d < r) for d in D_chunk]\n",
      "        ...     avg_dist = (D_chunk * (D_chunk < r)).mean(axis=1)\n",
      "        ...     return neigh, avg_dist\n",
      "        >>> gen = pairwise_distances_chunked(X, reduce_func=reduce_func)\n",
      "        >>> neigh, avg_dist = next(gen)\n",
      "        >>> neigh\n",
      "        [array([0, 3]), array([1]), array([2]), array([0, 3]), array([4])]\n",
      "        >>> avg_dist\n",
      "        array([0.039..., 0.        , 0.        , 0.039..., 0.        ])\n",
      "        \n",
      "        Where r is defined per sample, we need to make use of ``start``:\n",
      "        \n",
      "        >>> r = [.2, .4, .4, .3, .1]\n",
      "        >>> def reduce_func(D_chunk, start):\n",
      "        ...     neigh = [np.flatnonzero(d < r[i])\n",
      "        ...              for i, d in enumerate(D_chunk, start)]\n",
      "        ...     return neigh\n",
      "        >>> neigh = next(pairwise_distances_chunked(X, reduce_func=reduce_func))\n",
      "        >>> neigh\n",
      "        [array([0, 3]), array([0, 1]), array([2]), array([0, 3]), array([4])]\n",
      "        \n",
      "        Force row-by-row generation by reducing ``working_memory``:\n",
      "        \n",
      "        >>> gen = pairwise_distances_chunked(X, reduce_func=reduce_func,\n",
      "        ...                                  working_memory=0)\n",
      "        >>> next(gen)\n",
      "        [array([0, 3])]\n",
      "        >>> next(gen)\n",
      "        [array([0, 1])]\n",
      "    \n",
      "    pairwise_kernels(X, Y=None, metric='linear', *, filter_params=False, n_jobs=None, **kwds)\n",
      "        Compute the kernel between arrays X and optional array Y.\n",
      "        \n",
      "        This method takes either a vector array or a kernel matrix, and returns\n",
      "        a kernel matrix. If the input is a vector array, the kernels are\n",
      "        computed. If the input is a kernel matrix, it is returned instead.\n",
      "        \n",
      "        This method provides a safe way to take a kernel matrix as input, while\n",
      "        preserving compatibility with many other algorithms that take a vector\n",
      "        array.\n",
      "        \n",
      "        If Y is given (default is None), then the returned matrix is the pairwise\n",
      "        kernel between the arrays from both X and Y.\n",
      "        \n",
      "        Valid values for metric are:\n",
      "            ['additive_chi2', 'chi2', 'linear', 'poly', 'polynomial', 'rbf',\n",
      "            'laplacian', 'sigmoid', 'cosine']\n",
      "        \n",
      "        Read more in the :ref:`User Guide <metrics>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix}  of shape (n_samples_X, n_samples_X) or             (n_samples_X, n_features)\n",
      "            Array of pairwise kernels between samples, or a feature array.\n",
      "            The shape of the array should be (n_samples_X, n_samples_X) if\n",
      "            metric == \"precomputed\" and (n_samples_X, n_features) otherwise.\n",
      "        \n",
      "        Y : {array-like, sparse matrix} of shape (n_samples_Y, n_features), default=None\n",
      "            A second feature array only if X has shape (n_samples_X, n_features).\n",
      "        \n",
      "        metric : str or callable, default=\"linear\"\n",
      "            The metric to use when calculating kernel between instances in a\n",
      "            feature array. If metric is a string, it must be one of the metrics\n",
      "            in ``pairwise.PAIRWISE_KERNEL_FUNCTIONS``.\n",
      "            If metric is \"precomputed\", X is assumed to be a kernel matrix.\n",
      "            Alternatively, if metric is a callable function, it is called on each\n",
      "            pair of instances (rows) and the resulting value recorded. The callable\n",
      "            should take two rows from X as input and return the corresponding\n",
      "            kernel value as a single number. This means that callables from\n",
      "            :mod:`sklearn.metrics.pairwise` are not allowed, as they operate on\n",
      "            matrices, not single samples. Use the string identifying the kernel\n",
      "            instead.\n",
      "        \n",
      "        filter_params : bool, default=False\n",
      "            Whether to filter invalid parameters or not.\n",
      "        \n",
      "        n_jobs : int, default=None\n",
      "            The number of jobs to use for the computation. This works by breaking\n",
      "            down the pairwise matrix into n_jobs even slices and computing them\n",
      "            using multithreading.\n",
      "        \n",
      "            ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "            ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "            for more details.\n",
      "        \n",
      "        **kwds : optional keyword parameters\n",
      "            Any further parameters are passed directly to the kernel function.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        K : ndarray of shape (n_samples_X, n_samples_X) or (n_samples_X, n_samples_Y)\n",
      "            A kernel matrix K such that K_{i, j} is the kernel between the\n",
      "            ith and jth vectors of the given matrix X, if Y is None.\n",
      "            If Y is not None, then K_{i, j} is the kernel between the ith array\n",
      "            from X and the jth array from Y.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        If metric is 'precomputed', Y is ignored and X is returned.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics.pairwise import pairwise_kernels\n",
      "        >>> X = [[0, 0, 0], [1, 1, 1]]\n",
      "        >>> Y = [[1, 0, 0], [1, 1, 0]]\n",
      "        >>> pairwise_kernels(X, Y, metric='linear')\n",
      "        array([[0., 0.],\n",
      "               [1., 2.]])\n",
      "    \n",
      "    precision_recall_curve(y_true, y_score=None, *, pos_label=None, sample_weight=None, drop_intermediate=False, probas_pred='deprecated')\n",
      "        Compute precision-recall pairs for different probability thresholds.\n",
      "        \n",
      "        Note: this implementation is restricted to the binary classification task.\n",
      "        \n",
      "        The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\n",
      "        true positives and ``fp`` the number of false positives. The precision is\n",
      "        intuitively the ability of the classifier not to label as positive a sample\n",
      "        that is negative.\n",
      "        \n",
      "        The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\n",
      "        true positives and ``fn`` the number of false negatives. The recall is\n",
      "        intuitively the ability of the classifier to find all the positive samples.\n",
      "        \n",
      "        The last precision and recall values are 1. and 0. respectively and do not\n",
      "        have a corresponding threshold. This ensures that the graph starts on the\n",
      "        y axis.\n",
      "        \n",
      "        The first precision and recall values are precision=class balance and recall=1.0\n",
      "        which corresponds to a classifier that always predicts the positive class.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,)\n",
      "            True binary labels. If labels are not either {-1, 1} or {0, 1}, then\n",
      "            pos_label should be explicitly given.\n",
      "        \n",
      "        y_score : array-like of shape (n_samples,)\n",
      "            Target scores, can either be probability estimates of the positive\n",
      "            class, or non-thresholded measure of decisions (as returned by\n",
      "            `decision_function` on some classifiers).\n",
      "            For :term:`decision_function` scores, values greater than or equal to\n",
      "            zero should indicate the positive class.\n",
      "        \n",
      "        pos_label : int, float, bool or str, default=None\n",
      "            The label of the positive class.\n",
      "            When ``pos_label=None``, if y_true is in {-1, 1} or {0, 1},\n",
      "            ``pos_label`` is set to 1, otherwise an error will be raised.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        drop_intermediate : bool, default=False\n",
      "            Whether to drop some suboptimal thresholds which would not appear\n",
      "            on a plotted precision-recall curve. This is useful in order to create\n",
      "            lighter precision-recall curves.\n",
      "        \n",
      "            .. versionadded:: 1.3\n",
      "        \n",
      "        probas_pred : array-like of shape (n_samples,)\n",
      "            Target scores, can either be probability estimates of the positive\n",
      "            class, or non-thresholded measure of decisions (as returned by\n",
      "            `decision_function` on some classifiers).\n",
      "        \n",
      "            .. deprecated:: 1.5\n",
      "                `probas_pred` is deprecated and will be removed in 1.7. Use\n",
      "                `y_score` instead.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        precision : ndarray of shape (n_thresholds + 1,)\n",
      "            Precision values such that element i is the precision of\n",
      "            predictions with score >= thresholds[i] and the last element is 1.\n",
      "        \n",
      "        recall : ndarray of shape (n_thresholds + 1,)\n",
      "            Decreasing recall values such that element i is the recall of\n",
      "            predictions with score >= thresholds[i] and the last element is 0.\n",
      "        \n",
      "        thresholds : ndarray of shape (n_thresholds,)\n",
      "            Increasing thresholds on the decision function used to compute\n",
      "            precision and recall where `n_thresholds = len(np.unique(probas_pred))`.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        PrecisionRecallDisplay.from_estimator : Plot Precision Recall Curve given\n",
      "            a binary classifier.\n",
      "        PrecisionRecallDisplay.from_predictions : Plot Precision Recall Curve\n",
      "            using predictions from a binary classifier.\n",
      "        average_precision_score : Compute average precision from prediction scores.\n",
      "        det_curve: Compute error rates for different probability thresholds.\n",
      "        roc_curve : Compute Receiver operating characteristic (ROC) curve.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.metrics import precision_recall_curve\n",
      "        >>> y_true = np.array([0, 0, 1, 1])\n",
      "        >>> y_scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
      "        >>> precision, recall, thresholds = precision_recall_curve(\n",
      "        ...     y_true, y_scores)\n",
      "        >>> precision\n",
      "        array([0.5       , 0.66666667, 0.5       , 1.        , 1.        ])\n",
      "        >>> recall\n",
      "        array([1. , 1. , 0.5, 0.5, 0. ])\n",
      "        >>> thresholds\n",
      "        array([0.1 , 0.35, 0.4 , 0.8 ])\n",
      "    \n",
      "    precision_recall_fscore_support(y_true, y_pred, *, beta=1.0, labels=None, pos_label=1, average=None, warn_for=('precision', 'recall', 'f-score'), sample_weight=None, zero_division='warn')\n",
      "        Compute precision, recall, F-measure and support for each class.\n",
      "        \n",
      "        The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\n",
      "        true positives and ``fp`` the number of false positives. The precision is\n",
      "        intuitively the ability of the classifier not to label a negative sample as\n",
      "        positive.\n",
      "        \n",
      "        The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\n",
      "        true positives and ``fn`` the number of false negatives. The recall is\n",
      "        intuitively the ability of the classifier to find all the positive samples.\n",
      "        \n",
      "        The F-beta score can be interpreted as a weighted harmonic mean of\n",
      "        the precision and recall, where an F-beta score reaches its best\n",
      "        value at 1 and worst score at 0.\n",
      "        \n",
      "        The F-beta score weights recall more than precision by a factor of\n",
      "        ``beta``. ``beta == 1.0`` means recall and precision are equally important.\n",
      "        \n",
      "        The support is the number of occurrences of each class in ``y_true``.\n",
      "        \n",
      "        Support beyond term:`binary` targets is achieved by treating :term:`multiclass`\n",
      "        and :term:`multilabel` data as a collection of binary problems, one for each\n",
      "        label. For the :term:`binary` case, setting `average='binary'` will return\n",
      "        metrics for `pos_label`. If `average` is not `'binary'`, `pos_label` is ignored\n",
      "        and metrics for both classes are computed, then averaged or both returned (when\n",
      "        `average=None`). Similarly, for :term:`multiclass` and :term:`multilabel` targets,\n",
      "        metrics for all `labels` are either returned or averaged depending on the `average`\n",
      "        parameter. Use `labels` specify the set of labels to calculate metrics for.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "            Estimated targets as returned by a classifier.\n",
      "        \n",
      "        beta : float, default=1.0\n",
      "            The strength of recall versus precision in the F-score.\n",
      "        \n",
      "        labels : array-like, default=None\n",
      "            The set of labels to include when `average != 'binary'`, and their\n",
      "            order if `average is None`. Labels present in the data can be\n",
      "            excluded, for example in multiclass classification to exclude a \"negative\n",
      "            class\". Labels not present in the data can be included and will be\n",
      "            \"assigned\" 0 samples. For multilabel targets, labels are column indices.\n",
      "            By default, all labels in `y_true` and `y_pred` are used in sorted order.\n",
      "        \n",
      "            .. versionchanged:: 0.17\n",
      "               Parameter `labels` improved for multiclass problem.\n",
      "        \n",
      "        pos_label : int, float, bool or str, default=1\n",
      "            The class to report if `average='binary'` and the data is binary,\n",
      "            otherwise this parameter is ignored.\n",
      "            For multiclass or multilabel targets, set `labels=[pos_label]` and\n",
      "            `average != 'binary'` to report metrics for one label only.\n",
      "        \n",
      "        average : {'micro', 'macro', 'samples', 'weighted', 'binary'} or None,             default='binary'\n",
      "            This parameter is required for multiclass/multilabel targets.\n",
      "            If ``None``, the metrics for each class are returned. Otherwise, this\n",
      "            determines the type of averaging performed on the data:\n",
      "        \n",
      "            ``'binary'``:\n",
      "                Only report results for the class specified by ``pos_label``.\n",
      "                This is applicable only if targets (``y_{true,pred}``) are binary.\n",
      "            ``'micro'``:\n",
      "                Calculate metrics globally by counting the total true positives,\n",
      "                false negatives and false positives.\n",
      "            ``'macro'``:\n",
      "                Calculate metrics for each label, and find their unweighted\n",
      "                mean.  This does not take label imbalance into account.\n",
      "            ``'weighted'``:\n",
      "                Calculate metrics for each label, and find their average weighted\n",
      "                by support (the number of true instances for each label). This\n",
      "                alters 'macro' to account for label imbalance; it can result in an\n",
      "                F-score that is not between precision and recall.\n",
      "            ``'samples'``:\n",
      "                Calculate metrics for each instance, and find their average (only\n",
      "                meaningful for multilabel classification where this differs from\n",
      "                :func:`accuracy_score`).\n",
      "        \n",
      "        warn_for : list, tuple or set, for internal use\n",
      "            This determines which warnings will be made in the case that this\n",
      "            function is being used to return only one of its metrics.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        zero_division : {\"warn\", 0.0, 1.0, np.nan}, default=\"warn\"\n",
      "            Sets the value to return when there is a zero division:\n",
      "        \n",
      "            - recall: when there are no positive labels\n",
      "            - precision: when there are no positive predictions\n",
      "            - f-score: both\n",
      "        \n",
      "            Notes:\n",
      "        \n",
      "            - If set to \"warn\", this acts like 0, but a warning is also raised.\n",
      "            - If set to `np.nan`, such values will be excluded from the average.\n",
      "        \n",
      "            .. versionadded:: 1.3\n",
      "               `np.nan` option was added.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        precision : float (if average is not None) or array of float, shape =        [n_unique_labels]\n",
      "            Precision score.\n",
      "        \n",
      "        recall : float (if average is not None) or array of float, shape =        [n_unique_labels]\n",
      "            Recall score.\n",
      "        \n",
      "        fbeta_score : float (if average is not None) or array of float, shape =        [n_unique_labels]\n",
      "            F-beta score.\n",
      "        \n",
      "        support : None (if average is not None) or array of int, shape =        [n_unique_labels]\n",
      "            The number of occurrences of each label in ``y_true``.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        When ``true positive + false positive == 0``, precision is undefined.\n",
      "        When ``true positive + false negative == 0``, recall is undefined. When\n",
      "        ``true positive + false negative + false positive == 0``, f-score is\n",
      "        undefined. In such cases, by default the metric will be set to 0, and\n",
      "        ``UndefinedMetricWarning`` will be raised. This behavior can be modified\n",
      "        with ``zero_division``.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] `Wikipedia entry for the Precision and recall\n",
      "               <https://en.wikipedia.org/wiki/Precision_and_recall>`_.\n",
      "        \n",
      "        .. [2] `Wikipedia entry for the F1-score\n",
      "               <https://en.wikipedia.org/wiki/F1_score>`_.\n",
      "        \n",
      "        .. [3] `Discriminative Methods for Multi-labeled Classification Advances\n",
      "               in Knowledge Discovery and Data Mining (2004), pp. 22-30 by Shantanu\n",
      "               Godbole, Sunita Sarawagi\n",
      "               <http://www.godbole.net/shantanu/pubs/multilabelsvm-pakdd04.pdf>`_.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.metrics import precision_recall_fscore_support\n",
      "        >>> y_true = np.array(['cat', 'dog', 'pig', 'cat', 'dog', 'pig'])\n",
      "        >>> y_pred = np.array(['cat', 'pig', 'dog', 'cat', 'cat', 'dog'])\n",
      "        >>> precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
      "        (0.22..., 0.33..., 0.26..., None)\n",
      "        >>> precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
      "        (0.33..., 0.33..., 0.33..., None)\n",
      "        >>> precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
      "        (0.22..., 0.33..., 0.26..., None)\n",
      "        \n",
      "        It is possible to compute per-label precisions, recalls, F1-scores and\n",
      "        supports instead of averaging:\n",
      "        \n",
      "        >>> precision_recall_fscore_support(y_true, y_pred, average=None,\n",
      "        ... labels=['pig', 'dog', 'cat'])\n",
      "        (array([0.        , 0.        , 0.66...]),\n",
      "         array([0., 0., 1.]), array([0. , 0. , 0.8]),\n",
      "         array([2, 2, 2]))\n",
      "    \n",
      "    precision_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')\n",
      "        Compute the precision.\n",
      "        \n",
      "        The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\n",
      "        true positives and ``fp`` the number of false positives. The precision is\n",
      "        intuitively the ability of the classifier not to label as positive a sample\n",
      "        that is negative.\n",
      "        \n",
      "        The best value is 1 and the worst value is 0.\n",
      "        \n",
      "        Support beyond term:`binary` targets is achieved by treating :term:`multiclass`\n",
      "        and :term:`multilabel` data as a collection of binary problems, one for each\n",
      "        label. For the :term:`binary` case, setting `average='binary'` will return\n",
      "        precision for `pos_label`. If `average` is not `'binary'`, `pos_label` is ignored\n",
      "        and precision for both classes are computed, then averaged or both returned (when\n",
      "        `average=None`). Similarly, for :term:`multiclass` and :term:`multilabel` targets,\n",
      "        precision for all `labels` are either returned or averaged depending on the\n",
      "        `average` parameter. Use `labels` specify the set of labels to calculate precision\n",
      "        for.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "            Estimated targets as returned by a classifier.\n",
      "        \n",
      "        labels : array-like, default=None\n",
      "            The set of labels to include when `average != 'binary'`, and their\n",
      "            order if `average is None`. Labels present in the data can be\n",
      "            excluded, for example in multiclass classification to exclude a \"negative\n",
      "            class\". Labels not present in the data can be included and will be\n",
      "            \"assigned\" 0 samples. For multilabel targets, labels are column indices.\n",
      "            By default, all labels in `y_true` and `y_pred` are used in sorted order.\n",
      "        \n",
      "            .. versionchanged:: 0.17\n",
      "               Parameter `labels` improved for multiclass problem.\n",
      "        \n",
      "        pos_label : int, float, bool or str, default=1\n",
      "            The class to report if `average='binary'` and the data is binary,\n",
      "            otherwise this parameter is ignored.\n",
      "            For multiclass or multilabel targets, set `labels=[pos_label]` and\n",
      "            `average != 'binary'` to report metrics for one label only.\n",
      "        \n",
      "        average : {'micro', 'macro', 'samples', 'weighted', 'binary'} or None,             default='binary'\n",
      "            This parameter is required for multiclass/multilabel targets.\n",
      "            If ``None``, the metrics for each class are returned. Otherwise, this\n",
      "            determines the type of averaging performed on the data:\n",
      "        \n",
      "            ``'binary'``:\n",
      "                Only report results for the class specified by ``pos_label``.\n",
      "                This is applicable only if targets (``y_{true,pred}``) are binary.\n",
      "            ``'micro'``:\n",
      "                Calculate metrics globally by counting the total true positives,\n",
      "                false negatives and false positives.\n",
      "            ``'macro'``:\n",
      "                Calculate metrics for each label, and find their unweighted\n",
      "                mean.  This does not take label imbalance into account.\n",
      "            ``'weighted'``:\n",
      "                Calculate metrics for each label, and find their average weighted\n",
      "                by support (the number of true instances for each label). This\n",
      "                alters 'macro' to account for label imbalance; it can result in an\n",
      "                F-score that is not between precision and recall.\n",
      "            ``'samples'``:\n",
      "                Calculate metrics for each instance, and find their average (only\n",
      "                meaningful for multilabel classification where this differs from\n",
      "                :func:`accuracy_score`).\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        zero_division : {\"warn\", 0.0, 1.0, np.nan}, default=\"warn\"\n",
      "            Sets the value to return when there is a zero division.\n",
      "        \n",
      "            Notes:\n",
      "        \n",
      "            - If set to \"warn\", this acts like 0, but a warning is also raised.\n",
      "            - If set to `np.nan`, such values will be excluded from the average.\n",
      "        \n",
      "            .. versionadded:: 1.3\n",
      "               `np.nan` option was added.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        precision : float (if average is not None) or array of float of shape                 (n_unique_labels,)\n",
      "            Precision of the positive class in binary classification or weighted\n",
      "            average of the precision of each class for the multiclass task.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        precision_recall_fscore_support : Compute precision, recall, F-measure and\n",
      "            support for each class.\n",
      "        recall_score :  Compute the ratio ``tp / (tp + fn)`` where ``tp`` is the\n",
      "            number of true positives and ``fn`` the number of false negatives.\n",
      "        PrecisionRecallDisplay.from_estimator : Plot precision-recall curve given\n",
      "            an estimator and some data.\n",
      "        PrecisionRecallDisplay.from_predictions : Plot precision-recall curve given\n",
      "            binary class predictions.\n",
      "        multilabel_confusion_matrix : Compute a confusion matrix for each class or\n",
      "            sample.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        When ``true positive + false positive == 0``, precision returns 0 and\n",
      "        raises ``UndefinedMetricWarning``. This behavior can be\n",
      "        modified with ``zero_division``.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.metrics import precision_score\n",
      "        >>> y_true = [0, 1, 2, 0, 1, 2]\n",
      "        >>> y_pred = [0, 2, 1, 0, 0, 1]\n",
      "        >>> precision_score(y_true, y_pred, average='macro')\n",
      "        0.22...\n",
      "        >>> precision_score(y_true, y_pred, average='micro')\n",
      "        0.33...\n",
      "        >>> precision_score(y_true, y_pred, average='weighted')\n",
      "        0.22...\n",
      "        >>> precision_score(y_true, y_pred, average=None)\n",
      "        array([0.66..., 0.        , 0.        ])\n",
      "        >>> y_pred = [0, 0, 0, 0, 0, 0]\n",
      "        >>> precision_score(y_true, y_pred, average=None)\n",
      "        array([0.33..., 0.        , 0.        ])\n",
      "        >>> precision_score(y_true, y_pred, average=None, zero_division=1)\n",
      "        array([0.33..., 1.        , 1.        ])\n",
      "        >>> precision_score(y_true, y_pred, average=None, zero_division=np.nan)\n",
      "        array([0.33...,        nan,        nan])\n",
      "        \n",
      "        >>> # multilabel classification\n",
      "        >>> y_true = [[0, 0, 0], [1, 1, 1], [0, 1, 1]]\n",
      "        >>> y_pred = [[0, 0, 0], [1, 1, 1], [1, 1, 0]]\n",
      "        >>> precision_score(y_true, y_pred, average=None)\n",
      "        array([0.5, 1. , 1. ])\n",
      "    \n",
      "    r2_score(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average', force_finite=True)\n",
      "        :math:`R^2` (coefficient of determination) regression score function.\n",
      "        \n",
      "        Best possible score is 1.0 and it can be negative (because the\n",
      "        model can be arbitrarily worse). In the general case when the true y is\n",
      "        non-constant, a constant model that always predicts the average y\n",
      "        disregarding the input features would get a :math:`R^2` score of 0.0.\n",
      "        \n",
      "        In the particular case when ``y_true`` is constant, the :math:`R^2` score\n",
      "        is not finite: it is either ``NaN`` (perfect predictions) or ``-Inf``\n",
      "        (imperfect predictions). To prevent such non-finite numbers to pollute\n",
      "        higher-level experiments such as a grid search cross-validation, by default\n",
      "        these cases are replaced with 1.0 (perfect predictions) or 0.0 (imperfect\n",
      "        predictions) respectively. You can set ``force_finite`` to ``False`` to\n",
      "        prevent this fix from happening.\n",
      "        \n",
      "        Note: when the prediction residuals have zero mean, the :math:`R^2` score\n",
      "        is identical to the\n",
      "        :func:`Explained Variance score <explained_variance_score>`.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <r2_score>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Estimated target values.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        multioutput : {'raw_values', 'uniform_average', 'variance_weighted'},             array-like of shape (n_outputs,) or None, default='uniform_average'\n",
      "        \n",
      "            Defines aggregating of multiple output scores.\n",
      "            Array-like value defines weights used to average scores.\n",
      "            Default is \"uniform_average\".\n",
      "        \n",
      "            'raw_values' :\n",
      "                Returns a full set of scores in case of multioutput input.\n",
      "        \n",
      "            'uniform_average' :\n",
      "                Scores of all outputs are averaged with uniform weight.\n",
      "        \n",
      "            'variance_weighted' :\n",
      "                Scores of all outputs are averaged, weighted by the variances\n",
      "                of each individual output.\n",
      "        \n",
      "            .. versionchanged:: 0.19\n",
      "                Default value of multioutput is 'uniform_average'.\n",
      "        \n",
      "        force_finite : bool, default=True\n",
      "            Flag indicating if ``NaN`` and ``-Inf`` scores resulting from constant\n",
      "            data should be replaced with real numbers (``1.0`` if prediction is\n",
      "            perfect, ``0.0`` otherwise). Default is ``True``, a convenient setting\n",
      "            for hyperparameters' search procedures (e.g. grid search\n",
      "            cross-validation).\n",
      "        \n",
      "            .. versionadded:: 1.1\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        z : float or ndarray of floats\n",
      "            The :math:`R^2` score or ndarray of scores if 'multioutput' is\n",
      "            'raw_values'.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This is not a symmetric function.\n",
      "        \n",
      "        Unlike most other scores, :math:`R^2` score may be negative (it need not\n",
      "        actually be the square of a quantity R).\n",
      "        \n",
      "        This metric is not well-defined for single samples and will return a NaN\n",
      "        value if n_samples is less than two.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] `Wikipedia entry on the Coefficient of determination\n",
      "                <https://en.wikipedia.org/wiki/Coefficient_of_determination>`_\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import r2_score\n",
      "        >>> y_true = [3, -0.5, 2, 7]\n",
      "        >>> y_pred = [2.5, 0.0, 2, 8]\n",
      "        >>> r2_score(y_true, y_pred)\n",
      "        0.948...\n",
      "        >>> y_true = [[0.5, 1], [-1, 1], [7, -6]]\n",
      "        >>> y_pred = [[0, 2], [-1, 2], [8, -5]]\n",
      "        >>> r2_score(y_true, y_pred,\n",
      "        ...          multioutput='variance_weighted')\n",
      "        0.938...\n",
      "        >>> y_true = [1, 2, 3]\n",
      "        >>> y_pred = [1, 2, 3]\n",
      "        >>> r2_score(y_true, y_pred)\n",
      "        1.0\n",
      "        >>> y_true = [1, 2, 3]\n",
      "        >>> y_pred = [2, 2, 2]\n",
      "        >>> r2_score(y_true, y_pred)\n",
      "        0.0\n",
      "        >>> y_true = [1, 2, 3]\n",
      "        >>> y_pred = [3, 2, 1]\n",
      "        >>> r2_score(y_true, y_pred)\n",
      "        -3.0\n",
      "        >>> y_true = [-2, -2, -2]\n",
      "        >>> y_pred = [-2, -2, -2]\n",
      "        >>> r2_score(y_true, y_pred)\n",
      "        1.0\n",
      "        >>> r2_score(y_true, y_pred, force_finite=False)\n",
      "        nan\n",
      "        >>> y_true = [-2, -2, -2]\n",
      "        >>> y_pred = [-2, -2, -2 + 1e-8]\n",
      "        >>> r2_score(y_true, y_pred)\n",
      "        0.0\n",
      "        >>> r2_score(y_true, y_pred, force_finite=False)\n",
      "        -inf\n",
      "    \n",
      "    rand_score(labels_true, labels_pred)\n",
      "        Rand index.\n",
      "        \n",
      "        The Rand Index computes a similarity measure between two clusterings\n",
      "        by considering all pairs of samples and counting pairs that are\n",
      "        assigned in the same or different clusters in the predicted and\n",
      "        true clusterings [1]_ [2]_.\n",
      "        \n",
      "        The raw RI score [3]_ is:\n",
      "        \n",
      "        .. code-block:: text\n",
      "        \n",
      "            RI = (number of agreeing pairs) / (number of pairs)\n",
      "        \n",
      "        Read more in the :ref:`User Guide <rand_score>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        labels_true : array-like of shape (n_samples,), dtype=integral\n",
      "            Ground truth class labels to be used as a reference.\n",
      "        \n",
      "        labels_pred : array-like of shape (n_samples,), dtype=integral\n",
      "            Cluster labels to evaluate.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        RI : float\n",
      "           Similarity score between 0.0 and 1.0, inclusive, 1.0 stands for\n",
      "           perfect match.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        adjusted_rand_score: Adjusted Rand Score.\n",
      "        adjusted_mutual_info_score: Adjusted Mutual Information.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] :doi:`Hubert, L., Arabie, P. \"Comparing partitions.\"\n",
      "           Journal of Classification 2, 193–218 (1985).\n",
      "           <10.1007/BF01908075>`.\n",
      "        \n",
      "        .. [2] `Wikipedia: Simple Matching Coefficient\n",
      "            <https://en.wikipedia.org/wiki/Simple_matching_coefficient>`_\n",
      "        \n",
      "        .. [3] `Wikipedia: Rand Index <https://en.wikipedia.org/wiki/Rand_index>`_\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Perfectly matching labelings have a score of 1 even\n",
      "        \n",
      "          >>> from sklearn.metrics.cluster import rand_score\n",
      "          >>> rand_score([0, 0, 1, 1], [1, 1, 0, 0])\n",
      "          1.0\n",
      "        \n",
      "        Labelings that assign all classes members to the same clusters\n",
      "        are complete but may not always be pure, hence penalized:\n",
      "        \n",
      "          >>> rand_score([0, 0, 1, 2], [0, 0, 1, 1])\n",
      "          np.float64(0.83...)\n",
      "    \n",
      "    recall_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')\n",
      "        Compute the recall.\n",
      "        \n",
      "        The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\n",
      "        true positives and ``fn`` the number of false negatives. The recall is\n",
      "        intuitively the ability of the classifier to find all the positive samples.\n",
      "        \n",
      "        The best value is 1 and the worst value is 0.\n",
      "        \n",
      "        Support beyond term:`binary` targets is achieved by treating :term:`multiclass`\n",
      "        and :term:`multilabel` data as a collection of binary problems, one for each\n",
      "        label. For the :term:`binary` case, setting `average='binary'` will return\n",
      "        recall for `pos_label`. If `average` is not `'binary'`, `pos_label` is ignored\n",
      "        and recall for both classes are computed then averaged or both returned (when\n",
      "        `average=None`). Similarly, for :term:`multiclass` and :term:`multilabel` targets,\n",
      "        recall for all `labels` are either returned or averaged depending on the `average`\n",
      "        parameter. Use `labels` specify the set of labels to calculate recall for.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "            Estimated targets as returned by a classifier.\n",
      "        \n",
      "        labels : array-like, default=None\n",
      "            The set of labels to include when `average != 'binary'`, and their\n",
      "            order if `average is None`. Labels present in the data can be\n",
      "            excluded, for example in multiclass classification to exclude a \"negative\n",
      "            class\". Labels not present in the data can be included and will be\n",
      "            \"assigned\" 0 samples. For multilabel targets, labels are column indices.\n",
      "            By default, all labels in `y_true` and `y_pred` are used in sorted order.\n",
      "        \n",
      "            .. versionchanged:: 0.17\n",
      "               Parameter `labels` improved for multiclass problem.\n",
      "        \n",
      "        pos_label : int, float, bool or str, default=1\n",
      "            The class to report if `average='binary'` and the data is binary,\n",
      "            otherwise this parameter is ignored.\n",
      "            For multiclass or multilabel targets, set `labels=[pos_label]` and\n",
      "            `average != 'binary'` to report metrics for one label only.\n",
      "        \n",
      "        average : {'micro', 'macro', 'samples', 'weighted', 'binary'} or None,             default='binary'\n",
      "            This parameter is required for multiclass/multilabel targets.\n",
      "            If ``None``, the metrics for each class are returned. Otherwise, this\n",
      "            determines the type of averaging performed on the data:\n",
      "        \n",
      "            ``'binary'``:\n",
      "                Only report results for the class specified by ``pos_label``.\n",
      "                This is applicable only if targets (``y_{true,pred}``) are binary.\n",
      "            ``'micro'``:\n",
      "                Calculate metrics globally by counting the total true positives,\n",
      "                false negatives and false positives.\n",
      "            ``'macro'``:\n",
      "                Calculate metrics for each label, and find their unweighted\n",
      "                mean.  This does not take label imbalance into account.\n",
      "            ``'weighted'``:\n",
      "                Calculate metrics for each label, and find their average weighted\n",
      "                by support (the number of true instances for each label). This\n",
      "                alters 'macro' to account for label imbalance; it can result in an\n",
      "                F-score that is not between precision and recall. Weighted recall\n",
      "                is equal to accuracy.\n",
      "            ``'samples'``:\n",
      "                Calculate metrics for each instance, and find their average (only\n",
      "                meaningful for multilabel classification where this differs from\n",
      "                :func:`accuracy_score`).\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        zero_division : {\"warn\", 0.0, 1.0, np.nan}, default=\"warn\"\n",
      "            Sets the value to return when there is a zero division.\n",
      "        \n",
      "            Notes:\n",
      "        \n",
      "            - If set to \"warn\", this acts like 0, but a warning is also raised.\n",
      "            - If set to `np.nan`, such values will be excluded from the average.\n",
      "        \n",
      "            .. versionadded:: 1.3\n",
      "               `np.nan` option was added.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        recall : float (if average is not None) or array of float of shape              (n_unique_labels,)\n",
      "            Recall of the positive class in binary classification or weighted\n",
      "            average of the recall of each class for the multiclass task.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        precision_recall_fscore_support : Compute precision, recall, F-measure and\n",
      "            support for each class.\n",
      "        precision_score : Compute the ratio ``tp / (tp + fp)`` where ``tp`` is the\n",
      "            number of true positives and ``fp`` the number of false positives.\n",
      "        balanced_accuracy_score : Compute balanced accuracy to deal with imbalanced\n",
      "            datasets.\n",
      "        multilabel_confusion_matrix : Compute a confusion matrix for each class or\n",
      "            sample.\n",
      "        PrecisionRecallDisplay.from_estimator : Plot precision-recall curve given\n",
      "            an estimator and some data.\n",
      "        PrecisionRecallDisplay.from_predictions : Plot precision-recall curve given\n",
      "            binary class predictions.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        When ``true positive + false negative == 0``, recall returns 0 and raises\n",
      "        ``UndefinedMetricWarning``. This behavior can be modified with\n",
      "        ``zero_division``.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.metrics import recall_score\n",
      "        >>> y_true = [0, 1, 2, 0, 1, 2]\n",
      "        >>> y_pred = [0, 2, 1, 0, 0, 1]\n",
      "        >>> recall_score(y_true, y_pred, average='macro')\n",
      "        0.33...\n",
      "        >>> recall_score(y_true, y_pred, average='micro')\n",
      "        0.33...\n",
      "        >>> recall_score(y_true, y_pred, average='weighted')\n",
      "        0.33...\n",
      "        >>> recall_score(y_true, y_pred, average=None)\n",
      "        array([1., 0., 0.])\n",
      "        >>> y_true = [0, 0, 0, 0, 0, 0]\n",
      "        >>> recall_score(y_true, y_pred, average=None)\n",
      "        array([0.5, 0. , 0. ])\n",
      "        >>> recall_score(y_true, y_pred, average=None, zero_division=1)\n",
      "        array([0.5, 1. , 1. ])\n",
      "        >>> recall_score(y_true, y_pred, average=None, zero_division=np.nan)\n",
      "        array([0.5, nan, nan])\n",
      "        \n",
      "        >>> # multilabel classification\n",
      "        >>> y_true = [[0, 0, 0], [1, 1, 1], [0, 1, 1]]\n",
      "        >>> y_pred = [[0, 0, 0], [1, 1, 1], [1, 1, 0]]\n",
      "        >>> recall_score(y_true, y_pred, average=None)\n",
      "        array([1. , 1. , 0.5])\n",
      "    \n",
      "    roc_auc_score(y_true, y_score, *, average='macro', sample_weight=None, max_fpr=None, multi_class='raise', labels=None)\n",
      "        Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC)     from prediction scores.\n",
      "        \n",
      "        Note: this implementation can be used with binary, multiclass and\n",
      "        multilabel classification, but some restrictions apply (see Parameters).\n",
      "        \n",
      "        Read more in the :ref:`User Guide <roc_metrics>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,) or (n_samples, n_classes)\n",
      "            True labels or binary label indicators. The binary and multiclass cases\n",
      "            expect labels with shape (n_samples,) while the multilabel case expects\n",
      "            binary label indicators with shape (n_samples, n_classes).\n",
      "        \n",
      "        y_score : array-like of shape (n_samples,) or (n_samples, n_classes)\n",
      "            Target scores.\n",
      "        \n",
      "            * In the binary case, it corresponds to an array of shape\n",
      "              `(n_samples,)`. Both probability estimates and non-thresholded\n",
      "              decision values can be provided. The probability estimates correspond\n",
      "              to the **probability of the class with the greater label**,\n",
      "              i.e. `estimator.classes_[1]` and thus\n",
      "              `estimator.predict_proba(X, y)[:, 1]`. The decision values\n",
      "              corresponds to the output of `estimator.decision_function(X, y)`.\n",
      "              See more information in the :ref:`User guide <roc_auc_binary>`;\n",
      "            * In the multiclass case, it corresponds to an array of shape\n",
      "              `(n_samples, n_classes)` of probability estimates provided by the\n",
      "              `predict_proba` method. The probability estimates **must**\n",
      "              sum to 1 across the possible classes. In addition, the order of the\n",
      "              class scores must correspond to the order of ``labels``,\n",
      "              if provided, or else to the numerical or lexicographical order of\n",
      "              the labels in ``y_true``. See more information in the\n",
      "              :ref:`User guide <roc_auc_multiclass>`;\n",
      "            * In the multilabel case, it corresponds to an array of shape\n",
      "              `(n_samples, n_classes)`. Probability estimates are provided by the\n",
      "              `predict_proba` method and the non-thresholded decision values by\n",
      "              the `decision_function` method. The probability estimates correspond\n",
      "              to the **probability of the class with the greater label for each\n",
      "              output** of the classifier. See more information in the\n",
      "              :ref:`User guide <roc_auc_multilabel>`.\n",
      "        \n",
      "        average : {'micro', 'macro', 'samples', 'weighted'} or None,             default='macro'\n",
      "            If ``None``, the scores for each class are returned.\n",
      "            Otherwise, this determines the type of averaging performed on the data.\n",
      "            Note: multiclass ROC AUC currently only handles the 'macro' and\n",
      "            'weighted' averages. For multiclass targets, `average=None` is only\n",
      "            implemented for `multi_class='ovr'` and `average='micro'` is only\n",
      "            implemented for `multi_class='ovr'`.\n",
      "        \n",
      "            ``'micro'``:\n",
      "                Calculate metrics globally by considering each element of the label\n",
      "                indicator matrix as a label.\n",
      "            ``'macro'``:\n",
      "                Calculate metrics for each label, and find their unweighted\n",
      "                mean.  This does not take label imbalance into account.\n",
      "            ``'weighted'``:\n",
      "                Calculate metrics for each label, and find their average, weighted\n",
      "                by support (the number of true instances for each label).\n",
      "            ``'samples'``:\n",
      "                Calculate metrics for each instance, and find their average.\n",
      "        \n",
      "            Will be ignored when ``y_true`` is binary.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        max_fpr : float > 0 and <= 1, default=None\n",
      "            If not ``None``, the standardized partial AUC [2]_ over the range\n",
      "            [0, max_fpr] is returned. For the multiclass case, ``max_fpr``,\n",
      "            should be either equal to ``None`` or ``1.0`` as AUC ROC partial\n",
      "            computation currently is not supported for multiclass.\n",
      "        \n",
      "        multi_class : {'raise', 'ovr', 'ovo'}, default='raise'\n",
      "            Only used for multiclass targets. Determines the type of configuration\n",
      "            to use. The default value raises an error, so either\n",
      "            ``'ovr'`` or ``'ovo'`` must be passed explicitly.\n",
      "        \n",
      "            ``'ovr'``:\n",
      "                Stands for One-vs-rest. Computes the AUC of each class\n",
      "                against the rest [3]_ [4]_. This\n",
      "                treats the multiclass case in the same way as the multilabel case.\n",
      "                Sensitive to class imbalance even when ``average == 'macro'``,\n",
      "                because class imbalance affects the composition of each of the\n",
      "                'rest' groupings.\n",
      "            ``'ovo'``:\n",
      "                Stands for One-vs-one. Computes the average AUC of all\n",
      "                possible pairwise combinations of classes [5]_.\n",
      "                Insensitive to class imbalance when\n",
      "                ``average == 'macro'``.\n",
      "        \n",
      "        labels : array-like of shape (n_classes,), default=None\n",
      "            Only used for multiclass targets. List of labels that index the\n",
      "            classes in ``y_score``. If ``None``, the numerical or lexicographical\n",
      "            order of the labels in ``y_true`` is used.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        auc : float\n",
      "            Area Under the Curve score.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        average_precision_score : Area under the precision-recall curve.\n",
      "        roc_curve : Compute Receiver operating characteristic (ROC) curve.\n",
      "        RocCurveDisplay.from_estimator : Plot Receiver Operating Characteristic\n",
      "            (ROC) curve given an estimator and some data.\n",
      "        RocCurveDisplay.from_predictions : Plot Receiver Operating Characteristic\n",
      "            (ROC) curve given the true and predicted values.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The Gini Coefficient is a summary measure of the ranking ability of binary\n",
      "        classifiers. It is expressed using the area under of the ROC as follows:\n",
      "        \n",
      "        G = 2 * AUC - 1\n",
      "        \n",
      "        Where G is the Gini coefficient and AUC is the ROC-AUC score. This normalisation\n",
      "        will ensure that random guessing will yield a score of 0 in expectation, and it is\n",
      "        upper bounded by 1.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] `Wikipedia entry for the Receiver operating characteristic\n",
      "                <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_\n",
      "        \n",
      "        .. [2] `Analyzing a portion of the ROC curve. McClish, 1989\n",
      "                <https://www.ncbi.nlm.nih.gov/pubmed/2668680>`_\n",
      "        \n",
      "        .. [3] Provost, F., Domingos, P. (2000). Well-trained PETs: Improving\n",
      "               probability estimation trees (Section 6.2), CeDER Working Paper\n",
      "               #IS-00-04, Stern School of Business, New York University.\n",
      "        \n",
      "        .. [4] `Fawcett, T. (2006). An introduction to ROC analysis. Pattern\n",
      "                Recognition Letters, 27(8), 861-874.\n",
      "                <https://www.sciencedirect.com/science/article/pii/S016786550500303X>`_\n",
      "        \n",
      "        .. [5] `Hand, D.J., Till, R.J. (2001). A Simple Generalisation of the Area\n",
      "                Under the ROC Curve for Multiple Class Classification Problems.\n",
      "                Machine Learning, 45(2), 171-186.\n",
      "                <http://link.springer.com/article/10.1023/A:1010920819831>`_\n",
      "        .. [6] `Wikipedia entry for the Gini coefficient\n",
      "                <https://en.wikipedia.org/wiki/Gini_coefficient>`_\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Binary case:\n",
      "        \n",
      "        >>> from sklearn.datasets import load_breast_cancer\n",
      "        >>> from sklearn.linear_model import LogisticRegression\n",
      "        >>> from sklearn.metrics import roc_auc_score\n",
      "        >>> X, y = load_breast_cancer(return_X_y=True)\n",
      "        >>> clf = LogisticRegression(solver=\"liblinear\", random_state=0).fit(X, y)\n",
      "        >>> roc_auc_score(y, clf.predict_proba(X)[:, 1])\n",
      "        np.float64(0.99...)\n",
      "        >>> roc_auc_score(y, clf.decision_function(X))\n",
      "        np.float64(0.99...)\n",
      "        \n",
      "        Multiclass case:\n",
      "        \n",
      "        >>> from sklearn.datasets import load_iris\n",
      "        >>> X, y = load_iris(return_X_y=True)\n",
      "        >>> clf = LogisticRegression(solver=\"liblinear\").fit(X, y)\n",
      "        >>> roc_auc_score(y, clf.predict_proba(X), multi_class='ovr')\n",
      "        np.float64(0.99...)\n",
      "        \n",
      "        Multilabel case:\n",
      "        \n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.datasets import make_multilabel_classification\n",
      "        >>> from sklearn.multioutput import MultiOutputClassifier\n",
      "        >>> X, y = make_multilabel_classification(random_state=0)\n",
      "        >>> clf = MultiOutputClassifier(clf).fit(X, y)\n",
      "        >>> # get a list of n_output containing probability arrays of shape\n",
      "        >>> # (n_samples, n_classes)\n",
      "        >>> y_pred = clf.predict_proba(X)\n",
      "        >>> # extract the positive columns for each output\n",
      "        >>> y_pred = np.transpose([pred[:, 1] for pred in y_pred])\n",
      "        >>> roc_auc_score(y, y_pred, average=None)\n",
      "        array([0.82..., 0.86..., 0.94..., 0.85... , 0.94...])\n",
      "        >>> from sklearn.linear_model import RidgeClassifierCV\n",
      "        >>> clf = RidgeClassifierCV().fit(X, y)\n",
      "        >>> roc_auc_score(y, clf.decision_function(X), average=None)\n",
      "        array([0.81..., 0.84... , 0.93..., 0.87..., 0.94...])\n",
      "    \n",
      "    roc_curve(y_true, y_score, *, pos_label=None, sample_weight=None, drop_intermediate=True)\n",
      "        Compute Receiver operating characteristic (ROC).\n",
      "        \n",
      "        Note: this implementation is restricted to the binary classification task.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <roc_metrics>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,)\n",
      "            True binary labels. If labels are not either {-1, 1} or {0, 1}, then\n",
      "            pos_label should be explicitly given.\n",
      "        \n",
      "        y_score : array-like of shape (n_samples,)\n",
      "            Target scores, can either be probability estimates of the positive\n",
      "            class, confidence values, or non-thresholded measure of decisions\n",
      "            (as returned by \"decision_function\" on some classifiers).\n",
      "            For :term:`decision_function` scores, values greater than or equal to\n",
      "            zero should indicate the positive class.\n",
      "        \n",
      "        pos_label : int, float, bool or str, default=None\n",
      "            The label of the positive class.\n",
      "            When ``pos_label=None``, if `y_true` is in {-1, 1} or {0, 1},\n",
      "            ``pos_label`` is set to 1, otherwise an error will be raised.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        drop_intermediate : bool, default=True\n",
      "            Whether to drop some suboptimal thresholds which would not appear\n",
      "            on a plotted ROC curve. This is useful in order to create lighter\n",
      "            ROC curves.\n",
      "        \n",
      "            .. versionadded:: 0.17\n",
      "               parameter *drop_intermediate*.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        fpr : ndarray of shape (>2,)\n",
      "            Increasing false positive rates such that element i is the false\n",
      "            positive rate of predictions with score >= `thresholds[i]`.\n",
      "        \n",
      "        tpr : ndarray of shape (>2,)\n",
      "            Increasing true positive rates such that element `i` is the true\n",
      "            positive rate of predictions with score >= `thresholds[i]`.\n",
      "        \n",
      "        thresholds : ndarray of shape (n_thresholds,)\n",
      "            Decreasing thresholds on the decision function used to compute\n",
      "            fpr and tpr. `thresholds[0]` represents no instances being predicted\n",
      "            and is arbitrarily set to `np.inf`.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        RocCurveDisplay.from_estimator : Plot Receiver Operating Characteristic\n",
      "            (ROC) curve given an estimator and some data.\n",
      "        RocCurveDisplay.from_predictions : Plot Receiver Operating Characteristic\n",
      "            (ROC) curve given the true and predicted values.\n",
      "        det_curve: Compute error rates for different probability thresholds.\n",
      "        roc_auc_score : Compute the area under the ROC curve.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Since the thresholds are sorted from low to high values, they\n",
      "        are reversed upon returning them to ensure they correspond to both ``fpr``\n",
      "        and ``tpr``, which are sorted in reversed order during their calculation.\n",
      "        \n",
      "        An arbitrary threshold is added for the case `tpr=0` and `fpr=0` to\n",
      "        ensure that the curve starts at `(0, 0)`. This threshold corresponds to the\n",
      "        `np.inf`.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] `Wikipedia entry for the Receiver operating characteristic\n",
      "                <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_\n",
      "        \n",
      "        .. [2] Fawcett T. An introduction to ROC analysis[J]. Pattern Recognition\n",
      "               Letters, 2006, 27(8):861-874.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn import metrics\n",
      "        >>> y = np.array([1, 1, 2, 2])\n",
      "        >>> scores = np.array([0.1, 0.4, 0.35, 0.8])\n",
      "        >>> fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)\n",
      "        >>> fpr\n",
      "        array([0. , 0. , 0.5, 0.5, 1. ])\n",
      "        >>> tpr\n",
      "        array([0. , 0.5, 0.5, 1. , 1. ])\n",
      "        >>> thresholds\n",
      "        array([ inf, 0.8 , 0.4 , 0.35, 0.1 ])\n",
      "    \n",
      "    root_mean_squared_error(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average')\n",
      "        Root mean squared error regression loss.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <mean_squared_error>`.\n",
      "        \n",
      "        .. versionadded:: 1.4\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Estimated target values.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        multioutput : {'raw_values', 'uniform_average'} or array-like of shape             (n_outputs,), default='uniform_average'\n",
      "            Defines aggregating of multiple output values.\n",
      "            Array-like value defines weights used to average errors.\n",
      "        \n",
      "            'raw_values' :\n",
      "                Returns a full set of errors in case of multioutput input.\n",
      "        \n",
      "            'uniform_average' :\n",
      "                Errors of all outputs are averaged with uniform weight.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : float or ndarray of floats\n",
      "            A non-negative floating point value (the best value is 0.0), or an\n",
      "            array of floating point values, one for each individual target.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import root_mean_squared_error\n",
      "        >>> y_true = [3, -0.5, 2, 7]\n",
      "        >>> y_pred = [2.5, 0.0, 2, 8]\n",
      "        >>> root_mean_squared_error(y_true, y_pred)\n",
      "        0.612...\n",
      "        >>> y_true = [[0.5, 1],[-1, 1],[7, -6]]\n",
      "        >>> y_pred = [[0, 2],[-1, 2],[8, -5]]\n",
      "        >>> root_mean_squared_error(y_true, y_pred)\n",
      "        0.822...\n",
      "    \n",
      "    root_mean_squared_log_error(y_true, y_pred, *, sample_weight=None, multioutput='uniform_average')\n",
      "        Root mean squared logarithmic error regression loss.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <mean_squared_log_error>`.\n",
      "        \n",
      "        .. versionadded:: 1.4\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Ground truth (correct) target values.\n",
      "        \n",
      "        y_pred : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Estimated target values.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        multioutput : {'raw_values', 'uniform_average'} or array-like of shape             (n_outputs,), default='uniform_average'\n",
      "        \n",
      "            Defines aggregating of multiple output values.\n",
      "            Array-like value defines weights used to average errors.\n",
      "        \n",
      "            'raw_values' :\n",
      "                Returns a full set of errors when the input is of multioutput\n",
      "                format.\n",
      "        \n",
      "            'uniform_average' :\n",
      "                Errors of all outputs are averaged with uniform weight.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : float or ndarray of floats\n",
      "            A non-negative floating point value (the best value is 0.0), or an\n",
      "            array of floating point values, one for each individual target.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import root_mean_squared_log_error\n",
      "        >>> y_true = [3, 5, 2.5, 7]\n",
      "        >>> y_pred = [2.5, 5, 4, 8]\n",
      "        >>> root_mean_squared_log_error(y_true, y_pred)\n",
      "        0.199...\n",
      "    \n",
      "    silhouette_samples(X, labels, *, metric='euclidean', **kwds)\n",
      "        Compute the Silhouette Coefficient for each sample.\n",
      "        \n",
      "        The Silhouette Coefficient is a measure of how well samples are clustered\n",
      "        with samples that are similar to themselves. Clustering models with a high\n",
      "        Silhouette Coefficient are said to be dense, where samples in the same\n",
      "        cluster are similar to each other, and well separated, where samples in\n",
      "        different clusters are not very similar to each other.\n",
      "        \n",
      "        The Silhouette Coefficient is calculated using the mean intra-cluster\n",
      "        distance (``a``) and the mean nearest-cluster distance (``b``) for each\n",
      "        sample.  The Silhouette Coefficient for a sample is ``(b - a) / max(a,\n",
      "        b)``.\n",
      "        Note that Silhouette Coefficient is only defined if number of labels\n",
      "        is 2 ``<= n_labels <= n_samples - 1``.\n",
      "        \n",
      "        This function returns the Silhouette Coefficient for each sample.\n",
      "        \n",
      "        The best value is 1 and the worst value is -1. Values near 0 indicate\n",
      "        overlapping clusters.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <silhouette_coefficient>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples_a, n_samples_a) if metric ==             \"precomputed\" or (n_samples_a, n_features) otherwise\n",
      "            An array of pairwise distances between samples, or a feature array. If\n",
      "            a sparse matrix is provided, CSR format should be favoured avoiding\n",
      "            an additional copy.\n",
      "        \n",
      "        labels : array-like of shape (n_samples,)\n",
      "            Label values for each sample.\n",
      "        \n",
      "        metric : str or callable, default='euclidean'\n",
      "            The metric to use when calculating distance between instances in a\n",
      "            feature array. If metric is a string, it must be one of the options\n",
      "            allowed by :func:`~sklearn.metrics.pairwise_distances`.\n",
      "            If ``X`` is the distance array itself, use \"precomputed\" as the metric.\n",
      "            Precomputed distance matrices must have 0 along the diagonal.\n",
      "        \n",
      "        **kwds : optional keyword parameters\n",
      "            Any further parameters are passed directly to the distance function.\n",
      "            If using a ``scipy.spatial.distance`` metric, the parameters are still\n",
      "            metric dependent. See the scipy docs for usage examples.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        silhouette : array-like of shape (n_samples,)\n",
      "            Silhouette Coefficients for each sample.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        \n",
      "        .. [1] `Peter J. Rousseeuw (1987). \"Silhouettes: a Graphical Aid to the\n",
      "           Interpretation and Validation of Cluster Analysis\". Computational\n",
      "           and Applied Mathematics 20: 53-65.\n",
      "           <https://www.sciencedirect.com/science/article/pii/0377042787901257>`_\n",
      "        \n",
      "        .. [2] `Wikipedia entry on the Silhouette Coefficient\n",
      "           <https://en.wikipedia.org/wiki/Silhouette_(clustering)>`_\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import silhouette_samples\n",
      "        >>> from sklearn.datasets import make_blobs\n",
      "        >>> from sklearn.cluster import KMeans\n",
      "        >>> X, y = make_blobs(n_samples=50, random_state=42)\n",
      "        >>> kmeans = KMeans(n_clusters=3, random_state=42)\n",
      "        >>> labels = kmeans.fit_predict(X)\n",
      "        >>> silhouette_samples(X, labels)\n",
      "        array([...])\n",
      "    \n",
      "    silhouette_score(X, labels, *, metric='euclidean', sample_size=None, random_state=None, **kwds)\n",
      "        Compute the mean Silhouette Coefficient of all samples.\n",
      "        \n",
      "        The Silhouette Coefficient is calculated using the mean intra-cluster\n",
      "        distance (``a``) and the mean nearest-cluster distance (``b``) for each\n",
      "        sample.  The Silhouette Coefficient for a sample is ``(b - a) / max(a,\n",
      "        b)``.  To clarify, ``b`` is the distance between a sample and the nearest\n",
      "        cluster that the sample is not a part of.\n",
      "        Note that Silhouette Coefficient is only defined if number of labels\n",
      "        is ``2 <= n_labels <= n_samples - 1``.\n",
      "        \n",
      "        This function returns the mean Silhouette Coefficient over all samples.\n",
      "        To obtain the values for each sample, use :func:`silhouette_samples`.\n",
      "        \n",
      "        The best value is 1 and the worst value is -1. Values near 0 indicate\n",
      "        overlapping clusters. Negative values generally indicate that a sample has\n",
      "        been assigned to the wrong cluster, as a different cluster is more similar.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <silhouette_coefficient>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples_a, n_samples_a) if metric ==             \"precomputed\" or (n_samples_a, n_features) otherwise\n",
      "            An array of pairwise distances between samples, or a feature array.\n",
      "        \n",
      "        labels : array-like of shape (n_samples,)\n",
      "            Predicted labels for each sample.\n",
      "        \n",
      "        metric : str or callable, default='euclidean'\n",
      "            The metric to use when calculating distance between instances in a\n",
      "            feature array. If metric is a string, it must be one of the options\n",
      "            allowed by :func:`~sklearn.metrics.pairwise_distances`. If ``X`` is\n",
      "            the distance array itself, use ``metric=\"precomputed\"``.\n",
      "        \n",
      "        sample_size : int, default=None\n",
      "            The size of the sample to use when computing the Silhouette Coefficient\n",
      "            on a random subset of the data.\n",
      "            If ``sample_size is None``, no sampling is used.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=None\n",
      "            Determines random number generation for selecting a subset of samples.\n",
      "            Used when ``sample_size is not None``.\n",
      "            Pass an int for reproducible results across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        **kwds : optional keyword parameters\n",
      "            Any further parameters are passed directly to the distance function.\n",
      "            If using a scipy.spatial.distance metric, the parameters are still\n",
      "            metric dependent. See the scipy docs for usage examples.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        silhouette : float\n",
      "            Mean Silhouette Coefficient for all samples.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        \n",
      "        .. [1] `Peter J. Rousseeuw (1987). \"Silhouettes: a Graphical Aid to the\n",
      "           Interpretation and Validation of Cluster Analysis\". Computational\n",
      "           and Applied Mathematics 20: 53-65.\n",
      "           <https://www.sciencedirect.com/science/article/pii/0377042787901257>`_\n",
      "        \n",
      "        .. [2] `Wikipedia entry on the Silhouette Coefficient\n",
      "               <https://en.wikipedia.org/wiki/Silhouette_(clustering)>`_\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.datasets import make_blobs\n",
      "        >>> from sklearn.cluster import KMeans\n",
      "        >>> from sklearn.metrics import silhouette_score\n",
      "        >>> X, y = make_blobs(random_state=42)\n",
      "        >>> kmeans = KMeans(n_clusters=2, random_state=42)\n",
      "        >>> silhouette_score(X, kmeans.fit_predict(X))\n",
      "        np.float64(0.49...)\n",
      "    \n",
      "    top_k_accuracy_score(y_true, y_score, *, k=2, normalize=True, sample_weight=None, labels=None)\n",
      "        Top-k Accuracy classification score.\n",
      "        \n",
      "        This metric computes the number of times where the correct label is among\n",
      "        the top `k` labels predicted (ranked by predicted scores). Note that the\n",
      "        multilabel case isn't covered here.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <top_k_accuracy_score>`\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : array-like of shape (n_samples,)\n",
      "            True labels.\n",
      "        \n",
      "        y_score : array-like of shape (n_samples,) or (n_samples, n_classes)\n",
      "            Target scores. These can be either probability estimates or\n",
      "            non-thresholded decision values (as returned by\n",
      "            :term:`decision_function` on some classifiers).\n",
      "            The binary case expects scores with shape (n_samples,) while the\n",
      "            multiclass case expects scores with shape (n_samples, n_classes).\n",
      "            In the multiclass case, the order of the class scores must\n",
      "            correspond to the order of ``labels``, if provided, or else to\n",
      "            the numerical or lexicographical order of the labels in ``y_true``.\n",
      "            If ``y_true`` does not contain all the labels, ``labels`` must be\n",
      "            provided.\n",
      "        \n",
      "        k : int, default=2\n",
      "            Number of most likely outcomes considered to find the correct label.\n",
      "        \n",
      "        normalize : bool, default=True\n",
      "            If `True`, return the fraction of correctly classified samples.\n",
      "            Otherwise, return the number of correctly classified samples.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights. If `None`, all samples are given the same weight.\n",
      "        \n",
      "        labels : array-like of shape (n_classes,), default=None\n",
      "            Multiclass only. List of labels that index the classes in ``y_score``.\n",
      "            If ``None``, the numerical or lexicographical order of the labels in\n",
      "            ``y_true`` is used. If ``y_true`` does not contain all the labels,\n",
      "            ``labels`` must be provided.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        score : float\n",
      "            The top-k accuracy score. The best performance is 1 with\n",
      "            `normalize == True` and the number of samples with\n",
      "            `normalize == False`.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        accuracy_score : Compute the accuracy score. By default, the function will\n",
      "            return the fraction of correct predictions divided by the total number\n",
      "            of predictions.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        In cases where two or more labels are assigned equal predicted scores,\n",
      "        the labels with the highest indices will be chosen first. This might\n",
      "        impact the result if the correct label falls after the threshold because\n",
      "        of that.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.metrics import top_k_accuracy_score\n",
      "        >>> y_true = np.array([0, 1, 2, 2])\n",
      "        >>> y_score = np.array([[0.5, 0.2, 0.2],  # 0 is in top 2\n",
      "        ...                     [0.3, 0.4, 0.2],  # 1 is in top 2\n",
      "        ...                     [0.2, 0.4, 0.3],  # 2 is in top 2\n",
      "        ...                     [0.7, 0.2, 0.1]]) # 2 isn't in top 2\n",
      "        >>> top_k_accuracy_score(y_true, y_score, k=2)\n",
      "        np.float64(0.75)\n",
      "        >>> # Not normalizing gives the number of \"correctly\" classified samples\n",
      "        >>> top_k_accuracy_score(y_true, y_score, k=2, normalize=False)\n",
      "        np.int64(3)\n",
      "    \n",
      "    v_measure_score(labels_true, labels_pred, *, beta=1.0)\n",
      "        V-measure cluster labeling given a ground truth.\n",
      "        \n",
      "        This score is identical to :func:`normalized_mutual_info_score` with\n",
      "        the ``'arithmetic'`` option for averaging.\n",
      "        \n",
      "        The V-measure is the harmonic mean between homogeneity and completeness::\n",
      "        \n",
      "            v = (1 + beta) * homogeneity * completeness\n",
      "                 / (beta * homogeneity + completeness)\n",
      "        \n",
      "        This metric is independent of the absolute values of the labels:\n",
      "        a permutation of the class or cluster label values won't change the\n",
      "        score value in any way.\n",
      "        \n",
      "        This metric is furthermore symmetric: switching ``label_true`` with\n",
      "        ``label_pred`` will return the same score value. This can be useful to\n",
      "        measure the agreement of two independent label assignments strategies\n",
      "        on the same dataset when the real ground truth is not known.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <homogeneity_completeness>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        labels_true : array-like of shape (n_samples,)\n",
      "            Ground truth class labels to be used as a reference.\n",
      "        \n",
      "        labels_pred : array-like of shape (n_samples,)\n",
      "            Cluster labels to evaluate.\n",
      "        \n",
      "        beta : float, default=1.0\n",
      "            Ratio of weight attributed to ``homogeneity`` vs ``completeness``.\n",
      "            If ``beta`` is greater than 1, ``completeness`` is weighted more\n",
      "            strongly in the calculation. If ``beta`` is less than 1,\n",
      "            ``homogeneity`` is weighted more strongly.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        v_measure : float\n",
      "           Score between 0.0 and 1.0. 1.0 stands for perfectly complete labeling.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        homogeneity_score : Homogeneity metric of cluster labeling.\n",
      "        completeness_score : Completeness metric of cluster labeling.\n",
      "        normalized_mutual_info_score : Normalized Mutual Information.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        \n",
      "        .. [1] `Andrew Rosenberg and Julia Hirschberg, 2007. V-Measure: A\n",
      "           conditional entropy-based external cluster evaluation measure\n",
      "           <https://aclweb.org/anthology/D/D07/D07-1043.pdf>`_\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Perfect labelings are both homogeneous and complete, hence have score 1.0::\n",
      "        \n",
      "          >>> from sklearn.metrics.cluster import v_measure_score\n",
      "          >>> v_measure_score([0, 0, 1, 1], [0, 0, 1, 1])\n",
      "          np.float64(1.0)\n",
      "          >>> v_measure_score([0, 0, 1, 1], [1, 1, 0, 0])\n",
      "          np.float64(1.0)\n",
      "        \n",
      "        Labelings that assign all classes members to the same clusters\n",
      "        are complete but not homogeneous, hence penalized::\n",
      "        \n",
      "          >>> print(\"%.6f\" % v_measure_score([0, 0, 1, 2], [0, 0, 1, 1]))\n",
      "          0.8...\n",
      "          >>> print(\"%.6f\" % v_measure_score([0, 1, 2, 3], [0, 0, 1, 1]))\n",
      "          0.66...\n",
      "        \n",
      "        Labelings that have pure clusters with members coming from the same\n",
      "        classes are homogeneous but un-necessary splits harm completeness\n",
      "        and thus penalize V-measure as well::\n",
      "        \n",
      "          >>> print(\"%.6f\" % v_measure_score([0, 0, 1, 1], [0, 0, 1, 2]))\n",
      "          0.8...\n",
      "          >>> print(\"%.6f\" % v_measure_score([0, 0, 1, 1], [0, 1, 2, 3]))\n",
      "          0.66...\n",
      "        \n",
      "        If classes members are completely split across different clusters,\n",
      "        the assignment is totally incomplete, hence the V-Measure is null::\n",
      "        \n",
      "          >>> print(\"%.6f\" % v_measure_score([0, 0, 0, 0], [0, 1, 2, 3]))\n",
      "          0.0...\n",
      "        \n",
      "        Clusters that include samples from totally different classes totally\n",
      "        destroy the homogeneity of the labeling, hence::\n",
      "        \n",
      "          >>> print(\"%.6f\" % v_measure_score([0, 0, 1, 1], [0, 0, 0, 0]))\n",
      "          0.0...\n",
      "    \n",
      "    zero_one_loss(y_true, y_pred, *, normalize=True, sample_weight=None)\n",
      "        Zero-one classification loss.\n",
      "        \n",
      "        If normalize is ``True``, return the fraction of misclassifications\n",
      "        (float), else it returns the number of misclassifications (int). The best\n",
      "        performance is 0.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <zero_one_loss>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "            Ground truth (correct) labels.\n",
      "        \n",
      "        y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "            Predicted labels, as returned by a classifier.\n",
      "        \n",
      "        normalize : bool, default=True\n",
      "            If ``False``, return the number of misclassifications.\n",
      "            Otherwise, return the fraction of misclassifications.\n",
      "        \n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        loss : float or int,\n",
      "            If ``normalize == True``, return the fraction of misclassifications\n",
      "            (float), else it returns the number of misclassifications (int).\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        accuracy_score : Compute the accuracy score. By default, the function will\n",
      "            return the fraction of correct predictions divided by the total number\n",
      "            of predictions.\n",
      "        hamming_loss : Compute the average Hamming loss or Hamming distance between\n",
      "            two sets of samples.\n",
      "        jaccard_score : Compute the Jaccard similarity coefficient score.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        In multilabel classification, the zero_one_loss function corresponds to\n",
      "        the subset zero-one loss: for each sample, the entire set of labels must be\n",
      "        correctly predicted, otherwise the loss for that sample is equal to one.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn.metrics import zero_one_loss\n",
      "        >>> y_pred = [1, 2, 3, 4]\n",
      "        >>> y_true = [2, 2, 3, 4]\n",
      "        >>> zero_one_loss(y_true, y_pred)\n",
      "        0.25\n",
      "        >>> zero_one_loss(y_true, y_pred, normalize=False)\n",
      "        1.0\n",
      "        \n",
      "        In the multilabel case with binary label indicators:\n",
      "        \n",
      "        >>> import numpy as np\n",
      "        >>> zero_one_loss(np.array([[0, 1], [1, 1]]), np.ones((2, 2)))\n",
      "        0.5\n",
      "\n",
      "DATA\n",
      "    __all__ = ['accuracy_score', 'adjusted_mutual_info_score', 'adjusted_r...\n",
      "\n",
      "FILE\n",
      "    /home/max/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/metrics/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_base = pd.Series(np.zeros(len(y_test)))\n",
    "y_base.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '_AXIS_LEN',\n",
       " '_AXIS_ORDERS',\n",
       " '_AXIS_TO_AXIS_NUMBER',\n",
       " '_HANDLED_TYPES',\n",
       " '__abs__',\n",
       " '__add__',\n",
       " '__and__',\n",
       " '__annotations__',\n",
       " '__array__',\n",
       " '__array_priority__',\n",
       " '__array_ufunc__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__column_consortium_standard__',\n",
       " '__contains__',\n",
       " '__copy__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__divmod__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__finalize__',\n",
       " '__float__',\n",
       " '__floordiv__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__ifloordiv__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__int__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pandas_priority__',\n",
       " '__pos__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rand__',\n",
       " '__rdivmod__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rfloordiv__',\n",
       " '__rmatmul__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__ror__',\n",
       " '__round__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__rxor__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_accessors',\n",
       " '_accum_func',\n",
       " '_agg_examples_doc',\n",
       " '_agg_see_also_doc',\n",
       " '_align_for_op',\n",
       " '_align_frame',\n",
       " '_align_series',\n",
       " '_append',\n",
       " '_arith_method',\n",
       " '_as_manager',\n",
       " '_attrs',\n",
       " '_binop',\n",
       " '_can_hold_na',\n",
       " '_check_inplace_and_allows_duplicate_labels',\n",
       " '_check_is_chained_assignment_possible',\n",
       " '_check_label_or_level_ambiguity',\n",
       " '_check_setitem_copy',\n",
       " '_clear_item_cache',\n",
       " '_clip_with_one_bound',\n",
       " '_clip_with_scalar',\n",
       " '_cmp_method',\n",
       " '_consolidate',\n",
       " '_consolidate_inplace',\n",
       " '_construct_axes_dict',\n",
       " '_construct_result',\n",
       " '_constructor',\n",
       " '_constructor_expanddim',\n",
       " '_constructor_expanddim_from_mgr',\n",
       " '_constructor_from_mgr',\n",
       " '_data',\n",
       " '_deprecate_downcast',\n",
       " '_dir_additions',\n",
       " '_dir_deletions',\n",
       " '_drop_axis',\n",
       " '_drop_labels_or_levels',\n",
       " '_duplicated',\n",
       " '_find_valid_index',\n",
       " '_flags',\n",
       " '_flex_method',\n",
       " '_from_mgr',\n",
       " '_get_axis',\n",
       " '_get_axis_name',\n",
       " '_get_axis_number',\n",
       " '_get_axis_resolvers',\n",
       " '_get_block_manager_axis',\n",
       " '_get_bool_data',\n",
       " '_get_cacher',\n",
       " '_get_cleaned_column_resolvers',\n",
       " '_get_index_resolvers',\n",
       " '_get_label_or_level_values',\n",
       " '_get_numeric_data',\n",
       " '_get_rows_with_mask',\n",
       " '_get_value',\n",
       " '_get_values_tuple',\n",
       " '_get_with',\n",
       " '_getitem_slice',\n",
       " '_gotitem',\n",
       " '_hidden_attrs',\n",
       " '_indexed_same',\n",
       " '_info_axis',\n",
       " '_info_axis_name',\n",
       " '_info_axis_number',\n",
       " '_init_dict',\n",
       " '_init_mgr',\n",
       " '_inplace_method',\n",
       " '_internal_names',\n",
       " '_internal_names_set',\n",
       " '_is_cached',\n",
       " '_is_copy',\n",
       " '_is_label_or_level_reference',\n",
       " '_is_label_reference',\n",
       " '_is_level_reference',\n",
       " '_is_mixed_type',\n",
       " '_is_view',\n",
       " '_is_view_after_cow_rules',\n",
       " '_item_cache',\n",
       " '_ixs',\n",
       " '_logical_func',\n",
       " '_logical_method',\n",
       " '_map_values',\n",
       " '_maybe_update_cacher',\n",
       " '_memory_usage',\n",
       " '_metadata',\n",
       " '_mgr',\n",
       " '_min_count_stat_function',\n",
       " '_name',\n",
       " '_needs_reindex_multi',\n",
       " '_pad_or_backfill',\n",
       " '_protect_consolidate',\n",
       " '_reduce',\n",
       " '_references',\n",
       " '_reindex_axes',\n",
       " '_reindex_indexer',\n",
       " '_reindex_multi',\n",
       " '_reindex_with_indexers',\n",
       " '_rename',\n",
       " '_replace_single',\n",
       " '_repr_data_resource_',\n",
       " '_repr_latex_',\n",
       " '_reset_cache',\n",
       " '_reset_cacher',\n",
       " '_set_as_cached',\n",
       " '_set_axis',\n",
       " '_set_axis_name',\n",
       " '_set_axis_nocheck',\n",
       " '_set_is_copy',\n",
       " '_set_labels',\n",
       " '_set_name',\n",
       " '_set_value',\n",
       " '_set_values',\n",
       " '_set_with',\n",
       " '_set_with_engine',\n",
       " '_shift_with_freq',\n",
       " '_slice',\n",
       " '_stat_function',\n",
       " '_stat_function_ddof',\n",
       " '_take_with_is_copy',\n",
       " '_to_latex_via_styler',\n",
       " '_typ',\n",
       " '_update_inplace',\n",
       " '_validate_dtype',\n",
       " '_values',\n",
       " '_where',\n",
       " 'abs',\n",
       " 'add',\n",
       " 'add_prefix',\n",
       " 'add_suffix',\n",
       " 'agg',\n",
       " 'aggregate',\n",
       " 'align',\n",
       " 'all',\n",
       " 'any',\n",
       " 'apply',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'array',\n",
       " 'asfreq',\n",
       " 'asof',\n",
       " 'astype',\n",
       " 'at',\n",
       " 'at_time',\n",
       " 'attrs',\n",
       " 'autocorr',\n",
       " 'axes',\n",
       " 'backfill',\n",
       " 'between',\n",
       " 'between_time',\n",
       " 'bfill',\n",
       " 'bool',\n",
       " 'case_when',\n",
       " 'clip',\n",
       " 'combine',\n",
       " 'combine_first',\n",
       " 'compare',\n",
       " 'convert_dtypes',\n",
       " 'copy',\n",
       " 'corr',\n",
       " 'count',\n",
       " 'cov',\n",
       " 'cummax',\n",
       " 'cummin',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'describe',\n",
       " 'diff',\n",
       " 'div',\n",
       " 'divide',\n",
       " 'divmod',\n",
       " 'dot',\n",
       " 'drop',\n",
       " 'drop_duplicates',\n",
       " 'droplevel',\n",
       " 'dropna',\n",
       " 'dtype',\n",
       " 'dtypes',\n",
       " 'duplicated',\n",
       " 'empty',\n",
       " 'eq',\n",
       " 'equals',\n",
       " 'ewm',\n",
       " 'expanding',\n",
       " 'explode',\n",
       " 'factorize',\n",
       " 'ffill',\n",
       " 'fillna',\n",
       " 'filter',\n",
       " 'first',\n",
       " 'first_valid_index',\n",
       " 'flags',\n",
       " 'floordiv',\n",
       " 'ge',\n",
       " 'get',\n",
       " 'groupby',\n",
       " 'gt',\n",
       " 'hasnans',\n",
       " 'head',\n",
       " 'hist',\n",
       " 'iat',\n",
       " 'idxmax',\n",
       " 'idxmin',\n",
       " 'iloc',\n",
       " 'index',\n",
       " 'infer_objects',\n",
       " 'info',\n",
       " 'interpolate',\n",
       " 'is_monotonic_decreasing',\n",
       " 'is_monotonic_increasing',\n",
       " 'is_unique',\n",
       " 'isin',\n",
       " 'isna',\n",
       " 'isnull',\n",
       " 'item',\n",
       " 'items',\n",
       " 'keys',\n",
       " 'kurt',\n",
       " 'kurtosis',\n",
       " 'last',\n",
       " 'last_valid_index',\n",
       " 'le',\n",
       " 'list',\n",
       " 'loc',\n",
       " 'lt',\n",
       " 'map',\n",
       " 'mask',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'memory_usage',\n",
       " 'min',\n",
       " 'mod',\n",
       " 'mode',\n",
       " 'mul',\n",
       " 'multiply',\n",
       " 'name',\n",
       " 'nbytes',\n",
       " 'ndim',\n",
       " 'ne',\n",
       " 'nlargest',\n",
       " 'notna',\n",
       " 'notnull',\n",
       " 'nsmallest',\n",
       " 'nunique',\n",
       " 'pad',\n",
       " 'pct_change',\n",
       " 'pipe',\n",
       " 'plot',\n",
       " 'pop',\n",
       " 'pow',\n",
       " 'prod',\n",
       " 'product',\n",
       " 'quantile',\n",
       " 'radd',\n",
       " 'rank',\n",
       " 'ravel',\n",
       " 'rdiv',\n",
       " 'rdivmod',\n",
       " 'reindex',\n",
       " 'reindex_like',\n",
       " 'rename',\n",
       " 'rename_axis',\n",
       " 'reorder_levels',\n",
       " 'repeat',\n",
       " 'replace',\n",
       " 'resample',\n",
       " 'reset_index',\n",
       " 'rfloordiv',\n",
       " 'rmod',\n",
       " 'rmul',\n",
       " 'rolling',\n",
       " 'round',\n",
       " 'rpow',\n",
       " 'rsub',\n",
       " 'rtruediv',\n",
       " 'sample',\n",
       " 'searchsorted',\n",
       " 'sem',\n",
       " 'set_axis',\n",
       " 'set_flags',\n",
       " 'shape',\n",
       " 'shift',\n",
       " 'size',\n",
       " 'skew',\n",
       " 'sort_index',\n",
       " 'sort_values',\n",
       " 'squeeze',\n",
       " 'std',\n",
       " 'struct',\n",
       " 'sub',\n",
       " 'subtract',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'swaplevel',\n",
       " 'tail',\n",
       " 'take',\n",
       " 'to_clipboard',\n",
       " 'to_csv',\n",
       " 'to_dict',\n",
       " 'to_excel',\n",
       " 'to_frame',\n",
       " 'to_hdf',\n",
       " 'to_json',\n",
       " 'to_latex',\n",
       " 'to_list',\n",
       " 'to_markdown',\n",
       " 'to_numpy',\n",
       " 'to_period',\n",
       " 'to_pickle',\n",
       " 'to_sql',\n",
       " 'to_string',\n",
       " 'to_timestamp',\n",
       " 'to_xarray',\n",
       " 'transform',\n",
       " 'transpose',\n",
       " 'truediv',\n",
       " 'truncate',\n",
       " 'tz_convert',\n",
       " 'tz_localize',\n",
       " 'unique',\n",
       " 'unstack',\n",
       " 'update',\n",
       " 'value_counts',\n",
       " 'values',\n",
       " 'var',\n",
       " 'view',\n",
       " 'where',\n",
       " 'xs']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    0.990738\n",
       "1    0.009262\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, y_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995850622406639"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9504950495049505"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline precision score:  0.0\n",
      "RF precision score:  0.995850622406639\n",
      "LR precision score:  0.9504950495049505\n"
     ]
    }
   ],
   "source": [
    "print('Baseline precision score: ', precision_score(y_test, y_base))\n",
    "print('RF precision score: ', precision_score(y_test, rf.predict(X_test)))\n",
    "print('LR precision score: ', precision_score(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ConfusionMatrixDisplay',\n",
       " 'DetCurveDisplay',\n",
       " 'DistanceMetric',\n",
       " 'PrecisionRecallDisplay',\n",
       " 'PredictionErrorDisplay',\n",
       " 'RocCurveDisplay',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_base',\n",
       " '_classification',\n",
       " '_dist_metrics',\n",
       " '_pairwise_distances_reduction',\n",
       " '_pairwise_fast',\n",
       " '_plot',\n",
       " '_ranking',\n",
       " '_regression',\n",
       " '_scorer',\n",
       " 'accuracy_score',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'auc',\n",
       " 'average_precision_score',\n",
       " 'balanced_accuracy_score',\n",
       " 'brier_score_loss',\n",
       " 'calinski_harabasz_score',\n",
       " 'check_scoring',\n",
       " 'class_likelihood_ratios',\n",
       " 'classification_report',\n",
       " 'cluster',\n",
       " 'cohen_kappa_score',\n",
       " 'completeness_score',\n",
       " 'confusion_matrix',\n",
       " 'consensus_score',\n",
       " 'coverage_error',\n",
       " 'd2_absolute_error_score',\n",
       " 'd2_log_loss_score',\n",
       " 'd2_pinball_score',\n",
       " 'd2_tweedie_score',\n",
       " 'davies_bouldin_score',\n",
       " 'dcg_score',\n",
       " 'det_curve',\n",
       " 'euclidean_distances',\n",
       " 'explained_variance_score',\n",
       " 'f1_score',\n",
       " 'fbeta_score',\n",
       " 'fowlkes_mallows_score',\n",
       " 'get_scorer',\n",
       " 'get_scorer_names',\n",
       " 'hamming_loss',\n",
       " 'hinge_loss',\n",
       " 'homogeneity_completeness_v_measure',\n",
       " 'homogeneity_score',\n",
       " 'jaccard_score',\n",
       " 'label_ranking_average_precision_score',\n",
       " 'label_ranking_loss',\n",
       " 'log_loss',\n",
       " 'make_scorer',\n",
       " 'matthews_corrcoef',\n",
       " 'max_error',\n",
       " 'mean_absolute_error',\n",
       " 'mean_absolute_percentage_error',\n",
       " 'mean_gamma_deviance',\n",
       " 'mean_pinball_loss',\n",
       " 'mean_poisson_deviance',\n",
       " 'mean_squared_error',\n",
       " 'mean_squared_log_error',\n",
       " 'mean_tweedie_deviance',\n",
       " 'median_absolute_error',\n",
       " 'multilabel_confusion_matrix',\n",
       " 'mutual_info_score',\n",
       " 'nan_euclidean_distances',\n",
       " 'ndcg_score',\n",
       " 'normalized_mutual_info_score',\n",
       " 'pair_confusion_matrix',\n",
       " 'pairwise',\n",
       " 'pairwise_distances',\n",
       " 'pairwise_distances_argmin',\n",
       " 'pairwise_distances_argmin_min',\n",
       " 'pairwise_distances_chunked',\n",
       " 'pairwise_kernels',\n",
       " 'precision_recall_curve',\n",
       " 'precision_recall_fscore_support',\n",
       " 'precision_score',\n",
       " 'r2_score',\n",
       " 'rand_score',\n",
       " 'recall_score',\n",
       " 'roc_auc_score',\n",
       " 'roc_curve',\n",
       " 'root_mean_squared_error',\n",
       " 'root_mean_squared_log_error',\n",
       " 'silhouette_samples',\n",
       " 'silhouette_score',\n",
       " 'top_k_accuracy_score',\n",
       " 'v_measure_score',\n",
       " 'zero_one_loss']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_base = pd.Series(np.zeros(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline recall score:  0.0\n",
      "RF recall score:  0.5925925925925926\n",
      "LR recall score:  0.7111111111111111\n"
     ]
    }
   ],
   "source": [
    "print('Baseline recall score: ', recall_score(y_test, y_base))\n",
    "print('RF recall score: ', recall_score(y_test, rf.predict(X_test)))\n",
    "print('LR recall score: ', recall_score(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ConfusionMatrixDisplay',\n",
       " 'DetCurveDisplay',\n",
       " 'DistanceMetric',\n",
       " 'PrecisionRecallDisplay',\n",
       " 'PredictionErrorDisplay',\n",
       " 'RocCurveDisplay',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_base',\n",
       " '_classification',\n",
       " '_dist_metrics',\n",
       " '_pairwise_distances_reduction',\n",
       " '_pairwise_fast',\n",
       " '_plot',\n",
       " '_ranking',\n",
       " '_regression',\n",
       " '_scorer',\n",
       " 'accuracy_score',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'auc',\n",
       " 'average_precision_score',\n",
       " 'balanced_accuracy_score',\n",
       " 'brier_score_loss',\n",
       " 'calinski_harabasz_score',\n",
       " 'check_scoring',\n",
       " 'class_likelihood_ratios',\n",
       " 'classification_report',\n",
       " 'cluster',\n",
       " 'cohen_kappa_score',\n",
       " 'completeness_score',\n",
       " 'confusion_matrix',\n",
       " 'consensus_score',\n",
       " 'coverage_error',\n",
       " 'd2_absolute_error_score',\n",
       " 'd2_log_loss_score',\n",
       " 'd2_pinball_score',\n",
       " 'd2_tweedie_score',\n",
       " 'davies_bouldin_score',\n",
       " 'dcg_score',\n",
       " 'det_curve',\n",
       " 'euclidean_distances',\n",
       " 'explained_variance_score',\n",
       " 'f1_score',\n",
       " 'fbeta_score',\n",
       " 'fowlkes_mallows_score',\n",
       " 'get_scorer',\n",
       " 'get_scorer_names',\n",
       " 'hamming_loss',\n",
       " 'hinge_loss',\n",
       " 'homogeneity_completeness_v_measure',\n",
       " 'homogeneity_score',\n",
       " 'jaccard_score',\n",
       " 'label_ranking_average_precision_score',\n",
       " 'label_ranking_loss',\n",
       " 'log_loss',\n",
       " 'make_scorer',\n",
       " 'matthews_corrcoef',\n",
       " 'max_error',\n",
       " 'mean_absolute_error',\n",
       " 'mean_absolute_percentage_error',\n",
       " 'mean_gamma_deviance',\n",
       " 'mean_pinball_loss',\n",
       " 'mean_poisson_deviance',\n",
       " 'mean_squared_error',\n",
       " 'mean_squared_log_error',\n",
       " 'mean_tweedie_deviance',\n",
       " 'median_absolute_error',\n",
       " 'multilabel_confusion_matrix',\n",
       " 'mutual_info_score',\n",
       " 'nan_euclidean_distances',\n",
       " 'ndcg_score',\n",
       " 'normalized_mutual_info_score',\n",
       " 'pair_confusion_matrix',\n",
       " 'pairwise',\n",
       " 'pairwise_distances',\n",
       " 'pairwise_distances_argmin',\n",
       " 'pairwise_distances_argmin_min',\n",
       " 'pairwise_distances_chunked',\n",
       " 'pairwise_kernels',\n",
       " 'precision_recall_curve',\n",
       " 'precision_recall_fscore_support',\n",
       " 'precision_score',\n",
       " 'r2_score',\n",
       " 'rand_score',\n",
       " 'recall_score',\n",
       " 'roc_auc_score',\n",
       " 'roc_curve',\n",
       " 'root_mean_squared_error',\n",
       " 'root_mean_squared_log_error',\n",
       " 'silhouette_samples',\n",
       " 'silhouette_score',\n",
       " 'top_k_accuracy_score',\n",
       " 'v_measure_score',\n",
       " 'zero_one_loss']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_base= pd.Series(np.zeros(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline F1 score:  0.0\n",
      "RF F1 score: 0.7430340557275542\n",
      "LR F1 score : 0.8135593220338984\n"
     ]
    }
   ],
   "source": [
    "print('Baseline F1 score: ', f1_score(y_test, y_base))\n",
    "print(f\"RF F1 score: {f1_score(y_test, rf.predict(X_test))}\")\n",
    "print(f\"LR F1 score : {f1_score(y_test, lr.predict(X_test))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ConfusionMatrixDisplay',\n",
       " 'DetCurveDisplay',\n",
       " 'DistanceMetric',\n",
       " 'PrecisionRecallDisplay',\n",
       " 'PredictionErrorDisplay',\n",
       " 'RocCurveDisplay',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_base',\n",
       " '_classification',\n",
       " '_dist_metrics',\n",
       " '_pairwise_distances_reduction',\n",
       " '_pairwise_fast',\n",
       " '_plot',\n",
       " '_ranking',\n",
       " '_regression',\n",
       " '_scorer',\n",
       " 'accuracy_score',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'auc',\n",
       " 'average_precision_score',\n",
       " 'balanced_accuracy_score',\n",
       " 'brier_score_loss',\n",
       " 'calinski_harabasz_score',\n",
       " 'check_scoring',\n",
       " 'class_likelihood_ratios',\n",
       " 'classification_report',\n",
       " 'cluster',\n",
       " 'cohen_kappa_score',\n",
       " 'completeness_score',\n",
       " 'confusion_matrix',\n",
       " 'consensus_score',\n",
       " 'coverage_error',\n",
       " 'd2_absolute_error_score',\n",
       " 'd2_log_loss_score',\n",
       " 'd2_pinball_score',\n",
       " 'd2_tweedie_score',\n",
       " 'davies_bouldin_score',\n",
       " 'dcg_score',\n",
       " 'det_curve',\n",
       " 'euclidean_distances',\n",
       " 'explained_variance_score',\n",
       " 'f1_score',\n",
       " 'fbeta_score',\n",
       " 'fowlkes_mallows_score',\n",
       " 'get_scorer',\n",
       " 'get_scorer_names',\n",
       " 'hamming_loss',\n",
       " 'hinge_loss',\n",
       " 'homogeneity_completeness_v_measure',\n",
       " 'homogeneity_score',\n",
       " 'jaccard_score',\n",
       " 'label_ranking_average_precision_score',\n",
       " 'label_ranking_loss',\n",
       " 'log_loss',\n",
       " 'make_scorer',\n",
       " 'matthews_corrcoef',\n",
       " 'max_error',\n",
       " 'mean_absolute_error',\n",
       " 'mean_absolute_percentage_error',\n",
       " 'mean_gamma_deviance',\n",
       " 'mean_pinball_loss',\n",
       " 'mean_poisson_deviance',\n",
       " 'mean_squared_error',\n",
       " 'mean_squared_log_error',\n",
       " 'mean_tweedie_deviance',\n",
       " 'median_absolute_error',\n",
       " 'multilabel_confusion_matrix',\n",
       " 'mutual_info_score',\n",
       " 'nan_euclidean_distances',\n",
       " 'ndcg_score',\n",
       " 'normalized_mutual_info_score',\n",
       " 'pair_confusion_matrix',\n",
       " 'pairwise',\n",
       " 'pairwise_distances',\n",
       " 'pairwise_distances_argmin',\n",
       " 'pairwise_distances_argmin_min',\n",
       " 'pairwise_distances_chunked',\n",
       " 'pairwise_kernels',\n",
       " 'precision_recall_curve',\n",
       " 'precision_recall_fscore_support',\n",
       " 'precision_score',\n",
       " 'r2_score',\n",
       " 'rand_score',\n",
       " 'recall_score',\n",
       " 'roc_auc_score',\n",
       " 'roc_curve',\n",
       " 'root_mean_squared_error',\n",
       " 'root_mean_squared_log_error',\n",
       " 'silhouette_samples',\n",
       " 'silhouette_score',\n",
       " 'top_k_accuracy_score',\n",
       " 'v_measure_score',\n",
       " 'zero_one_loss']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f-score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'warn'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Compute precision, recall, F-measure and support for each class.\n",
      "\n",
      "The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\n",
      "true positives and ``fp`` the number of false positives. The precision is\n",
      "intuitively the ability of the classifier not to label a negative sample as\n",
      "positive.\n",
      "\n",
      "The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\n",
      "true positives and ``fn`` the number of false negatives. The recall is\n",
      "intuitively the ability of the classifier to find all the positive samples.\n",
      "\n",
      "The F-beta score can be interpreted as a weighted harmonic mean of\n",
      "the precision and recall, where an F-beta score reaches its best\n",
      "value at 1 and worst score at 0.\n",
      "\n",
      "The F-beta score weights recall more than precision by a factor of\n",
      "``beta``. ``beta == 1.0`` means recall and precision are equally important.\n",
      "\n",
      "The support is the number of occurrences of each class in ``y_true``.\n",
      "\n",
      "Support beyond term:`binary` targets is achieved by treating :term:`multiclass`\n",
      "and :term:`multilabel` data as a collection of binary problems, one for each\n",
      "label. For the :term:`binary` case, setting `average='binary'` will return\n",
      "metrics for `pos_label`. If `average` is not `'binary'`, `pos_label` is ignored\n",
      "and metrics for both classes are computed, then averaged or both returned (when\n",
      "`average=None`). Similarly, for :term:`multiclass` and :term:`multilabel` targets,\n",
      "metrics for all `labels` are either returned or averaged depending on the `average`\n",
      "parameter. Use `labels` specify the set of labels to calculate metrics for.\n",
      "\n",
      "Read more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "    Ground truth (correct) target values.\n",
      "\n",
      "y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "    Estimated targets as returned by a classifier.\n",
      "\n",
      "beta : float, default=1.0\n",
      "    The strength of recall versus precision in the F-score.\n",
      "\n",
      "labels : array-like, default=None\n",
      "    The set of labels to include when `average != 'binary'`, and their\n",
      "    order if `average is None`. Labels present in the data can be\n",
      "    excluded, for example in multiclass classification to exclude a \"negative\n",
      "    class\". Labels not present in the data can be included and will be\n",
      "    \"assigned\" 0 samples. For multilabel targets, labels are column indices.\n",
      "    By default, all labels in `y_true` and `y_pred` are used in sorted order.\n",
      "\n",
      "    .. versionchanged:: 0.17\n",
      "       Parameter `labels` improved for multiclass problem.\n",
      "\n",
      "pos_label : int, float, bool or str, default=1\n",
      "    The class to report if `average='binary'` and the data is binary,\n",
      "    otherwise this parameter is ignored.\n",
      "    For multiclass or multilabel targets, set `labels=[pos_label]` and\n",
      "    `average != 'binary'` to report metrics for one label only.\n",
      "\n",
      "average : {'micro', 'macro', 'samples', 'weighted', 'binary'} or None,             default='binary'\n",
      "    This parameter is required for multiclass/multilabel targets.\n",
      "    If ``None``, the metrics for each class are returned. Otherwise, this\n",
      "    determines the type of averaging performed on the data:\n",
      "\n",
      "    ``'binary'``:\n",
      "        Only report results for the class specified by ``pos_label``.\n",
      "        This is applicable only if targets (``y_{true,pred}``) are binary.\n",
      "    ``'micro'``:\n",
      "        Calculate metrics globally by counting the total true positives,\n",
      "        false negatives and false positives.\n",
      "    ``'macro'``:\n",
      "        Calculate metrics for each label, and find their unweighted\n",
      "        mean.  This does not take label imbalance into account.\n",
      "    ``'weighted'``:\n",
      "        Calculate metrics for each label, and find their average weighted\n",
      "        by support (the number of true instances for each label). This\n",
      "        alters 'macro' to account for label imbalance; it can result in an\n",
      "        F-score that is not between precision and recall.\n",
      "    ``'samples'``:\n",
      "        Calculate metrics for each instance, and find their average (only\n",
      "        meaningful for multilabel classification where this differs from\n",
      "        :func:`accuracy_score`).\n",
      "\n",
      "warn_for : list, tuple or set, for internal use\n",
      "    This determines which warnings will be made in the case that this\n",
      "    function is being used to return only one of its metrics.\n",
      "\n",
      "sample_weight : array-like of shape (n_samples,), default=None\n",
      "    Sample weights.\n",
      "\n",
      "zero_division : {\"warn\", 0.0, 1.0, np.nan}, default=\"warn\"\n",
      "    Sets the value to return when there is a zero division:\n",
      "\n",
      "    - recall: when there are no positive labels\n",
      "    - precision: when there are no positive predictions\n",
      "    - f-score: both\n",
      "\n",
      "    Notes:\n",
      "\n",
      "    - If set to \"warn\", this acts like 0, but a warning is also raised.\n",
      "    - If set to `np.nan`, such values will be excluded from the average.\n",
      "\n",
      "    .. versionadded:: 1.3\n",
      "       `np.nan` option was added.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "precision : float (if average is not None) or array of float, shape =        [n_unique_labels]\n",
      "    Precision score.\n",
      "\n",
      "recall : float (if average is not None) or array of float, shape =        [n_unique_labels]\n",
      "    Recall score.\n",
      "\n",
      "fbeta_score : float (if average is not None) or array of float, shape =        [n_unique_labels]\n",
      "    F-beta score.\n",
      "\n",
      "support : None (if average is not None) or array of int, shape =        [n_unique_labels]\n",
      "    The number of occurrences of each label in ``y_true``.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "When ``true positive + false positive == 0``, precision is undefined.\n",
      "When ``true positive + false negative == 0``, recall is undefined. When\n",
      "``true positive + false negative + false positive == 0``, f-score is\n",
      "undefined. In such cases, by default the metric will be set to 0, and\n",
      "``UndefinedMetricWarning`` will be raised. This behavior can be modified\n",
      "with ``zero_division``.\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] `Wikipedia entry for the Precision and recall\n",
      "       <https://en.wikipedia.org/wiki/Precision_and_recall>`_.\n",
      "\n",
      ".. [2] `Wikipedia entry for the F1-score\n",
      "       <https://en.wikipedia.org/wiki/F1_score>`_.\n",
      "\n",
      ".. [3] `Discriminative Methods for Multi-labeled Classification Advances\n",
      "       in Knowledge Discovery and Data Mining (2004), pp. 22-30 by Shantanu\n",
      "       Godbole, Sunita Sarawagi\n",
      "       <http://www.godbole.net/shantanu/pubs/multilabelsvm-pakdd04.pdf>`_.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> import numpy as np\n",
      ">>> from sklearn.metrics import precision_recall_fscore_support\n",
      ">>> y_true = np.array(['cat', 'dog', 'pig', 'cat', 'dog', 'pig'])\n",
      ">>> y_pred = np.array(['cat', 'pig', 'dog', 'cat', 'cat', 'dog'])\n",
      ">>> precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
      "(0.22..., 0.33..., 0.26..., None)\n",
      ">>> precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
      "(0.33..., 0.33..., 0.33..., None)\n",
      ">>> precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
      "(0.22..., 0.33..., 0.26..., None)\n",
      "\n",
      "It is possible to compute per-label precisions, recalls, F1-scores and\n",
      "supports instead of averaging:\n",
      "\n",
      ">>> precision_recall_fscore_support(y_true, y_pred, average=None,\n",
      "... labels=['pig', 'dog', 'cat'])\n",
      "(array([0.        , 0.        , 0.66...]),\n",
      " array([0., 0., 1.]), array([0. , 0. , 0.8]),\n",
      " array([2, 2, 2]))\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "?precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_base = pd.Series(np.zeros(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ConfusionMatrixDisplay',\n",
       " 'DetCurveDisplay',\n",
       " 'DistanceMetric',\n",
       " 'PrecisionRecallDisplay',\n",
       " 'PredictionErrorDisplay',\n",
       " 'RocCurveDisplay',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_base',\n",
       " '_classification',\n",
       " '_dist_metrics',\n",
       " '_pairwise_distances_reduction',\n",
       " '_pairwise_fast',\n",
       " '_plot',\n",
       " '_ranking',\n",
       " '_regression',\n",
       " '_scorer',\n",
       " 'accuracy_score',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'auc',\n",
       " 'average_precision_score',\n",
       " 'balanced_accuracy_score',\n",
       " 'brier_score_loss',\n",
       " 'calinski_harabasz_score',\n",
       " 'check_scoring',\n",
       " 'class_likelihood_ratios',\n",
       " 'classification_report',\n",
       " 'cluster',\n",
       " 'cohen_kappa_score',\n",
       " 'completeness_score',\n",
       " 'confusion_matrix',\n",
       " 'consensus_score',\n",
       " 'coverage_error',\n",
       " 'd2_absolute_error_score',\n",
       " 'd2_log_loss_score',\n",
       " 'd2_pinball_score',\n",
       " 'd2_tweedie_score',\n",
       " 'davies_bouldin_score',\n",
       " 'dcg_score',\n",
       " 'det_curve',\n",
       " 'euclidean_distances',\n",
       " 'explained_variance_score',\n",
       " 'f1_score',\n",
       " 'fbeta_score',\n",
       " 'fowlkes_mallows_score',\n",
       " 'get_scorer',\n",
       " 'get_scorer_names',\n",
       " 'hamming_loss',\n",
       " 'hinge_loss',\n",
       " 'homogeneity_completeness_v_measure',\n",
       " 'homogeneity_score',\n",
       " 'jaccard_score',\n",
       " 'label_ranking_average_precision_score',\n",
       " 'label_ranking_loss',\n",
       " 'log_loss',\n",
       " 'make_scorer',\n",
       " 'matthews_corrcoef',\n",
       " 'max_error',\n",
       " 'mean_absolute_error',\n",
       " 'mean_absolute_percentage_error',\n",
       " 'mean_gamma_deviance',\n",
       " 'mean_pinball_loss',\n",
       " 'mean_poisson_deviance',\n",
       " 'mean_squared_error',\n",
       " 'mean_squared_log_error',\n",
       " 'mean_tweedie_deviance',\n",
       " 'median_absolute_error',\n",
       " 'multilabel_confusion_matrix',\n",
       " 'mutual_info_score',\n",
       " 'nan_euclidean_distances',\n",
       " 'ndcg_score',\n",
       " 'normalized_mutual_info_score',\n",
       " 'pair_confusion_matrix',\n",
       " 'pairwise',\n",
       " 'pairwise_distances',\n",
       " 'pairwise_distances_argmin',\n",
       " 'pairwise_distances_argmin_min',\n",
       " 'pairwise_distances_chunked',\n",
       " 'pairwise_kernels',\n",
       " 'precision_recall_curve',\n",
       " 'precision_recall_fscore_support',\n",
       " 'precision_score',\n",
       " 'r2_score',\n",
       " 'rand_score',\n",
       " 'recall_score',\n",
       " 'roc_auc_score',\n",
       " 'roc_curve',\n",
       " 'root_mean_squared_error',\n",
       " 'root_mean_squared_log_error',\n",
       " 'silhouette_samples',\n",
       " 'silhouette_score',\n",
       " 'top_k_accuracy_score',\n",
       " 'v_measure_score',\n",
       " 'zero_one_loss']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m\n",
      "\u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f-score'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'warn'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Compute precision, recall, F-measure and support for each class.\n",
      "\n",
      "The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\n",
      "true positives and ``fp`` the number of false positives. The precision is\n",
      "intuitively the ability of the classifier not to label a negative sample as\n",
      "positive.\n",
      "\n",
      "The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of\n",
      "true positives and ``fn`` the number of false negatives. The recall is\n",
      "intuitively the ability of the classifier to find all the positive samples.\n",
      "\n",
      "The F-beta score can be interpreted as a weighted harmonic mean of\n",
      "the precision and recall, where an F-beta score reaches its best\n",
      "value at 1 and worst score at 0.\n",
      "\n",
      "The F-beta score weights recall more than precision by a factor of\n",
      "``beta``. ``beta == 1.0`` means recall and precision are equally important.\n",
      "\n",
      "The support is the number of occurrences of each class in ``y_true``.\n",
      "\n",
      "Support beyond term:`binary` targets is achieved by treating :term:`multiclass`\n",
      "and :term:`multilabel` data as a collection of binary problems, one for each\n",
      "label. For the :term:`binary` case, setting `average='binary'` will return\n",
      "metrics for `pos_label`. If `average` is not `'binary'`, `pos_label` is ignored\n",
      "and metrics for both classes are computed, then averaged or both returned (when\n",
      "`average=None`). Similarly, for :term:`multiclass` and :term:`multilabel` targets,\n",
      "metrics for all `labels` are either returned or averaged depending on the `average`\n",
      "parameter. Use `labels` specify the set of labels to calculate metrics for.\n",
      "\n",
      "Read more in the :ref:`User Guide <precision_recall_f_measure_metrics>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "y_true : 1d array-like, or label indicator array / sparse matrix\n",
      "    Ground truth (correct) target values.\n",
      "\n",
      "y_pred : 1d array-like, or label indicator array / sparse matrix\n",
      "    Estimated targets as returned by a classifier.\n",
      "\n",
      "beta : float, default=1.0\n",
      "    The strength of recall versus precision in the F-score.\n",
      "\n",
      "labels : array-like, default=None\n",
      "    The set of labels to include when `average != 'binary'`, and their\n",
      "    order if `average is None`. Labels present in the data can be\n",
      "    excluded, for example in multiclass classification to exclude a \"negative\n",
      "    class\". Labels not present in the data can be included and will be\n",
      "    \"assigned\" 0 samples. For multilabel targets, labels are column indices.\n",
      "    By default, all labels in `y_true` and `y_pred` are used in sorted order.\n",
      "\n",
      "    .. versionchanged:: 0.17\n",
      "       Parameter `labels` improved for multiclass problem.\n",
      "\n",
      "pos_label : int, float, bool or str, default=1\n",
      "    The class to report if `average='binary'` and the data is binary,\n",
      "    otherwise this parameter is ignored.\n",
      "    For multiclass or multilabel targets, set `labels=[pos_label]` and\n",
      "    `average != 'binary'` to report metrics for one label only.\n",
      "\n",
      "average : {'micro', 'macro', 'samples', 'weighted', 'binary'} or None,             default='binary'\n",
      "    This parameter is required for multiclass/multilabel targets.\n",
      "    If ``None``, the metrics for each class are returned. Otherwise, this\n",
      "    determines the type of averaging performed on the data:\n",
      "\n",
      "    ``'binary'``:\n",
      "        Only report results for the class specified by ``pos_label``.\n",
      "        This is applicable only if targets (``y_{true,pred}``) are binary.\n",
      "    ``'micro'``:\n",
      "        Calculate metrics globally by counting the total true positives,\n",
      "        false negatives and false positives.\n",
      "    ``'macro'``:\n",
      "        Calculate metrics for each label, and find their unweighted\n",
      "        mean.  This does not take label imbalance into account.\n",
      "    ``'weighted'``:\n",
      "        Calculate metrics for each label, and find their average weighted\n",
      "        by support (the number of true instances for each label). This\n",
      "        alters 'macro' to account for label imbalance; it can result in an\n",
      "        F-score that is not between precision and recall.\n",
      "    ``'samples'``:\n",
      "        Calculate metrics for each instance, and find their average (only\n",
      "        meaningful for multilabel classification where this differs from\n",
      "        :func:`accuracy_score`).\n",
      "\n",
      "warn_for : list, tuple or set, for internal use\n",
      "    This determines which warnings will be made in the case that this\n",
      "    function is being used to return only one of its metrics.\n",
      "\n",
      "sample_weight : array-like of shape (n_samples,), default=None\n",
      "    Sample weights.\n",
      "\n",
      "zero_division : {\"warn\", 0.0, 1.0, np.nan}, default=\"warn\"\n",
      "    Sets the value to return when there is a zero division:\n",
      "\n",
      "    - recall: when there are no positive labels\n",
      "    - precision: when there are no positive predictions\n",
      "    - f-score: both\n",
      "\n",
      "    Notes:\n",
      "\n",
      "    - If set to \"warn\", this acts like 0, but a warning is also raised.\n",
      "    - If set to `np.nan`, such values will be excluded from the average.\n",
      "\n",
      "    .. versionadded:: 1.3\n",
      "       `np.nan` option was added.\n",
      "\n",
      "Returns\n",
      "-------\n",
      "precision : float (if average is not None) or array of float, shape =        [n_unique_labels]\n",
      "    Precision score.\n",
      "\n",
      "recall : float (if average is not None) or array of float, shape =        [n_unique_labels]\n",
      "    Recall score.\n",
      "\n",
      "fbeta_score : float (if average is not None) or array of float, shape =        [n_unique_labels]\n",
      "    F-beta score.\n",
      "\n",
      "support : None (if average is not None) or array of int, shape =        [n_unique_labels]\n",
      "    The number of occurrences of each label in ``y_true``.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "When ``true positive + false positive == 0``, precision is undefined.\n",
      "When ``true positive + false negative == 0``, recall is undefined. When\n",
      "``true positive + false negative + false positive == 0``, f-score is\n",
      "undefined. In such cases, by default the metric will be set to 0, and\n",
      "``UndefinedMetricWarning`` will be raised. This behavior can be modified\n",
      "with ``zero_division``.\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] `Wikipedia entry for the Precision and recall\n",
      "       <https://en.wikipedia.org/wiki/Precision_and_recall>`_.\n",
      "\n",
      ".. [2] `Wikipedia entry for the F1-score\n",
      "       <https://en.wikipedia.org/wiki/F1_score>`_.\n",
      "\n",
      ".. [3] `Discriminative Methods for Multi-labeled Classification Advances\n",
      "       in Knowledge Discovery and Data Mining (2004), pp. 22-30 by Shantanu\n",
      "       Godbole, Sunita Sarawagi\n",
      "       <http://www.godbole.net/shantanu/pubs/multilabelsvm-pakdd04.pdf>`_.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> import numpy as np\n",
      ">>> from sklearn.metrics import precision_recall_fscore_support\n",
      ">>> y_true = np.array(['cat', 'dog', 'pig', 'cat', 'dog', 'pig'])\n",
      ">>> y_pred = np.array(['cat', 'pig', 'dog', 'cat', 'cat', 'dog'])\n",
      ">>> precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
      "(0.22..., 0.33..., 0.26..., None)\n",
      ">>> precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
      "(0.33..., 0.33..., 0.33..., None)\n",
      ">>> precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
      "(0.22..., 0.33..., 0.26..., None)\n",
      "\n",
      "It is possible to compute per-label precisions, recalls, F1-scores and\n",
      "supports instead of averaging:\n",
      "\n",
      ">>> precision_recall_fscore_support(y_true, y_pred, average=None,\n",
      "... labels=['pig', 'dog', 'cat'])\n",
      "(array([0.        , 0.        , 0.66...]),\n",
      " array([0., 0., 1.]), array([0. , 0. , 0.8]),\n",
      " array([2, 2, 2]))\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py\n",
      "\u001b[0;31mType:\u001b[0m      function"
     ]
    }
   ],
   "source": [
    "?precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fscore, support =precision_recall_fscore_support(y_test, y_base, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Baseline precision: [0.99073778 0.        ]\n",
      "      Baseline recall: [1. 0.]\n",
      "    Baseline fscore: [0.99534734 0.        ]\n",
      "    Baseline support; [43321   405]\n",
      "      \n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "      Baseline precision: {precision}\n",
    "      Baseline recall: {recall}\n",
    "    Baseline fscore: {fscore}\n",
    "    Baseline support; {support}\n",
    "      \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ConfusionMatrixDisplay',\n",
       " 'DetCurveDisplay',\n",
       " 'DistanceMetric',\n",
       " 'PrecisionRecallDisplay',\n",
       " 'PredictionErrorDisplay',\n",
       " 'RocCurveDisplay',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_base',\n",
       " '_classification',\n",
       " '_dist_metrics',\n",
       " '_pairwise_distances_reduction',\n",
       " '_pairwise_fast',\n",
       " '_plot',\n",
       " '_ranking',\n",
       " '_regression',\n",
       " '_scorer',\n",
       " 'accuracy_score',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'auc',\n",
       " 'average_precision_score',\n",
       " 'balanced_accuracy_score',\n",
       " 'brier_score_loss',\n",
       " 'calinski_harabasz_score',\n",
       " 'check_scoring',\n",
       " 'class_likelihood_ratios',\n",
       " 'classification_report',\n",
       " 'cluster',\n",
       " 'cohen_kappa_score',\n",
       " 'completeness_score',\n",
       " 'confusion_matrix',\n",
       " 'consensus_score',\n",
       " 'coverage_error',\n",
       " 'd2_absolute_error_score',\n",
       " 'd2_log_loss_score',\n",
       " 'd2_pinball_score',\n",
       " 'd2_tweedie_score',\n",
       " 'davies_bouldin_score',\n",
       " 'dcg_score',\n",
       " 'det_curve',\n",
       " 'euclidean_distances',\n",
       " 'explained_variance_score',\n",
       " 'f1_score',\n",
       " 'fbeta_score',\n",
       " 'fowlkes_mallows_score',\n",
       " 'get_scorer',\n",
       " 'get_scorer_names',\n",
       " 'hamming_loss',\n",
       " 'hinge_loss',\n",
       " 'homogeneity_completeness_v_measure',\n",
       " 'homogeneity_score',\n",
       " 'jaccard_score',\n",
       " 'label_ranking_average_precision_score',\n",
       " 'label_ranking_loss',\n",
       " 'log_loss',\n",
       " 'make_scorer',\n",
       " 'matthews_corrcoef',\n",
       " 'max_error',\n",
       " 'mean_absolute_error',\n",
       " 'mean_absolute_percentage_error',\n",
       " 'mean_gamma_deviance',\n",
       " 'mean_pinball_loss',\n",
       " 'mean_poisson_deviance',\n",
       " 'mean_squared_error',\n",
       " 'mean_squared_log_error',\n",
       " 'mean_tweedie_deviance',\n",
       " 'median_absolute_error',\n",
       " 'multilabel_confusion_matrix',\n",
       " 'mutual_info_score',\n",
       " 'nan_euclidean_distances',\n",
       " 'ndcg_score',\n",
       " 'normalized_mutual_info_score',\n",
       " 'pair_confusion_matrix',\n",
       " 'pairwise',\n",
       " 'pairwise_distances',\n",
       " 'pairwise_distances_argmin',\n",
       " 'pairwise_distances_argmin_min',\n",
       " 'pairwise_distances_chunked',\n",
       " 'pairwise_kernels',\n",
       " 'precision_recall_curve',\n",
       " 'precision_recall_fscore_support',\n",
       " 'precision_score',\n",
       " 'r2_score',\n",
       " 'rand_score',\n",
       " 'recall_score',\n",
       " 'roc_auc_score',\n",
       " 'roc_curve',\n",
       " 'root_mean_squared_error',\n",
       " 'root_mean_squared_log_error',\n",
       " 'silhouette_samples',\n",
       " 'silhouette_score',\n",
       " 'top_k_accuracy_score',\n",
       " 'v_measure_score',\n",
       " 'zero_one_loss']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "dir(sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    RF's precision: [0.99620559 0.99585062]\n",
      "    RF's recall: [0.99997692 0.59259259]\n",
      "    RF's fscore: [0.99808769 0.74303406]\n",
      "    RF's support: [43321   405]\n",
      "      \n",
      "      \n",
      "      \n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "    RF's precision: {precision}\n",
    "    RF's recall: {recall}\n",
    "    RF's fscore: {fscore}\n",
    "    RF's support: {support}\n",
    "      \n",
    "      \n",
    "      \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ConfusionMatrixDisplay',\n",
       " 'DetCurveDisplay',\n",
       " 'DistanceMetric',\n",
       " 'PrecisionRecallDisplay',\n",
       " 'PredictionErrorDisplay',\n",
       " 'RocCurveDisplay',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_base',\n",
       " '_classification',\n",
       " '_dist_metrics',\n",
       " '_pairwise_distances_reduction',\n",
       " '_pairwise_fast',\n",
       " '_plot',\n",
       " '_ranking',\n",
       " '_regression',\n",
       " '_scorer',\n",
       " 'accuracy_score',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'auc',\n",
       " 'average_precision_score',\n",
       " 'balanced_accuracy_score',\n",
       " 'brier_score_loss',\n",
       " 'calinski_harabasz_score',\n",
       " 'check_scoring',\n",
       " 'class_likelihood_ratios',\n",
       " 'classification_report',\n",
       " 'cluster',\n",
       " 'cohen_kappa_score',\n",
       " 'completeness_score',\n",
       " 'confusion_matrix',\n",
       " 'consensus_score',\n",
       " 'coverage_error',\n",
       " 'd2_absolute_error_score',\n",
       " 'd2_log_loss_score',\n",
       " 'd2_pinball_score',\n",
       " 'd2_tweedie_score',\n",
       " 'davies_bouldin_score',\n",
       " 'dcg_score',\n",
       " 'det_curve',\n",
       " 'euclidean_distances',\n",
       " 'explained_variance_score',\n",
       " 'f1_score',\n",
       " 'fbeta_score',\n",
       " 'fowlkes_mallows_score',\n",
       " 'get_scorer',\n",
       " 'get_scorer_names',\n",
       " 'hamming_loss',\n",
       " 'hinge_loss',\n",
       " 'homogeneity_completeness_v_measure',\n",
       " 'homogeneity_score',\n",
       " 'jaccard_score',\n",
       " 'label_ranking_average_precision_score',\n",
       " 'label_ranking_loss',\n",
       " 'log_loss',\n",
       " 'make_scorer',\n",
       " 'matthews_corrcoef',\n",
       " 'max_error',\n",
       " 'mean_absolute_error',\n",
       " 'mean_absolute_percentage_error',\n",
       " 'mean_gamma_deviance',\n",
       " 'mean_pinball_loss',\n",
       " 'mean_poisson_deviance',\n",
       " 'mean_squared_error',\n",
       " 'mean_squared_log_error',\n",
       " 'mean_tweedie_deviance',\n",
       " 'median_absolute_error',\n",
       " 'multilabel_confusion_matrix',\n",
       " 'mutual_info_score',\n",
       " 'nan_euclidean_distances',\n",
       " 'ndcg_score',\n",
       " 'normalized_mutual_info_score',\n",
       " 'pair_confusion_matrix',\n",
       " 'pairwise',\n",
       " 'pairwise_distances',\n",
       " 'pairwise_distances_argmin',\n",
       " 'pairwise_distances_argmin_min',\n",
       " 'pairwise_distances_chunked',\n",
       " 'pairwise_kernels',\n",
       " 'precision_recall_curve',\n",
       " 'precision_recall_fscore_support',\n",
       " 'precision_score',\n",
       " 'r2_score',\n",
       " 'rand_score',\n",
       " 'recall_score',\n",
       " 'roc_auc_score',\n",
       " 'roc_curve',\n",
       " 'root_mean_squared_error',\n",
       " 'root_mean_squared_log_error',\n",
       " 'silhouette_samples',\n",
       " 'silhouette_score',\n",
       " 'top_k_accuracy_score',\n",
       " 'v_measure_score',\n",
       " 'zero_one_loss']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "dir(sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, lr.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    LR's precision: [0.99730558 0.95049505]\n",
      "LR's recall: [0.99965375 0.71111111]\n",
      "LR's fscore: [0.99847828 0.81355932]\n",
      "LR's support: [43321   405]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "    LR's precision: {precision}\n",
    "LR's recall: {recall}\n",
    "LR's fscore: {fscore}\n",
    "LR's support: {support}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ConfusionMatrixDisplay',\n",
       " 'DetCurveDisplay',\n",
       " 'DistanceMetric',\n",
       " 'PrecisionRecallDisplay',\n",
       " 'PredictionErrorDisplay',\n",
       " 'RocCurveDisplay',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_base',\n",
       " '_classification',\n",
       " '_dist_metrics',\n",
       " '_pairwise_distances_reduction',\n",
       " '_pairwise_fast',\n",
       " '_plot',\n",
       " '_ranking',\n",
       " '_regression',\n",
       " '_scorer',\n",
       " 'accuracy_score',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'auc',\n",
       " 'average_precision_score',\n",
       " 'balanced_accuracy_score',\n",
       " 'brier_score_loss',\n",
       " 'calinski_harabasz_score',\n",
       " 'check_scoring',\n",
       " 'class_likelihood_ratios',\n",
       " 'classification_report',\n",
       " 'cluster',\n",
       " 'cohen_kappa_score',\n",
       " 'completeness_score',\n",
       " 'confusion_matrix',\n",
       " 'consensus_score',\n",
       " 'coverage_error',\n",
       " 'd2_absolute_error_score',\n",
       " 'd2_log_loss_score',\n",
       " 'd2_pinball_score',\n",
       " 'd2_tweedie_score',\n",
       " 'davies_bouldin_score',\n",
       " 'dcg_score',\n",
       " 'det_curve',\n",
       " 'euclidean_distances',\n",
       " 'explained_variance_score',\n",
       " 'f1_score',\n",
       " 'fbeta_score',\n",
       " 'fowlkes_mallows_score',\n",
       " 'get_scorer',\n",
       " 'get_scorer_names',\n",
       " 'hamming_loss',\n",
       " 'hinge_loss',\n",
       " 'homogeneity_completeness_v_measure',\n",
       " 'homogeneity_score',\n",
       " 'jaccard_score',\n",
       " 'label_ranking_average_precision_score',\n",
       " 'label_ranking_loss',\n",
       " 'log_loss',\n",
       " 'make_scorer',\n",
       " 'matthews_corrcoef',\n",
       " 'max_error',\n",
       " 'mean_absolute_error',\n",
       " 'mean_absolute_percentage_error',\n",
       " 'mean_gamma_deviance',\n",
       " 'mean_pinball_loss',\n",
       " 'mean_poisson_deviance',\n",
       " 'mean_squared_error',\n",
       " 'mean_squared_log_error',\n",
       " 'mean_tweedie_deviance',\n",
       " 'median_absolute_error',\n",
       " 'multilabel_confusion_matrix',\n",
       " 'mutual_info_score',\n",
       " 'nan_euclidean_distances',\n",
       " 'ndcg_score',\n",
       " 'normalized_mutual_info_score',\n",
       " 'pair_confusion_matrix',\n",
       " 'pairwise',\n",
       " 'pairwise_distances',\n",
       " 'pairwise_distances_argmin',\n",
       " 'pairwise_distances_argmin_min',\n",
       " 'pairwise_distances_chunked',\n",
       " 'pairwise_kernels',\n",
       " 'precision_recall_curve',\n",
       " 'precision_recall_fscore_support',\n",
       " 'precision_score',\n",
       " 'r2_score',\n",
       " 'rand_score',\n",
       " 'recall_score',\n",
       " 'roc_auc_score',\n",
       " 'roc_curve',\n",
       " 'root_mean_squared_error',\n",
       " 'root_mean_squared_log_error',\n",
       " 'silhouette_samples',\n",
       " 'silhouette_score',\n",
       " 'top_k_accuracy_score',\n",
       " 'v_measure_score',\n",
       " 'zero_one_loss']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(sklearn.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ClassBalance',\n",
       " 'ClassificationScoreVisualizer',\n",
       " 'ROCAUC',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '__version_info__',\n",
       " '_orig_rc_params',\n",
       " 'anscombe',\n",
       " 'base',\n",
       " 'bestfit',\n",
       " 'classifier',\n",
       " 'color_palette',\n",
       " 'contrib',\n",
       " 'datasaurus',\n",
       " 'draw',\n",
       " 'exceptions',\n",
       " 'get_version',\n",
       " 'mpl',\n",
       " 'reset_defaults',\n",
       " 'reset_orig',\n",
       " 'set_aesthetic',\n",
       " 'set_color_codes',\n",
       " 'set_palette',\n",
       " 'set_style',\n",
       " 'style',\n",
       " 'target',\n",
       " 'utils',\n",
       " 'version']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(yellowbrick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yellowbrick.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ClassBalance',\n",
       " 'ClassPredictionError',\n",
       " 'ClassificationReport',\n",
       " 'ClassificationScoreVisualizer',\n",
       " 'ConfusionMatrix',\n",
       " 'DiscriminationThreshold',\n",
       " 'PRCurve',\n",
       " 'PrecisionRecallCurve',\n",
       " 'ROCAUC',\n",
       " 'ScoreVisualizer',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'base',\n",
       " 'class_balance',\n",
       " 'class_prediction_error',\n",
       " 'classification_report',\n",
       " 'confusion_matrix',\n",
       " 'discrimination_threshold',\n",
       " 'prcurve',\n",
       " 'precision_recall_curve',\n",
       " 'roc_auc',\n",
       " 'rocauc',\n",
       " 'threshold']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(yellowbrick.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ClassBalance',\n",
       " 'ClassificationScoreVisualizer',\n",
       " 'ROCAUC',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '__version_info__',\n",
       " '_orig_rc_params',\n",
       " 'anscombe',\n",
       " 'base',\n",
       " 'bestfit',\n",
       " 'classifier',\n",
       " 'color_palette',\n",
       " 'contrib',\n",
       " 'datasaurus',\n",
       " 'draw',\n",
       " 'exceptions',\n",
       " 'get_version',\n",
       " 'mpl',\n",
       " 'reset_defaults',\n",
       " 'reset_orig',\n",
       " 'set_aesthetic',\n",
       " 'set_color_codes',\n",
       " 'set_palette',\n",
       " 'set_style',\n",
       " 'style',\n",
       " 'target',\n",
       " 'utils',\n",
       " 'version']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(yellowbrick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ClassBalance',\n",
       " 'ClassPredictionError',\n",
       " 'ClassificationReport',\n",
       " 'ClassificationScoreVisualizer',\n",
       " 'ConfusionMatrix',\n",
       " 'DiscriminationThreshold',\n",
       " 'PRCurve',\n",
       " 'PrecisionRecallCurve',\n",
       " 'ROCAUC',\n",
       " 'ScoreVisualizer',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'base',\n",
       " 'class_balance',\n",
       " 'class_prediction_error',\n",
       " 'classification_report',\n",
       " 'confusion_matrix',\n",
       " 'discrimination_threshold',\n",
       " 'prcurve',\n",
       " 'precision_recall_curve',\n",
       " 'roc_auc',\n",
       " 'rocauc',\n",
       " 'threshold']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(yellowbrick.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import ClassificationReport, DiscriminationThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mClassificationReport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'YlOrRd'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msupport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mencoder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mis_fitted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mforce_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcolorbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Classification report that shows the precision, recall, F1, and support scores\n",
      "for the model. Integrates numerical scores as well as a color-coded heatmap.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "estimator : estimator\n",
      "    A scikit-learn estimator that should be a classifier. If the model is\n",
      "    not a classifier, an exception is raised. If the internal model is not\n",
      "    fitted, it is fit when the visualizer is fitted, unless otherwise specified\n",
      "    by ``is_fitted``.\n",
      "\n",
      "ax : matplotlib Axes, default: None\n",
      "    The axes to plot the figure on. If not specified the current axes will be\n",
      "    used (or generated if required).\n",
      "\n",
      "classes : list of str, defult: None\n",
      "    The class labels to use for the legend ordered by the index of the sorted\n",
      "    classes discovered in the ``fit()`` method. Specifying classes in this\n",
      "    manner is used to change the class names to a more specific format or\n",
      "    to label encoded integer classes. Some visualizers may also use this\n",
      "    field to filter the visualization for specific classes. For more advanced\n",
      "    usage specify an encoder rather than class labels.\n",
      "\n",
      "cmap : string, default: ``'YlOrRd'``\n",
      "    Specify a colormap to define the heatmap of the predicted class\n",
      "    against the actual class in the classification report.\n",
      "\n",
      "support: {True, False, None, 'percent', 'count'}, default: None\n",
      "    Specify if support will be displayed. It can be further defined by\n",
      "    whether support should be reported as a raw count or percentage.\n",
      "\n",
      "encoder : dict or LabelEncoder, default: None\n",
      "    A mapping of classes to human readable labels. Often there is a mismatch\n",
      "    between desired class labels and those contained in the target variable\n",
      "    passed to ``fit()`` or ``score()``. The encoder disambiguates this mismatch\n",
      "    ensuring that classes are labeled correctly in the visualization.\n",
      "\n",
      "is_fitted : bool or str, default=\"auto\"\n",
      "    Specify if the wrapped estimator is already fitted. If False, the estimator\n",
      "    will be fit when the visualizer is fit, otherwise, the estimator will not be\n",
      "    modified. If \"auto\" (default), a helper method will check if the estimator\n",
      "    is fitted before fitting it again.\n",
      "\n",
      "force_model : bool, default: False\n",
      "    Do not check to ensure that the underlying estimator is a classifier. This\n",
      "    will prevent an exception when the visualizer is initialized but may result\n",
      "    in unexpected or unintended behavior.\n",
      "\n",
      "colorbar : bool, default: True\n",
      "    Specify if the color bar should be present\n",
      "\n",
      "fontsize : int or None, default: None\n",
      "    Specify the font size of the x and y labels\n",
      "\n",
      "kwargs : dict\n",
      "    Keyword arguments passed to the visualizer base classes.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from yellowbrick.classifier import ClassificationReport\n",
      ">>> from sklearn.linear_model import LogisticRegression\n",
      ">>> viz = ClassificationReport(LogisticRegression())\n",
      ">>> viz.fit(X_train, y_train)\n",
      ">>> viz.score(X_test, y_test)\n",
      ">>> viz.show()\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "classes_ : ndarray of shape (n_classes,)\n",
      "    The class labels observed while fitting.\n",
      "\n",
      "class_count_ : ndarray of shape (n_classes,)\n",
      "    Number of samples encountered for each class during fitting.\n",
      "\n",
      "score_ : float\n",
      "    An evaluation metric of the classifier on test data produced when\n",
      "    ``score()`` is called. This metric is between 0 and 1 -- higher scores are\n",
      "    generally better. For classifiers, this score is usually accuracy, but\n",
      "    ensure you check the underlying model for more details about the score.\n",
      "\n",
      "scores_ : dict of dicts\n",
      "    Outer dictionary composed of precision, recall, f1, and support scores with\n",
      "    inner dictionaries specifiying the values for each class listed.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/yellowbrick/classifier/classification_report.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?ClassificationReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ClassificationReport(ax=&lt;Axes: &gt;,\n",
       "                     cmap=&lt;matplotlib.colors.ListedColormap object at 0x7facdc581300&gt;,\n",
       "                     estimator=RandomForestClassifier(max_depth=2, n_jobs=4,\n",
       "                                                      random_state=0))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>ClassificationReport</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>ClassificationReport(ax=&lt;Axes: &gt;,\n",
       "                     cmap=&lt;matplotlib.colors.ListedColormap object at 0x7facdc581300&gt;,\n",
       "                     estimator=RandomForestClassifier(max_depth=2, n_jobs=4,\n",
       "                                                      random_state=0))</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>estimator: RandomForestClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=2, n_jobs=4, random_state=0)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=2, n_jobs=4, random_state=0)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ClassificationReport(ax=<Axes: >,\n",
       "                     cmap=<matplotlib.colors.ListedColormap object at 0x7facdc581300>,\n",
       "                     estimator=RandomForestClassifier(max_depth=2, n_jobs=4,\n",
       "                                                      random_state=0))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualizer = ClassificationReport(rf)\n",
    "visualizer.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9962036317065361"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualizer = ClassificationReport(rf)\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ClassBalance',\n",
       " 'ClassPredictionError',\n",
       " 'ClassificationReport',\n",
       " 'ClassificationScoreVisualizer',\n",
       " 'ConfusionMatrix',\n",
       " 'DiscriminationThreshold',\n",
       " 'PRCurve',\n",
       " 'PrecisionRecallCurve',\n",
       " 'ROCAUC',\n",
       " 'ScoreVisualizer',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'base',\n",
       " 'class_balance',\n",
       " 'class_prediction_error',\n",
       " 'classification_report',\n",
       " 'confusion_matrix',\n",
       " 'discrimination_threshold',\n",
       " 'prcurve',\n",
       " 'precision_recall_curve',\n",
       " 'roc_auc',\n",
       " 'rocauc',\n",
       " 'threshold']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(yellowbrick.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__sklearn_clone__',\n",
       " '__sklearn_tags__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_ax',\n",
       " '_build_request_for_signature',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_decode_labels',\n",
       " '_displayed_scores',\n",
       " '_doc_link_module',\n",
       " '_doc_link_template',\n",
       " '_doc_link_url_param_generator',\n",
       " '_fig',\n",
       " '_get_default_requests',\n",
       " '_get_doc_link',\n",
       " '_get_metadata_request',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_labels',\n",
       " '_more_tags',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_size',\n",
       " '_validate_data',\n",
       " '_validate_params',\n",
       " '_wrapped',\n",
       " 'ax',\n",
       " 'class_colors_',\n",
       " 'class_counts_',\n",
       " 'classes',\n",
       " 'classes_',\n",
       " 'cmap',\n",
       " 'color',\n",
       " 'colorbar',\n",
       " 'draw',\n",
       " 'encoder',\n",
       " 'estimator',\n",
       " 'fig',\n",
       " 'finalize',\n",
       " 'fit',\n",
       " 'fontsize',\n",
       " 'force_model',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'is_fitted',\n",
       " 'name',\n",
       " 'poof',\n",
       " 'score',\n",
       " 'score_',\n",
       " 'scores_',\n",
       " 'set_params',\n",
       " 'set_title',\n",
       " 'show',\n",
       " 'size',\n",
       " 'support',\n",
       " 'support_score_',\n",
       " 'title']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(visualizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mvisualizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m\n",
      "Generates the Scikit-Learn classification report.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "X : ndarray or DataFrame of shape n x m\n",
      "    A matrix of n instances with m features\n",
      "\n",
      "y : ndarray or Series of length n\n",
      "    An array or series of target or class values\n",
      "\n",
      "Returns\n",
      "-------\n",
      "\n",
      "score_ : float\n",
      "    Global accuracy score\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/yellowbrick/classifier/classification_report.py\n",
      "\u001b[0;31mType:\u001b[0m      method"
     ]
    }
   ],
   "source": [
    "?visualizer.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'RandomForestClassifier Classification Report'}>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualizer = ClassificationReport(rf)\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'LogisticRegression Classification Report'}>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualizer_LR = ClassificationReport(lr)\n",
    "visualizer_LR.fit(X_train, y_train)\n",
    "visualizer_LR.score(X_test, y_test)\n",
    "visualizer_LR.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ClassBalance',\n",
       " 'ClassPredictionError',\n",
       " 'ClassificationReport',\n",
       " 'ClassificationScoreVisualizer',\n",
       " 'ConfusionMatrix',\n",
       " 'DiscriminationThreshold',\n",
       " 'PRCurve',\n",
       " 'PrecisionRecallCurve',\n",
       " 'ROCAUC',\n",
       " 'ScoreVisualizer',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'base',\n",
       " 'class_balance',\n",
       " 'class_prediction_error',\n",
       " 'classification_report',\n",
       " 'confusion_matrix',\n",
       " 'discrimination_threshold',\n",
       " 'prcurve',\n",
       " 'precision_recall_curve',\n",
       " 'roc_auc',\n",
       " 'rocauc',\n",
       " 'threshold']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(yellowbrick.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import DiscriminationThreshold, ClassificationReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mDiscriminationThreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0margmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fscore'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mquantiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mis_fitted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mforce_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Visualizes how precision, recall, f1 score, and queue rate change as the\n",
      "discrimination threshold increases. For probabilistic, binary classifiers,\n",
      "the discrimination threshold is the probability at which you choose the\n",
      "positive class over the negative. Generally this is set to 50%, but\n",
      "adjusting the discrimination threshold will adjust sensitivity to false\n",
      "positives which is described by the inverse relationship of precision and\n",
      "recall with respect to the threshold.\n",
      "\n",
      "The visualizer also accounts for variability in the model by running\n",
      "multiple trials with different train and test splits of the data. The\n",
      "variability is visualized using a band such that the curve is drawn as the\n",
      "median score of each trial and the band is from the 10th to 90th\n",
      "percentile.\n",
      "\n",
      "The visualizer is intended to help users determine an appropriate\n",
      "threshold for decision making (e.g. at what threshold do we have a human\n",
      "review the data), given a tolerance for precision and recall or limiting\n",
      "the number of records to check (the queue rate).\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "estimator : estimator\n",
      "    A scikit-learn estimator that should be a classifier. If the model is\n",
      "    not a classifier, an exception is raised. If the internal model is not\n",
      "    fitted, it is fit when the visualizer is fitted, unless otherwise specified\n",
      "    by ``is_fitted``.\n",
      "\n",
      "ax : matplotlib Axes, default: None\n",
      "    The axes to plot the figure on. If not specified the current axes will be\n",
      "    used (or generated if required).\n",
      "\n",
      "n_trials : integer, default: 50\n",
      "    Number of times to shuffle and split the dataset to account for noise\n",
      "    in the threshold metrics curves. Note if cv provides > 1 splits,\n",
      "    the number of trials will be n_trials * cv.get_n_splits()\n",
      "\n",
      "cv : float or cross-validation generator, default: 0.1\n",
      "    Determines the splitting strategy for each trial. Possible inputs are:\n",
      "\n",
      "    - float, to specify the percent of the test split\n",
      "    - object to be used as cross-validation generator\n",
      "\n",
      "    This attribute is meant to give flexibility with stratified splitting\n",
      "    but if a splitter is provided, it should only return one split and\n",
      "    have shuffle set to True.\n",
      "\n",
      "fbeta : float, 1.0 by default\n",
      "    The strength of recall versus precision in the F-score.\n",
      "\n",
      "argmax : str or None, default: 'fscore'\n",
      "    Annotate the threshold maximized by the supplied metric (see exclude\n",
      "    for the possible metrics to use). If None or passed to exclude,\n",
      "    will not annotate the graph.\n",
      "\n",
      "exclude : str or list, optional\n",
      "    Specify metrics to omit from the graph, can include:\n",
      "\n",
      "    - ``\"precision\"``\n",
      "    - ``\"recall\"``\n",
      "    - ``\"queue_rate\"``\n",
      "    - ``\"fscore\"``\n",
      "\n",
      "    Excluded metrics will not be displayed in the graph, nor will they\n",
      "    be available in ``thresholds_``; however, they will be computed on fit.\n",
      "\n",
      "quantiles : sequence, default: np.array([0.1, 0.5, 0.9])\n",
      "    Specify the quantiles to view model variability across a number of\n",
      "    trials. Must be monotonic and have three elements such that the first\n",
      "    element is the lower bound, the second is the drawn curve, and the\n",
      "    third is the upper bound. By default the curve is drawn at the median,\n",
      "    and the bounds from the 10th percentile to the 90th percentile.\n",
      "\n",
      "random_state : int, optional\n",
      "    Used to seed the random state for shuffling the data while composing\n",
      "    different train and test splits. If supplied, the random state is\n",
      "    incremented in a deterministic fashion for each split.\n",
      "\n",
      "    Note that if a splitter is provided, it's random state will also be\n",
      "    updated with this random state, even if it was previously set.\n",
      "\n",
      "is_fitted : bool or str, default=\"auto\"\n",
      "    Specify if the wrapped estimator is already fitted. If False, the estimator\n",
      "    will be fit when the visualizer is fit, otherwise, the estimator will not be\n",
      "    modified. If \"auto\" (default), a helper method will check if the estimator\n",
      "    is fitted before fitting it again.\n",
      "\n",
      "force_model : bool, default: False\n",
      "    Do not check to ensure that the underlying estimator is a classifier. This\n",
      "    will prevent an exception when the visualizer is initialized but may result\n",
      "    in unexpected or unintended behavior.\n",
      "\n",
      "kwargs : dict\n",
      "    Keyword arguments passed to the visualizer base classes.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "thresholds_ : array\n",
      "    The uniform thresholds identified by each of the trial runs.\n",
      "\n",
      "cv_scores_ : dict of arrays of ``len(thresholds_)``\n",
      "    The values for all included metrics including the upper and lower\n",
      "    bounds of the metrics defined by quantiles.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The term \"discrimination threshold\" is rare in the literature. Here, we\n",
      "use it to mean the probability at which the positive class is selected\n",
      "over the negative class in binary classification.\n",
      "\n",
      "Classification models must implement either a ``decision_function`` or\n",
      "``predict_proba`` method in order to be used with this class. A\n",
      "``YellowbrickTypeError`` is raised otherwise.\n",
      "\n",
      ".. caution:: This method only works for binary, probabilistic classifiers.\n",
      "\n",
      ".. seealso::\n",
      "    For a thorough explanation of discrimination thresholds, see:\n",
      "    `Visualizing Machine Learning Thresholds to Make Better Business\n",
      "    Decisions\n",
      "    <http://blog.insightdatalabs.com/visualizing-classifier-thresholds/>`_\n",
      "    by Insight Data.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/yellowbrick/classifier/threshold.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?DiscriminationThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DiscriminationThreshold in module yellowbrick.classifier.threshold:\n",
      "\n",
      "class DiscriminationThreshold(yellowbrick.base.ModelVisualizer)\n",
      " |  DiscriminationThreshold(estimator, ax=None, n_trials=50, cv=0.1, fbeta=1.0, argmax='fscore', exclude=None, quantiles=array([0.1, 0.5, 0.9]), random_state=None, is_fitted='auto', force_model=False, **kwargs)\n",
      " |  \n",
      " |  Visualizes how precision, recall, f1 score, and queue rate change as the\n",
      " |  discrimination threshold increases. For probabilistic, binary classifiers,\n",
      " |  the discrimination threshold is the probability at which you choose the\n",
      " |  positive class over the negative. Generally this is set to 50%, but\n",
      " |  adjusting the discrimination threshold will adjust sensitivity to false\n",
      " |  positives which is described by the inverse relationship of precision and\n",
      " |  recall with respect to the threshold.\n",
      " |  \n",
      " |  The visualizer also accounts for variability in the model by running\n",
      " |  multiple trials with different train and test splits of the data. The\n",
      " |  variability is visualized using a band such that the curve is drawn as the\n",
      " |  median score of each trial and the band is from the 10th to 90th\n",
      " |  percentile.\n",
      " |  \n",
      " |  The visualizer is intended to help users determine an appropriate\n",
      " |  threshold for decision making (e.g. at what threshold do we have a human\n",
      " |  review the data), given a tolerance for precision and recall or limiting\n",
      " |  the number of records to check (the queue rate).\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator\n",
      " |      A scikit-learn estimator that should be a classifier. If the model is\n",
      " |      not a classifier, an exception is raised. If the internal model is not\n",
      " |      fitted, it is fit when the visualizer is fitted, unless otherwise specified\n",
      " |      by ``is_fitted``.\n",
      " |  \n",
      " |  ax : matplotlib Axes, default: None\n",
      " |      The axes to plot the figure on. If not specified the current axes will be\n",
      " |      used (or generated if required).\n",
      " |  \n",
      " |  n_trials : integer, default: 50\n",
      " |      Number of times to shuffle and split the dataset to account for noise\n",
      " |      in the threshold metrics curves. Note if cv provides > 1 splits,\n",
      " |      the number of trials will be n_trials * cv.get_n_splits()\n",
      " |  \n",
      " |  cv : float or cross-validation generator, default: 0.1\n",
      " |      Determines the splitting strategy for each trial. Possible inputs are:\n",
      " |  \n",
      " |      - float, to specify the percent of the test split\n",
      " |      - object to be used as cross-validation generator\n",
      " |  \n",
      " |      This attribute is meant to give flexibility with stratified splitting\n",
      " |      but if a splitter is provided, it should only return one split and\n",
      " |      have shuffle set to True.\n",
      " |  \n",
      " |  fbeta : float, 1.0 by default\n",
      " |      The strength of recall versus precision in the F-score.\n",
      " |  \n",
      " |  argmax : str or None, default: 'fscore'\n",
      " |      Annotate the threshold maximized by the supplied metric (see exclude\n",
      " |      for the possible metrics to use). If None or passed to exclude,\n",
      " |      will not annotate the graph.\n",
      " |  \n",
      " |  exclude : str or list, optional\n",
      " |      Specify metrics to omit from the graph, can include:\n",
      " |  \n",
      " |      - ``\"precision\"``\n",
      " |      - ``\"recall\"``\n",
      " |      - ``\"queue_rate\"``\n",
      " |      - ``\"fscore\"``\n",
      " |  \n",
      " |      Excluded metrics will not be displayed in the graph, nor will they\n",
      " |      be available in ``thresholds_``; however, they will be computed on fit.\n",
      " |  \n",
      " |  quantiles : sequence, default: np.array([0.1, 0.5, 0.9])\n",
      " |      Specify the quantiles to view model variability across a number of\n",
      " |      trials. Must be monotonic and have three elements such that the first\n",
      " |      element is the lower bound, the second is the drawn curve, and the\n",
      " |      third is the upper bound. By default the curve is drawn at the median,\n",
      " |      and the bounds from the 10th percentile to the 90th percentile.\n",
      " |  \n",
      " |  random_state : int, optional\n",
      " |      Used to seed the random state for shuffling the data while composing\n",
      " |      different train and test splits. If supplied, the random state is\n",
      " |      incremented in a deterministic fashion for each split.\n",
      " |  \n",
      " |      Note that if a splitter is provided, it's random state will also be\n",
      " |      updated with this random state, even if it was previously set.\n",
      " |  \n",
      " |  is_fitted : bool or str, default=\"auto\"\n",
      " |      Specify if the wrapped estimator is already fitted. If False, the estimator\n",
      " |      will be fit when the visualizer is fit, otherwise, the estimator will not be\n",
      " |      modified. If \"auto\" (default), a helper method will check if the estimator\n",
      " |      is fitted before fitting it again.\n",
      " |  \n",
      " |  force_model : bool, default: False\n",
      " |      Do not check to ensure that the underlying estimator is a classifier. This\n",
      " |      will prevent an exception when the visualizer is initialized but may result\n",
      " |      in unexpected or unintended behavior.\n",
      " |  \n",
      " |  kwargs : dict\n",
      " |      Keyword arguments passed to the visualizer base classes.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  thresholds_ : array\n",
      " |      The uniform thresholds identified by each of the trial runs.\n",
      " |  \n",
      " |  cv_scores_ : dict of arrays of ``len(thresholds_)``\n",
      " |      The values for all included metrics including the upper and lower\n",
      " |      bounds of the metrics defined by quantiles.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The term \"discrimination threshold\" is rare in the literature. Here, we\n",
      " |  use it to mean the probability at which the positive class is selected\n",
      " |  over the negative class in binary classification.\n",
      " |  \n",
      " |  Classification models must implement either a ``decision_function`` or\n",
      " |  ``predict_proba`` method in order to be used with this class. A\n",
      " |  ``YellowbrickTypeError`` is raised otherwise.\n",
      " |  \n",
      " |  .. caution:: This method only works for binary, probabilistic classifiers.\n",
      " |  \n",
      " |  .. seealso::\n",
      " |      For a thorough explanation of discrimination thresholds, see:\n",
      " |      `Visualizing Machine Learning Thresholds to Make Better Business\n",
      " |      Decisions\n",
      " |      <http://blog.insightdatalabs.com/visualizing-classifier-thresholds/>`_\n",
      " |      by Insight Data.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DiscriminationThreshold\n",
      " |      yellowbrick.base.ModelVisualizer\n",
      " |      yellowbrick.base.Visualizer\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      yellowbrick.utils.wrapper.Wrapper\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, ax=None, n_trials=50, cv=0.1, fbeta=1.0, argmax='fscore', exclude=None, quantiles=array([0.1, 0.5, 0.9]), random_state=None, is_fitted='auto', force_model=False, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  draw(self)\n",
      " |      Draws the cv scores as a line chart on the current axes.\n",
      " |  \n",
      " |  finalize(self, **kwargs)\n",
      " |      Sets a title and axis labels on the visualizer and ensures that the\n",
      " |      axis limits are scaled to valid threshold values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      kwargs: generic keyword arguments.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Generally this method is called from show and not directly by the user.\n",
      " |  \n",
      " |  fit(self, X, y, **kwargs)\n",
      " |      Fit is the entry point for the visualizer. Given instances described\n",
      " |      by X and binary classes described in the target y, fit performs n\n",
      " |      trials by shuffling and splitting the dataset then computing the\n",
      " |      precision, recall, f1, and queue rate scores for each trial. The\n",
      " |      scores are aggregated by the quantiles expressed then drawn.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : ndarray or DataFrame of shape n x m\n",
      " |          A matrix of n instances with m features\n",
      " |      \n",
      " |      y : ndarray or Series of length n\n",
      " |          An array or series of target or class values. The target y must\n",
      " |          be a binary classification target.\n",
      " |      \n",
      " |      kwargs: dict\n",
      " |          keyword arguments passed to Scikit-Learn API.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : instance\n",
      " |          Returns the instance of the visualizer\n",
      " |      \n",
      " |      raises: YellowbrickValueError\n",
      " |          If the target y is not a binary classification target.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from yellowbrick.base.ModelVisualizer:\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      After v0.24 - scikit-learn is able to determine that ``self.estimator`` is\n",
      " |      nested and fetches its params using ``estimator__param``. This functionality is\n",
      " |      pretty cool but it's a pretty big overhaul to change our \"wrapped\" estimator API\n",
      " |      to a \"nested\" estimator API, therefore we override ``get_params`` to flatten out\n",
      " |      the estimator params.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      The latest version of scikit-learn is able to determine that ``self.estimator``\n",
      " |      is nested and sets its params using ``estimator__param``. In order to maintain\n",
      " |      the Yellowbrick \"wrapped\" API, this method finds any params belonging to the\n",
      " |      underlying estimator and sets them directly.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from yellowbrick.base.Visualizer:\n",
      " |  \n",
      " |  poof(self, *args, **kwargs)\n",
      " |      This method is deprecated, please use ``show()`` instead.\n",
      " |  \n",
      " |  set_title(self, title=None)\n",
      " |      Sets the title on the current axes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      title: string, default: None\n",
      " |          Add title to figure or if None leave untitled.\n",
      " |  \n",
      " |  show(self, outpath=None, clear_figure=False, **kwargs)\n",
      " |      Makes the magic happen and a visualizer appear! You can pass in a path to\n",
      " |      save the figure to disk with various backends, or you can call it with no\n",
      " |      arguments to show the figure either in a notebook or in a GUI window that\n",
      " |      pops up on screen.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      outpath: string, default: None\n",
      " |          path or None. Save figure to disk or if None show in window\n",
      " |      \n",
      " |      clear_figure: boolean, default: False\n",
      " |          When True, this flag clears the figure after saving to file or\n",
      " |          showing on screen. This is useful when making consecutive plots.\n",
      " |      \n",
      " |      kwargs: dict\n",
      " |          generic keyword arguments.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Developers of visualizers don't usually override show, as it is\n",
      " |      primarily called by the user to render the visualization.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from yellowbrick.base.Visualizer:\n",
      " |  \n",
      " |  ax\n",
      " |      The matplotlib axes that the visualizer draws upon (can also be a grid\n",
      " |      of multiple axes objects). The visualizer uses :func:`matplotlib.pyplot.gca`\n",
      " |      to create an axes for the user if one has not been specified.\n",
      " |  \n",
      " |  fig\n",
      " |      The matplotlib fig that the visualizer draws upon. The visualizer uses\n",
      " |      the matplotlib method :func:`matplotlib.pyplot.gcf` to create a figure for\n",
      " |      the user if one has not been specified.\n",
      " |  \n",
      " |  size\n",
      " |      Returns the actual size in pixels as set by matplotlib, or\n",
      " |      the user provided size if available.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  __sklearn_tags__(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs) from builtins.type\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from yellowbrick.utils.wrapper.Wrapper:\n",
      " |  \n",
      " |  __getattr__(self, attr)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DiscriminationThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Threshold Plot for LogisticRegression'}, xlabel='discrimination threshold', ylabel='score'>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualizer = DiscriminationThreshold(lr, n_trials=1, cv=0.5, argmax='fscore', random_state=0, is_fitted='auto', exclude='queue_rate')\n",
    "\n",
    "visualizer.fit(X_train, y_train)\n",
    "visualizer.score(X_test, y_test)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ClassBalance',\n",
       " 'ClassPredictionError',\n",
       " 'ClassificationReport',\n",
       " 'ClassificationScoreVisualizer',\n",
       " 'ConfusionMatrix',\n",
       " 'DiscriminationThreshold',\n",
       " 'PRCurve',\n",
       " 'PrecisionRecallCurve',\n",
       " 'ROCAUC',\n",
       " 'ScoreVisualizer',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'base',\n",
       " 'class_balance',\n",
       " 'class_prediction_error',\n",
       " 'classification_report',\n",
       " 'confusion_matrix',\n",
       " 'discrimination_threshold',\n",
       " 'prcurve',\n",
       " 'precision_recall_curve',\n",
       " 'roc_auc',\n",
       " 'rocauc',\n",
       " 'threshold']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(yellowbrick.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import DiscriminationThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mDiscriminationThreshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mfbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0margmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fscore'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mquantiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mis_fitted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mforce_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Visualizes how precision, recall, f1 score, and queue rate change as the\n",
      "discrimination threshold increases. For probabilistic, binary classifiers,\n",
      "the discrimination threshold is the probability at which you choose the\n",
      "positive class over the negative. Generally this is set to 50%, but\n",
      "adjusting the discrimination threshold will adjust sensitivity to false\n",
      "positives which is described by the inverse relationship of precision and\n",
      "recall with respect to the threshold.\n",
      "\n",
      "The visualizer also accounts for variability in the model by running\n",
      "multiple trials with different train and test splits of the data. The\n",
      "variability is visualized using a band such that the curve is drawn as the\n",
      "median score of each trial and the band is from the 10th to 90th\n",
      "percentile.\n",
      "\n",
      "The visualizer is intended to help users determine an appropriate\n",
      "threshold for decision making (e.g. at what threshold do we have a human\n",
      "review the data), given a tolerance for precision and recall or limiting\n",
      "the number of records to check (the queue rate).\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "estimator : estimator\n",
      "    A scikit-learn estimator that should be a classifier. If the model is\n",
      "    not a classifier, an exception is raised. If the internal model is not\n",
      "    fitted, it is fit when the visualizer is fitted, unless otherwise specified\n",
      "    by ``is_fitted``.\n",
      "\n",
      "ax : matplotlib Axes, default: None\n",
      "    The axes to plot the figure on. If not specified the current axes will be\n",
      "    used (or generated if required).\n",
      "\n",
      "n_trials : integer, default: 50\n",
      "    Number of times to shuffle and split the dataset to account for noise\n",
      "    in the threshold metrics curves. Note if cv provides > 1 splits,\n",
      "    the number of trials will be n_trials * cv.get_n_splits()\n",
      "\n",
      "cv : float or cross-validation generator, default: 0.1\n",
      "    Determines the splitting strategy for each trial. Possible inputs are:\n",
      "\n",
      "    - float, to specify the percent of the test split\n",
      "    - object to be used as cross-validation generator\n",
      "\n",
      "    This attribute is meant to give flexibility with stratified splitting\n",
      "    but if a splitter is provided, it should only return one split and\n",
      "    have shuffle set to True.\n",
      "\n",
      "fbeta : float, 1.0 by default\n",
      "    The strength of recall versus precision in the F-score.\n",
      "\n",
      "argmax : str or None, default: 'fscore'\n",
      "    Annotate the threshold maximized by the supplied metric (see exclude\n",
      "    for the possible metrics to use). If None or passed to exclude,\n",
      "    will not annotate the graph.\n",
      "\n",
      "exclude : str or list, optional\n",
      "    Specify metrics to omit from the graph, can include:\n",
      "\n",
      "    - ``\"precision\"``\n",
      "    - ``\"recall\"``\n",
      "    - ``\"queue_rate\"``\n",
      "    - ``\"fscore\"``\n",
      "\n",
      "    Excluded metrics will not be displayed in the graph, nor will they\n",
      "    be available in ``thresholds_``; however, they will be computed on fit.\n",
      "\n",
      "quantiles : sequence, default: np.array([0.1, 0.5, 0.9])\n",
      "    Specify the quantiles to view model variability across a number of\n",
      "    trials. Must be monotonic and have three elements such that the first\n",
      "    element is the lower bound, the second is the drawn curve, and the\n",
      "    third is the upper bound. By default the curve is drawn at the median,\n",
      "    and the bounds from the 10th percentile to the 90th percentile.\n",
      "\n",
      "random_state : int, optional\n",
      "    Used to seed the random state for shuffling the data while composing\n",
      "    different train and test splits. If supplied, the random state is\n",
      "    incremented in a deterministic fashion for each split.\n",
      "\n",
      "    Note that if a splitter is provided, it's random state will also be\n",
      "    updated with this random state, even if it was previously set.\n",
      "\n",
      "is_fitted : bool or str, default=\"auto\"\n",
      "    Specify if the wrapped estimator is already fitted. If False, the estimator\n",
      "    will be fit when the visualizer is fit, otherwise, the estimator will not be\n",
      "    modified. If \"auto\" (default), a helper method will check if the estimator\n",
      "    is fitted before fitting it again.\n",
      "\n",
      "force_model : bool, default: False\n",
      "    Do not check to ensure that the underlying estimator is a classifier. This\n",
      "    will prevent an exception when the visualizer is initialized but may result\n",
      "    in unexpected or unintended behavior.\n",
      "\n",
      "kwargs : dict\n",
      "    Keyword arguments passed to the visualizer base classes.\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "thresholds_ : array\n",
      "    The uniform thresholds identified by each of the trial runs.\n",
      "\n",
      "cv_scores_ : dict of arrays of ``len(thresholds_)``\n",
      "    The values for all included metrics including the upper and lower\n",
      "    bounds of the metrics defined by quantiles.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The term \"discrimination threshold\" is rare in the literature. Here, we\n",
      "use it to mean the probability at which the positive class is selected\n",
      "over the negative class in binary classification.\n",
      "\n",
      "Classification models must implement either a ``decision_function`` or\n",
      "``predict_proba`` method in order to be used with this class. A\n",
      "``YellowbrickTypeError`` is raised otherwise.\n",
      "\n",
      ".. caution:: This method only works for binary, probabilistic classifiers.\n",
      "\n",
      ".. seealso::\n",
      "    For a thorough explanation of discrimination thresholds, see:\n",
      "    `Visualizing Machine Learning Thresholds to Make Better Business\n",
      "    Decisions\n",
      "    <http://blog.insightdatalabs.com/visualizing-classifier-thresholds/>`_\n",
      "    by Insight Data.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/yellowbrick/classifier/threshold.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "?DiscriminationThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class DiscriminationThreshold in module yellowbrick.classifier.threshold:\n",
      "\n",
      "class DiscriminationThreshold(yellowbrick.base.ModelVisualizer)\n",
      " |  DiscriminationThreshold(estimator, ax=None, n_trials=50, cv=0.1, fbeta=1.0, argmax='fscore', exclude=None, quantiles=array([0.1, 0.5, 0.9]), random_state=None, is_fitted='auto', force_model=False, **kwargs)\n",
      " |  \n",
      " |  Visualizes how precision, recall, f1 score, and queue rate change as the\n",
      " |  discrimination threshold increases. For probabilistic, binary classifiers,\n",
      " |  the discrimination threshold is the probability at which you choose the\n",
      " |  positive class over the negative. Generally this is set to 50%, but\n",
      " |  adjusting the discrimination threshold will adjust sensitivity to false\n",
      " |  positives which is described by the inverse relationship of precision and\n",
      " |  recall with respect to the threshold.\n",
      " |  \n",
      " |  The visualizer also accounts for variability in the model by running\n",
      " |  multiple trials with different train and test splits of the data. The\n",
      " |  variability is visualized using a band such that the curve is drawn as the\n",
      " |  median score of each trial and the band is from the 10th to 90th\n",
      " |  percentile.\n",
      " |  \n",
      " |  The visualizer is intended to help users determine an appropriate\n",
      " |  threshold for decision making (e.g. at what threshold do we have a human\n",
      " |  review the data), given a tolerance for precision and recall or limiting\n",
      " |  the number of records to check (the queue rate).\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  estimator : estimator\n",
      " |      A scikit-learn estimator that should be a classifier. If the model is\n",
      " |      not a classifier, an exception is raised. If the internal model is not\n",
      " |      fitted, it is fit when the visualizer is fitted, unless otherwise specified\n",
      " |      by ``is_fitted``.\n",
      " |  \n",
      " |  ax : matplotlib Axes, default: None\n",
      " |      The axes to plot the figure on. If not specified the current axes will be\n",
      " |      used (or generated if required).\n",
      " |  \n",
      " |  n_trials : integer, default: 50\n",
      " |      Number of times to shuffle and split the dataset to account for noise\n",
      " |      in the threshold metrics curves. Note if cv provides > 1 splits,\n",
      " |      the number of trials will be n_trials * cv.get_n_splits()\n",
      " |  \n",
      " |  cv : float or cross-validation generator, default: 0.1\n",
      " |      Determines the splitting strategy for each trial. Possible inputs are:\n",
      " |  \n",
      " |      - float, to specify the percent of the test split\n",
      " |      - object to be used as cross-validation generator\n",
      " |  \n",
      " |      This attribute is meant to give flexibility with stratified splitting\n",
      " |      but if a splitter is provided, it should only return one split and\n",
      " |      have shuffle set to True.\n",
      " |  \n",
      " |  fbeta : float, 1.0 by default\n",
      " |      The strength of recall versus precision in the F-score.\n",
      " |  \n",
      " |  argmax : str or None, default: 'fscore'\n",
      " |      Annotate the threshold maximized by the supplied metric (see exclude\n",
      " |      for the possible metrics to use). If None or passed to exclude,\n",
      " |      will not annotate the graph.\n",
      " |  \n",
      " |  exclude : str or list, optional\n",
      " |      Specify metrics to omit from the graph, can include:\n",
      " |  \n",
      " |      - ``\"precision\"``\n",
      " |      - ``\"recall\"``\n",
      " |      - ``\"queue_rate\"``\n",
      " |      - ``\"fscore\"``\n",
      " |  \n",
      " |      Excluded metrics will not be displayed in the graph, nor will they\n",
      " |      be available in ``thresholds_``; however, they will be computed on fit.\n",
      " |  \n",
      " |  quantiles : sequence, default: np.array([0.1, 0.5, 0.9])\n",
      " |      Specify the quantiles to view model variability across a number of\n",
      " |      trials. Must be monotonic and have three elements such that the first\n",
      " |      element is the lower bound, the second is the drawn curve, and the\n",
      " |      third is the upper bound. By default the curve is drawn at the median,\n",
      " |      and the bounds from the 10th percentile to the 90th percentile.\n",
      " |  \n",
      " |  random_state : int, optional\n",
      " |      Used to seed the random state for shuffling the data while composing\n",
      " |      different train and test splits. If supplied, the random state is\n",
      " |      incremented in a deterministic fashion for each split.\n",
      " |  \n",
      " |      Note that if a splitter is provided, it's random state will also be\n",
      " |      updated with this random state, even if it was previously set.\n",
      " |  \n",
      " |  is_fitted : bool or str, default=\"auto\"\n",
      " |      Specify if the wrapped estimator is already fitted. If False, the estimator\n",
      " |      will be fit when the visualizer is fit, otherwise, the estimator will not be\n",
      " |      modified. If \"auto\" (default), a helper method will check if the estimator\n",
      " |      is fitted before fitting it again.\n",
      " |  \n",
      " |  force_model : bool, default: False\n",
      " |      Do not check to ensure that the underlying estimator is a classifier. This\n",
      " |      will prevent an exception when the visualizer is initialized but may result\n",
      " |      in unexpected or unintended behavior.\n",
      " |  \n",
      " |  kwargs : dict\n",
      " |      Keyword arguments passed to the visualizer base classes.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  thresholds_ : array\n",
      " |      The uniform thresholds identified by each of the trial runs.\n",
      " |  \n",
      " |  cv_scores_ : dict of arrays of ``len(thresholds_)``\n",
      " |      The values for all included metrics including the upper and lower\n",
      " |      bounds of the metrics defined by quantiles.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The term \"discrimination threshold\" is rare in the literature. Here, we\n",
      " |  use it to mean the probability at which the positive class is selected\n",
      " |  over the negative class in binary classification.\n",
      " |  \n",
      " |  Classification models must implement either a ``decision_function`` or\n",
      " |  ``predict_proba`` method in order to be used with this class. A\n",
      " |  ``YellowbrickTypeError`` is raised otherwise.\n",
      " |  \n",
      " |  .. caution:: This method only works for binary, probabilistic classifiers.\n",
      " |  \n",
      " |  .. seealso::\n",
      " |      For a thorough explanation of discrimination thresholds, see:\n",
      " |      `Visualizing Machine Learning Thresholds to Make Better Business\n",
      " |      Decisions\n",
      " |      <http://blog.insightdatalabs.com/visualizing-classifier-thresholds/>`_\n",
      " |      by Insight Data.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DiscriminationThreshold\n",
      " |      yellowbrick.base.ModelVisualizer\n",
      " |      yellowbrick.base.Visualizer\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin\n",
      " |      sklearn.utils._metadata_requests._MetadataRequester\n",
      " |      yellowbrick.utils.wrapper.Wrapper\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, estimator, ax=None, n_trials=50, cv=0.1, fbeta=1.0, argmax='fscore', exclude=None, quantiles=array([0.1, 0.5, 0.9]), random_state=None, is_fitted='auto', force_model=False, **kwargs)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  draw(self)\n",
      " |      Draws the cv scores as a line chart on the current axes.\n",
      " |  \n",
      " |  finalize(self, **kwargs)\n",
      " |      Sets a title and axis labels on the visualizer and ensures that the\n",
      " |      axis limits are scaled to valid threshold values.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      kwargs: generic keyword arguments.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Generally this method is called from show and not directly by the user.\n",
      " |  \n",
      " |  fit(self, X, y, **kwargs)\n",
      " |      Fit is the entry point for the visualizer. Given instances described\n",
      " |      by X and binary classes described in the target y, fit performs n\n",
      " |      trials by shuffling and splitting the dataset then computing the\n",
      " |      precision, recall, f1, and queue rate scores for each trial. The\n",
      " |      scores are aggregated by the quantiles expressed then drawn.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : ndarray or DataFrame of shape n x m\n",
      " |          A matrix of n instances with m features\n",
      " |      \n",
      " |      y : ndarray or Series of length n\n",
      " |          An array or series of target or class values. The target y must\n",
      " |          be a binary classification target.\n",
      " |      \n",
      " |      kwargs: dict\n",
      " |          keyword arguments passed to Scikit-Learn API.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : instance\n",
      " |          Returns the instance of the visualizer\n",
      " |      \n",
      " |      raises: YellowbrickValueError\n",
      " |          If the target y is not a binary classification target.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from yellowbrick.base.ModelVisualizer:\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      After v0.24 - scikit-learn is able to determine that ``self.estimator`` is\n",
      " |      nested and fetches its params using ``estimator__param``. This functionality is\n",
      " |      pretty cool but it's a pretty big overhaul to change our \"wrapped\" estimator API\n",
      " |      to a \"nested\" estimator API, therefore we override ``get_params`` to flatten out\n",
      " |      the estimator params.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      The latest version of scikit-learn is able to determine that ``self.estimator``\n",
      " |      is nested and sets its params using ``estimator__param``. In order to maintain\n",
      " |      the Yellowbrick \"wrapped\" API, this method finds any params belonging to the\n",
      " |      underlying estimator and sets them directly.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from yellowbrick.base.Visualizer:\n",
      " |  \n",
      " |  poof(self, *args, **kwargs)\n",
      " |      This method is deprecated, please use ``show()`` instead.\n",
      " |  \n",
      " |  set_title(self, title=None)\n",
      " |      Sets the title on the current axes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      title: string, default: None\n",
      " |          Add title to figure or if None leave untitled.\n",
      " |  \n",
      " |  show(self, outpath=None, clear_figure=False, **kwargs)\n",
      " |      Makes the magic happen and a visualizer appear! You can pass in a path to\n",
      " |      save the figure to disk with various backends, or you can call it with no\n",
      " |      arguments to show the figure either in a notebook or in a GUI window that\n",
      " |      pops up on screen.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      outpath: string, default: None\n",
      " |          path or None. Save figure to disk or if None show in window\n",
      " |      \n",
      " |      clear_figure: boolean, default: False\n",
      " |          When True, this flag clears the figure after saving to file or\n",
      " |          showing on screen. This is useful when making consecutive plots.\n",
      " |      \n",
      " |      kwargs: dict\n",
      " |          generic keyword arguments.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      Developers of visualizers don't usually override show, as it is\n",
      " |      primarily called by the user to render the visualization.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from yellowbrick.base.Visualizer:\n",
      " |  \n",
      " |  ax\n",
      " |      The matplotlib axes that the visualizer draws upon (can also be a grid\n",
      " |      of multiple axes objects). The visualizer uses :func:`matplotlib.pyplot.gca`\n",
      " |      to create an axes for the user if one has not been specified.\n",
      " |  \n",
      " |  fig\n",
      " |      The matplotlib fig that the visualizer draws upon. The visualizer uses\n",
      " |      the matplotlib method :func:`matplotlib.pyplot.gcf` to create a figure for\n",
      " |      the user if one has not been specified.\n",
      " |  \n",
      " |  size\n",
      " |      Returns the actual size in pixels as set by matplotlib, or\n",
      " |      the user provided size if available.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  __sklearn_clone__(self)\n",
      " |  \n",
      " |  __sklearn_tags__(self)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.utils._estimator_html_repr._HTMLDocumentationLinkMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  get_metadata_routing(self)\n",
      " |      Get metadata routing of this object.\n",
      " |      \n",
      " |      Please check :ref:`User Guide <metadata_routing>` on how the routing\n",
      " |      mechanism works.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      routing : MetadataRequest\n",
      " |          A :class:`~sklearn.utils.metadata_routing.MetadataRequest` encapsulating\n",
      " |          routing information.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from sklearn.utils._metadata_requests._MetadataRequester:\n",
      " |  \n",
      " |  __init_subclass__(**kwargs) from builtins.type\n",
      " |      Set the ``set_{method}_request`` methods.\n",
      " |      \n",
      " |      This uses PEP-487 [1]_ to set the ``set_{method}_request`` methods. It\n",
      " |      looks for the information available in the set default values which are\n",
      " |      set using ``__metadata_request__*`` class attributes, or inferred\n",
      " |      from method signatures.\n",
      " |      \n",
      " |      The ``__metadata_request__*`` class attributes are used when a method\n",
      " |      does not explicitly accept a metadata through its arguments or if the\n",
      " |      developer would like to specify a request value for those metadata\n",
      " |      which are different from the default ``None``.\n",
      " |      \n",
      " |      References\n",
      " |      ----------\n",
      " |      .. [1] https://www.python.org/dev/peps/pep-0487\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from yellowbrick.utils.wrapper.Wrapper:\n",
      " |  \n",
      " |  __getattr__(self, attr)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(DiscriminationThreshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__sklearn_clone__',\n",
       " '__sklearn_tags__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_ax',\n",
       " '_build_request_for_signature',\n",
       " '_check_argmax',\n",
       " '_check_cv',\n",
       " '_check_exclude',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_check_quantiles',\n",
       " '_doc_link_module',\n",
       " '_doc_link_template',\n",
       " '_doc_link_url_param_generator',\n",
       " '_fig',\n",
       " '_get_default_requests',\n",
       " '_get_doc_link',\n",
       " '_get_metadata_request',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_size',\n",
       " '_split_fit_score_trial',\n",
       " '_validate_data',\n",
       " '_validate_params',\n",
       " '_wrapped',\n",
       " 'argmax',\n",
       " 'ax',\n",
       " 'color',\n",
       " 'cv',\n",
       " 'cv_scores_',\n",
       " 'draw',\n",
       " 'estimator',\n",
       " 'exclude',\n",
       " 'fbeta',\n",
       " 'fig',\n",
       " 'finalize',\n",
       " 'fit',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'is_fitted',\n",
       " 'n_trials',\n",
       " 'name',\n",
       " 'poof',\n",
       " 'quantiles',\n",
       " 'random_state',\n",
       " 'set_params',\n",
       " 'set_title',\n",
       " 'show',\n",
       " 'size',\n",
       " 'thresholds_',\n",
       " 'title']"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(visualizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "ename": "YellowbrickAttributeError",
     "evalue": "neither visualizer 'DiscriminationThreshold' nor wrapped estimator 'RandomForestClassifier' have attribute 'force_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/yellowbrick/utils/wrapper.py:48\u001b[0m, in \u001b[0;36mWrapper.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'force_model'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mYellowbrickAttributeError\u001b[0m                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/IPython/core/formatters.py:1036\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m   1033\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m   1035\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1036\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/base.py:467\u001b[0m, in \u001b[0;36mBaseEstimator._repr_mimebundle_\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_repr_mimebundle_\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    466\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mime bundle used by jupyter kernels to display estimator\"\"\"\u001b[39;00m\n\u001b[0;32m--> 467\u001b[0m     output \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/plain\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m}\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisplay\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiagram\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    469\u001b[0m         output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext/html\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m estimator_html_repr(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/base.py:319\u001b[0m, in \u001b[0;36mBaseEstimator.__repr__\u001b[0;34m(self, N_CHAR_MAX)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# use ellipsis for sequences with a lot of elements\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pp \u001b[38;5;241m=\u001b[39m _EstimatorPrettyPrinter(\n\u001b[1;32m    313\u001b[0m     compact\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    314\u001b[0m     indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    315\u001b[0m     indent_at_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    316\u001b[0m     n_max_elements_to_show\u001b[38;5;241m=\u001b[39mN_MAX_ELEMENTS_TO_SHOW,\n\u001b[1;32m    317\u001b[0m )\n\u001b[0;32m--> 319\u001b[0m repr_ \u001b[38;5;241m=\u001b[39m \u001b[43mpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# Use bruteforce ellipsis when there are a lot of non-blank characters\u001b[39;00m\n\u001b[1;32m    322\u001b[0m n_nonblank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(repr_\u001b[38;5;241m.\u001b[39msplit()))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/pprint.py:157\u001b[0m, in \u001b[0;36mPrettyPrinter.pformat\u001b[0;34m(self, object)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    156\u001b[0m     sio \u001b[38;5;241m=\u001b[39m _StringIO()\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sio\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/pprint.py:174\u001b[0m, in \u001b[0;36mPrettyPrinter._format\u001b[0;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m max_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_width \u001b[38;5;241m-\u001b[39m indent \u001b[38;5;241m-\u001b[39m allowance\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rep) \u001b[38;5;241m>\u001b[39m max_width:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/pprint.py:454\u001b[0m, in \u001b[0;36mPrettyPrinter._repr\u001b[0;34m(self, object, context, level)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_repr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mobject\u001b[39m, context, level):\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28mrepr\u001b[39m, readable, recursive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m readable:\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/utils/_pprint.py:191\u001b[0m, in \u001b[0;36m_EstimatorPrettyPrinter.format\u001b[0;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mobject\u001b[39m, context, maxlevels, level):\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_safe_repr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlevels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchanged_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_changed_only\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/utils/_pprint.py:440\u001b[0m, in \u001b[0;36m_safe_repr\u001b[0;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[1;32m    438\u001b[0m recursive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m changed_only:\n\u001b[0;32m--> 440\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43m_changed_params\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/utils/_pprint.py:95\u001b[0m, in \u001b[0;36m_changed_params\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_changed_params\u001b[39m(estimator):\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return dict (param_name: value) of parameters that were given to\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    estimator with non-default values.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     init_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated_original\u001b[39m\u001b[38;5;124m\"\u001b[39m, estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m)\n\u001b[1;32m     97\u001b[0m     init_params \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(init_func)\u001b[38;5;241m.\u001b[39mparameters\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/yellowbrick/base.py:342\u001b[0m, in \u001b[0;36mModelVisualizer.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_params\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    335\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    After v0.24 - scikit-learn is able to determine that ``self.estimator`` is\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m    nested and fetches its params using ``estimator__param``. This functionality is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m    the estimator params.\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mModelVisualizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(params\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/base.py:248\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    246\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names():\n\u001b[0;32m--> 248\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtype\u001b[39m):\n\u001b[1;32m    250\u001b[0m         deep_items \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mget_params()\u001b[38;5;241m.\u001b[39mitems()\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/yellowbrick/utils/wrapper.py:50\u001b[0m, in \u001b[0;36mWrapper.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped, attr)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m YellowbrickAttributeError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneither visualizer \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m nor wrapped estimator \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m have attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mYellowbrickAttributeError\u001b[0m: neither visualizer 'DiscriminationThreshold' nor wrapped estimator 'RandomForestClassifier' have attribute 'force_model'"
     ]
    },
    {
     "ename": "YellowbrickAttributeError",
     "evalue": "neither visualizer 'DiscriminationThreshold' nor wrapped estimator 'RandomForestClassifier' have attribute 'force_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/yellowbrick/utils/wrapper.py:48\u001b[0m, in \u001b[0;36mWrapper.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'force_model'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mYellowbrickAttributeError\u001b[0m                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/IPython/core/formatters.py:770\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    763\u001b[0m stream \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[1;32m    764\u001b[0m printer \u001b[38;5;241m=\u001b[39m pretty\u001b[38;5;241m.\u001b[39mRepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewline,\n\u001b[1;32m    766\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_seq_length,\n\u001b[1;32m    767\u001b[0m     singleton_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingleton_printers,\n\u001b[1;32m    768\u001b[0m     type_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_printers,\n\u001b[1;32m    769\u001b[0m     deferred_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeferred_printers)\n\u001b[0;32m--> 770\u001b[0m \u001b[43mprinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    771\u001b[0m printer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/IPython/lib/pretty.py:419\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    408\u001b[0m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    409\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    410\u001b[0m                     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    411\u001b[0m                     \u001b[38;5;66;03m# check if cls defines __repr__\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m                     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(_safe_getattr(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    418\u001b[0m                 ):\n\u001b[0;32m--> 419\u001b[0m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/IPython/lib/pretty.py:794\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[0;32m--> 794\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    795\u001b[0m lines \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgroup():\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/base.py:319\u001b[0m, in \u001b[0;36mBaseEstimator.__repr__\u001b[0;34m(self, N_CHAR_MAX)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# use ellipsis for sequences with a lot of elements\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pp \u001b[38;5;241m=\u001b[39m _EstimatorPrettyPrinter(\n\u001b[1;32m    313\u001b[0m     compact\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    314\u001b[0m     indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    315\u001b[0m     indent_at_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    316\u001b[0m     n_max_elements_to_show\u001b[38;5;241m=\u001b[39mN_MAX_ELEMENTS_TO_SHOW,\n\u001b[1;32m    317\u001b[0m )\n\u001b[0;32m--> 319\u001b[0m repr_ \u001b[38;5;241m=\u001b[39m \u001b[43mpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# Use bruteforce ellipsis when there are a lot of non-blank characters\u001b[39;00m\n\u001b[1;32m    322\u001b[0m n_nonblank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(repr_\u001b[38;5;241m.\u001b[39msplit()))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/pprint.py:157\u001b[0m, in \u001b[0;36mPrettyPrinter.pformat\u001b[0;34m(self, object)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    156\u001b[0m     sio \u001b[38;5;241m=\u001b[39m _StringIO()\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sio\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/pprint.py:174\u001b[0m, in \u001b[0;36mPrettyPrinter._format\u001b[0;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m max_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_width \u001b[38;5;241m-\u001b[39m indent \u001b[38;5;241m-\u001b[39m allowance\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rep) \u001b[38;5;241m>\u001b[39m max_width:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/pprint.py:454\u001b[0m, in \u001b[0;36mPrettyPrinter._repr\u001b[0;34m(self, object, context, level)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_repr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mobject\u001b[39m, context, level):\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28mrepr\u001b[39m, readable, recursive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m readable:\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/utils/_pprint.py:191\u001b[0m, in \u001b[0;36m_EstimatorPrettyPrinter.format\u001b[0;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mobject\u001b[39m, context, maxlevels, level):\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_safe_repr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlevels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchanged_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_changed_only\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/utils/_pprint.py:440\u001b[0m, in \u001b[0;36m_safe_repr\u001b[0;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[1;32m    438\u001b[0m recursive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m changed_only:\n\u001b[0;32m--> 440\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43m_changed_params\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/utils/_pprint.py:95\u001b[0m, in \u001b[0;36m_changed_params\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_changed_params\u001b[39m(estimator):\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return dict (param_name: value) of parameters that were given to\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    estimator with non-default values.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     init_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated_original\u001b[39m\u001b[38;5;124m\"\u001b[39m, estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m)\n\u001b[1;32m     97\u001b[0m     init_params \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(init_func)\u001b[38;5;241m.\u001b[39mparameters\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/yellowbrick/base.py:342\u001b[0m, in \u001b[0;36mModelVisualizer.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_params\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    335\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    After v0.24 - scikit-learn is able to determine that ``self.estimator`` is\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m    nested and fetches its params using ``estimator__param``. This functionality is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m    the estimator params.\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mModelVisualizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(params\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/base.py:248\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    246\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names():\n\u001b[0;32m--> 248\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtype\u001b[39m):\n\u001b[1;32m    250\u001b[0m         deep_items \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mget_params()\u001b[38;5;241m.\u001b[39mitems()\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/yellowbrick/utils/wrapper.py:50\u001b[0m, in \u001b[0;36mWrapper.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped, attr)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m YellowbrickAttributeError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneither visualizer \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m nor wrapped estimator \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m have attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mYellowbrickAttributeError\u001b[0m: neither visualizer 'DiscriminationThreshold' nor wrapped estimator 'RandomForestClassifier' have attribute 'force_model'"
     ]
    },
    {
     "ename": "YellowbrickAttributeError",
     "evalue": "neither visualizer 'DiscriminationThreshold' nor wrapped estimator 'RandomForestClassifier' have attribute 'force_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/yellowbrick/utils/wrapper.py:48\u001b[0m, in \u001b[0;36mWrapper.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'force_model'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mYellowbrickAttributeError\u001b[0m                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/IPython/core/formatters.py:406\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    404\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 406\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/base.py:463\u001b[0m, in \u001b[0;36mBaseEstimator._repr_html_inner\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_repr_html_inner\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    459\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function is returned by the @property `_repr_html_` to make\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;124;03m    `hasattr(estimator, \"_repr_html_\") return `True` or `False` depending\u001b[39;00m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;124;03m    on `get_config()[\"display\"]`.\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mestimator_html_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/utils/_estimator_html_repr.py:402\u001b[0m, in \u001b[0;36mestimator_html_repr\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    400\u001b[0m style_template \u001b[38;5;241m=\u001b[39m Template(_CSS_STYLE)\n\u001b[1;32m    401\u001b[0m style_with_id \u001b[38;5;241m=\u001b[39m style_template\u001b[38;5;241m.\u001b[39msubstitute(\u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39mcontainer_id)\n\u001b[0;32m--> 402\u001b[0m estimator_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# The fallback message is shown by default and loading the CSS sets\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;66;03m# div.sk-text-repr-fallback to display: none to hide the fallback message.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    411\u001b[0m \u001b[38;5;66;03m# The reverse logic applies to HTML repr div.sk-container.\u001b[39;00m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;66;03m# div.sk-container is hidden by default and the loading the CSS displays it.\u001b[39;00m\n\u001b[1;32m    413\u001b[0m fallback_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn a Jupyter environment, please rerun this cell to show the HTML\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m representation or trust the notebook. <br />On GitHub, the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m HTML representation is unable to render, please try loading this page\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m with nbviewer.org.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    418\u001b[0m )\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/base.py:319\u001b[0m, in \u001b[0;36mBaseEstimator.__repr__\u001b[0;34m(self, N_CHAR_MAX)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# use ellipsis for sequences with a lot of elements\u001b[39;00m\n\u001b[1;32m    312\u001b[0m pp \u001b[38;5;241m=\u001b[39m _EstimatorPrettyPrinter(\n\u001b[1;32m    313\u001b[0m     compact\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    314\u001b[0m     indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    315\u001b[0m     indent_at_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    316\u001b[0m     n_max_elements_to_show\u001b[38;5;241m=\u001b[39mN_MAX_ELEMENTS_TO_SHOW,\n\u001b[1;32m    317\u001b[0m )\n\u001b[0;32m--> 319\u001b[0m repr_ \u001b[38;5;241m=\u001b[39m \u001b[43mpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# Use bruteforce ellipsis when there are a lot of non-blank characters\u001b[39;00m\n\u001b[1;32m    322\u001b[0m n_nonblank \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(repr_\u001b[38;5;241m.\u001b[39msplit()))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/pprint.py:157\u001b[0m, in \u001b[0;36mPrettyPrinter.pformat\u001b[0;34m(self, object)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    156\u001b[0m     sio \u001b[38;5;241m=\u001b[39m _StringIO()\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_format\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sio\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/pprint.py:174\u001b[0m, in \u001b[0;36mPrettyPrinter._format\u001b[0;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 174\u001b[0m rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m max_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_width \u001b[38;5;241m-\u001b[39m indent \u001b[38;5;241m-\u001b[39m allowance\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(rep) \u001b[38;5;241m>\u001b[39m max_width:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/pprint.py:454\u001b[0m, in \u001b[0;36mPrettyPrinter._repr\u001b[0;34m(self, object, context, level)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_repr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mobject\u001b[39m, context, level):\n\u001b[0;32m--> 454\u001b[0m     \u001b[38;5;28mrepr\u001b[39m, readable, recursive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m                                            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m readable:\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_readable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/utils/_pprint.py:191\u001b[0m, in \u001b[0;36m_EstimatorPrettyPrinter.format\u001b[0;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mobject\u001b[39m, context, maxlevels, level):\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_safe_repr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxlevels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchanged_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_changed_only\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/utils/_pprint.py:440\u001b[0m, in \u001b[0;36m_safe_repr\u001b[0;34m(object, context, maxlevels, level, changed_only)\u001b[0m\n\u001b[1;32m    438\u001b[0m recursive \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m changed_only:\n\u001b[0;32m--> 440\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43m_changed_params\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39mget_params(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/utils/_pprint.py:95\u001b[0m, in \u001b[0;36m_changed_params\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_changed_params\u001b[39m(estimator):\n\u001b[1;32m     92\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return dict (param_name: value) of parameters that were given to\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;124;03m    estimator with non-default values.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     init_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated_original\u001b[39m\u001b[38;5;124m\"\u001b[39m, estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m)\n\u001b[1;32m     97\u001b[0m     init_params \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(init_func)\u001b[38;5;241m.\u001b[39mparameters\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/yellowbrick/base.py:342\u001b[0m, in \u001b[0;36mModelVisualizer.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_params\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    335\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    After v0.24 - scikit-learn is able to determine that ``self.estimator`` is\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m    nested and fetches its params using ``estimator__param``. This functionality is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;124;03m    the estimator params.\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mModelVisualizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(params\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mestimator__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/sklearn/base.py:248\u001b[0m, in \u001b[0;36mBaseEstimator.get_params\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    246\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_param_names():\n\u001b[0;32m--> 248\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mget_params\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mtype\u001b[39m):\n\u001b[1;32m    250\u001b[0m         deep_items \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mget_params()\u001b[38;5;241m.\u001b[39mitems()\n",
      "File \u001b[0;32m~/Udemy/Udemy/machine_learning_imbalanced_data/.venv/lib/python3.10/site-packages/yellowbrick/utils/wrapper.py:50\u001b[0m, in \u001b[0;36mWrapper.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped, attr)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m YellowbrickAttributeError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mneither visualizer \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m nor wrapped estimator \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrapped)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m have attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mYellowbrickAttributeError\u001b[0m: neither visualizer 'DiscriminationThreshold' nor wrapped estimator 'RandomForestClassifier' have attribute 'force_model'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualizer = DiscriminationThreshold(estimator = rf, cv=0.5, argmax='fscore', random_state=0, is_fitted='auto', exclude='queue_rate')\n",
    "visualizer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__sklearn_clone__',\n",
       " '__sklearn_tags__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_ax',\n",
       " '_build_request_for_signature',\n",
       " '_check_argmax',\n",
       " '_check_cv',\n",
       " '_check_exclude',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_check_quantiles',\n",
       " '_doc_link_module',\n",
       " '_doc_link_template',\n",
       " '_doc_link_url_param_generator',\n",
       " '_fig',\n",
       " '_get_default_requests',\n",
       " '_get_doc_link',\n",
       " '_get_metadata_request',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_size',\n",
       " '_split_fit_score_trial',\n",
       " '_validate_data',\n",
       " '_validate_params',\n",
       " '_wrapped',\n",
       " 'argmax',\n",
       " 'ax',\n",
       " 'color',\n",
       " 'cv',\n",
       " 'cv_scores_',\n",
       " 'draw',\n",
       " 'estimator',\n",
       " 'exclude',\n",
       " 'fbeta',\n",
       " 'fig',\n",
       " 'finalize',\n",
       " 'fit',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'is_fitted',\n",
       " 'n_trials',\n",
       " 'name',\n",
       " 'poof',\n",
       " 'quantiles',\n",
       " 'random_state',\n",
       " 'set_params',\n",
       " 'set_title',\n",
       " 'show',\n",
       " 'size',\n",
       " 'thresholds_',\n",
       " 'title']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(visualizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = DiscriminationThreshold(estimator = rf, cv=0.5, argmax='fscore', random_state=0, is_fitted='auto', exclude='queue_rate')\n",
    "visualizer.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n",
      "findfont: Generic family 'sans-serif' not found because none of the following families were found: Arial, Liberation Sans, Bitstream Vera Sans, sans-serif\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Threshold Plot for RandomForestClassifier'}, xlabel='discrimination threshold', ylabel='score'>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualizer = DiscriminationThreshold(rf, n_trials=1, cv=0.5, argmax='fscore', random_state=0, is_fitted='auto', exclude='queue_rate')\n",
    "\n",
    "visualizer.fit(X_train, y_train)\n",
    "# visualizer.score(X_test, y_test)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__sklearn_clone__',\n",
       " '__sklearn_tags__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_ax',\n",
       " '_build_request_for_signature',\n",
       " '_check_argmax',\n",
       " '_check_cv',\n",
       " '_check_exclude',\n",
       " '_check_feature_names',\n",
       " '_check_n_features',\n",
       " '_check_quantiles',\n",
       " '_doc_link_module',\n",
       " '_doc_link_template',\n",
       " '_doc_link_url_param_generator',\n",
       " '_fig',\n",
       " '_get_default_requests',\n",
       " '_get_doc_link',\n",
       " '_get_metadata_request',\n",
       " '_get_param_names',\n",
       " '_get_tags',\n",
       " '_more_tags',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_size',\n",
       " '_split_fit_score_trial',\n",
       " '_validate_data',\n",
       " '_validate_params',\n",
       " '_wrapped',\n",
       " 'argmax',\n",
       " 'ax',\n",
       " 'color',\n",
       " 'cv',\n",
       " 'cv_scores_',\n",
       " 'draw',\n",
       " 'estimator',\n",
       " 'exclude',\n",
       " 'fbeta',\n",
       " 'fig',\n",
       " 'finalize',\n",
       " 'fit',\n",
       " 'get_metadata_routing',\n",
       " 'get_params',\n",
       " 'is_fitted',\n",
       " 'n_trials',\n",
       " 'name',\n",
       " 'poof',\n",
       " 'quantiles',\n",
       " 'random_state',\n",
       " 'set_params',\n",
       " 'set_title',\n",
       " 'show',\n",
       " 'size',\n",
       " 'thresholds_',\n",
       " 'title']"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(visualizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9962036317065361"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualizer.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"DejaVu Sans\"  # Change to a known font\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Threshold Plot for RandomForestClassifier'}, xlabel='discrimination threshold', ylabel='score'>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualizer = DiscriminationThreshold(estimator=rf, cv=0.5, argmax='fscore', random_state=0, is_fitted='auto', exclude='queue_rate')\n",
    "\n",
    "visualizer.fit(X_train, y_train)\n",
    "# visualizer.score(X_test, y_test)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
